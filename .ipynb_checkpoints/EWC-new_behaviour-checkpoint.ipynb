{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cF83GGjUe9_N"
   },
   "source": [
    "# Elastic weight consolidation - new behaviour\n",
    "\n",
    "In the past notebook *Triplet learning for bearing fault classification* we trained a classification model for bearing faults of rotating equipment. Such model was robust to different operating conditions such as different machine loads or rotation velocity, and did not use characteristic information about the machine, such as the rotation velocity or the characteristic coefficients. We used an approach based on triplet learning.\n",
    "\n",
    "In this notebook, we want to illustrate how the retraining process would be done, when new data (from the same machine) arribes. Such new data may be slightly different from the data previously seen by the model, either because of concept drift or simply because we are seeing a common behaviour which had not been seen before. Therefore, we want the model to learn useful information of this new data without forgetting about the previously acquired knowledge.\n",
    "\n",
    "In this notebook we will simulate the arrival of new unseen behaviour, with little change, and see how the model adapts to this new situation. In the notebook *Elastic weight consolidation - concept drift* we simulate the other situation, concept drift. In order to simulate this new behaviour we will use two these two datasets:\n",
    "\n",
    "+ **Case Western Reserve University Bearing Data Center - without noise**: This dataset contains vibration data (waveforms) of different bearings, each suffering from a fault (inner ring, outer ring) or being healthy. The fault is completely developed. This dataset will be considered as the *old* dataset.\n",
    "\n",
    "+ **Case Western Reserve University Bearing Data Center - with noise**: It is the same dataset as the *old* one, but we have included some (non-white) noise. We will use this data as the *new* data that the model has to learn.\n",
    "\n",
    "The inputs of the models will be the same as in the notebook *Triplet learning for bearing fault classification*.\n",
    "\n",
    "More details about the training process are provided in the following sections.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zMvDLLmTgaDf"
   },
   "source": [
    "The following lines of code are used to mount to drive account and import the needed packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 34959,
     "status": "ok",
     "timestamp": 1586447332344,
     "user": {
      "displayName": "Laia Domingo",
      "photoUrl": "",
      "userId": "05713674999451466092"
     },
     "user_tz": -120
    },
    "id": "9bSImtZ6oENC",
    "outputId": "c9ba7e2b-5f55-4acd-e22c-0c365119ec1c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.signal\n",
    "\n",
    "import plotly\n",
    "from plotly.graph_objs import graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, layers\n",
    "\n",
    "import pandas as pd\n",
    "import umap\n",
    "import sys\n",
    "\n",
    "sys.path.append('./Training')\n",
    "sys.path.append('./Data')\n",
    "sys.path.append('./Models')\n",
    "sys.path.append('./Load_Data')\n",
    "sys.path.append('./Preprocessing')\n",
    "\n",
    "from CWRU_data import Preprocessing_CWRU, Load_CWRU_noise, Load_CWRU\n",
    "from spectrum import acc_spectrum\n",
    "from CNN_model import Embedding, Classification\n",
    "from train_classifier import Training_classifier\n",
    "from train_embeddings import Train_Embeddings\n",
    "from pretraining import Pretraining\n",
    "from EWC import Train_Classifier_EWC, Train_Embeddings_EWC,Fisher_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 34940,
     "status": "ok",
     "timestamp": 1586447332345,
     "user": {
      "displayName": "Laia Domingo",
      "photoUrl": "",
      "userId": "05713674999451466092"
     },
     "user_tz": -120
    },
    "id": "Up41WXICo-6W",
    "outputId": "decabd90-e0e1-4334-f3a9-f0b1c06d1a31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YPuniEl8-ZqE"
   },
   "source": [
    "## Datasets\n",
    "\n",
    "We upload two types of data. The first one is noiseless.\n",
    "The second one has noise.\n",
    "\n",
    "The noise is introduced in two different ways:\n",
    "\n",
    "1. Amplify the apmplitude of the 4rth first harmonics.\n",
    "\n",
    "2. Introduce white noise (random frequencies) within a frequency band of 750-1000Hz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9zBjfmK14B9E"
   },
   "source": [
    "## Preprocessing\n",
    "\n",
    "In order to preprocess data we performed the following steps:\n",
    "\n",
    "+ Downsampling from 20000 Hz to 5000 Hz in order to have data more similiar to the real productio data.\n",
    "\n",
    "+ Rolling window for each waveform, to reduce the size of the wavevorm to 1000 timestamps (instead of 5000) and to obtain more samples from the same waveform. There is no overlap.\n",
    "\n",
    "+ Adaptative normalization: minmax scaling.\n",
    "\n",
    "+ Shuffle samples.\n",
    "\n",
    "+ Split of training and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KB_tFudZgfKK"
   },
   "source": [
    "## Load Case Western Reserve University (CWRU) Data\n",
    "\n",
    "Given the file names of the data, the following class imports and processes the data in order to make it suitable for the CNN model. \n",
    "\n",
    "The datasets are stored in Matlab files. There are three bearing failure modes: healthy, inner ring and outer ring. For each failure, there are four different loads, running at different rotation speed: 1797, 1772, 1750 and 1730 rpm. Finally, for each load there are two different diameter failures (7mm and 14mm). We will mix all the failures, loads and diameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 49833,
     "status": "ok",
     "timestamp": 1586447347261,
     "user": {
      "displayName": "Laia Domingo",
      "photoUrl": "",
      "userId": "05713674999451466092"
     },
     "user_tz": -120
    },
    "id": "lC2TEDhu3ZHc",
    "outputId": "62ed0bf4-2bd8-4931-cdee-474cb32dcd17"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laia.domingo.colomer\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4117: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prep = Preprocessing_CWRU()\n",
    "\n",
    "CWRU_noise = Load_CWRU_noise(prep)\n",
    "\n",
    "X_train_noise, X_test_noise, y_train_noise, y_test_noise, load_train_noise, load_test_noise = CWRU_noise.get_X_y()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uM1RzTUrAsjp"
   },
   "source": [
    "## Noiseless CWRU Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 52132,
     "status": "ok",
     "timestamp": 1586447349584,
     "user": {
      "displayName": "Laia Domingo",
      "photoUrl": "",
      "userId": "05713674999451466092"
     },
     "user_tz": -120
    },
    "id": "Bv7T49u0B0vx",
    "outputId": "bc26778d-c489-4b5b-aef9-6d00c8b148e1"
   },
   "outputs": [],
   "source": [
    "CWRU = Load_CWRU(prep)\n",
    "\n",
    "X_train, X_test, y_train, y_test, load_train, load_test = CWRU.get_X_y()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q87Y3-ikp7dE"
   },
   "source": [
    "## Visualizing the noise\n",
    "\n",
    "We have created two datasets: CWRU with and without noise. In the following code, we will give an example to show what the noise looks like, both in the time (waveform) and frequency (spectrum) domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 53705,
     "status": "ok",
     "timestamp": 1586447351178,
     "user": {
      "displayName": "Laia Domingo",
      "photoUrl": "",
      "userId": "05713674999451466092"
     },
     "user_tz": -120
    },
    "id": "2Wm-iWsKqnVC",
    "outputId": "3787aa70-b2c4-4f14-c96f-0ad0119544a5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Prepare the data\n",
    "normal0_raw = scipy.io.loadmat('Data/CWRU/D7/Normal/97.mat')['X097_DE_time'].reshape(1,-1)[0]\n",
    "normal0_raw = scipy.signal.decimate(normal0_raw,2)\n",
    "\n",
    "data = np.copy(normal0_raw)\n",
    "env = envl_freq(5000, 1800, 2400)\n",
    "\n",
    "#Prepare the noise and added noise\n",
    "noise = np.zeros(data.shape)\n",
    "noise = prep.add_noise_harmonics(noise,1797)\n",
    "noise = prep.add_noise_band(noise,300000,20000,0,0.08,10,4.0)\n",
    "data_noise = data + noise\n",
    "\n",
    "#Show plots\n",
    "\n",
    "#Spectrum of signal\n",
    "fft_env, freqs_env, _ = env.acc_spectrum(data, len(data), 5000, cutoff_freq=1)\n",
    "plt.title('Spectrum of signal')\n",
    "plt.plot(freqs_env, fft_env)\n",
    "plt.show()\n",
    "\n",
    "#Spectrum of noise\n",
    "fft_noise, freqs_noise, _ = env.acc_spectrum(noise, len(noise), 5000, cutoff_freq=1)\n",
    "plt.plot(freqs_noise, fft_noise)\n",
    "plt.title('Spectrum of noise')\n",
    "plt.show()\n",
    "\n",
    "#Spectrum of signal+noise\n",
    "fft_env, freqs_env, _ = env.acc_spectrum(data_noise, len(data_noise), 5000, cutoff_freq=1)\n",
    "plt.title('Spectrum of signal+noise')\n",
    "plt.plot(freqs_env, fft_env)\n",
    "plt.show()\n",
    "\n",
    "#Waveform of signal\n",
    "plt.plot(range(len(data[range(100,2000,5)])),data[range(100,2000,5)])\n",
    "plt.title('Waveform of signal')\n",
    "plt.show()\n",
    "\n",
    "#Waveform of noise\n",
    "plt.plot(range(len(noise[range(100,2000,5)])),noise[range(100,2000,5)])\n",
    "plt.title('Waveform of noise')\n",
    "plt.show()\n",
    "\n",
    "#Waveform of signal+noise\n",
    "plt.plot(range(len(data_noise[range(100,2000,5)])),data_noise[range(100,2000,5)])\n",
    "plt.title('Waveform of signal+noise')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code to load the embedding and classification models from the path where the weights are saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(filepath, learning_rate = 0.001, net = 'classification'):\n",
    "    \"\"\"\n",
    "    Loads the embedding and classification models.\n",
    "    Args:\n",
    "        filepath (str): Path of the saved weights\n",
    "        learning_rate (float): Learning rate of the Adam optimizer\n",
    "    Returns:\n",
    "        embedding (Model): Embedding model\n",
    "        classification (Model): Classification model\n",
    "    \"\"\"\n",
    "    #Redefine model\n",
    "    embedding = Embedding()\n",
    "    classification = Classification(embedding)\n",
    "\n",
    "    optimizer = tf.optimizers.Adam(learning_rate)\n",
    "    if net=='classification':\n",
    "        ckpt = tf.train.Checkpoint(optimizer=optimizer, net=classification)\n",
    "        manager = tf.train.CheckpointManager(ckpt, directory = filepath , max_to_keep=3)\n",
    "        ckpt.restore(manager.latest_checkpoint)\n",
    "        embedding = classification.embedding\n",
    "    else:\n",
    "        ckpt = tf.train.Checkpoint(optimizer=optimizer, net=embedding)\n",
    "        manager = tf.train.CheckpointManager(ckpt, directory = filepath , max_to_keep=3)\n",
    "        ckpt.restore(manager.latest_checkpoint)\n",
    "        \n",
    "    if manager.latest_checkpoint:\n",
    "        print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
    "    else:\n",
    "        print(\"Initializing from scratch.\")\n",
    "\n",
    "    return embedding, classification\n",
    "\n",
    "# Example of use:\n",
    "# embedding, classification = load_model(\"Weights/TL/classifier/training/\", learning_rate = 0.0001 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SdqR0rG9DX6q"
   },
   "source": [
    "## Pretraining: Simple CNN\n",
    "\n",
    "We start by pre training the CNN with cross entropy loss, because it is a very stable loss function. This pre trained model will be used later to train the embeddings and the final classification model. \n",
    "\n",
    "We first define the hyperparameters: learning rate, training iterations, batch size, input size of the CNN, number of classification outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wPKcGP2n6xZB"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 500\n",
    "batch_size = 16\n",
    "display_step = 10\n",
    "filepath = \"Weights/EWC/CWRU-noise/classifier/pretraining/\"\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 1000 # Length of input data\n",
    "num_classes = 4  # number of classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cbRV0wXp7UrJ"
   },
   "source": [
    "### Embeddings\n",
    "\n",
    "Next, we define the structure of the embedding network:\n",
    "\n",
    "It consists of a 1D neural network, with the input the temporal series (waveform). \n",
    "\n",
    "The CNN has 3 1D Convolutional layers with 32,32 and 64 filters respectively, height=10, strides=4 and padding='same'. We have 3 MaxPooling subsampling layers with pool size = 10, strides = 4. Then we have 2 FC with 32 nodes, and another with 20 output nodes. This last layer is the output of the embedding- All layers have Relu activation function. This embedding will be used later on to classify the faults into different faults."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qj2e45pf7WWZ"
   },
   "source": [
    "### Classification model\n",
    "\n",
    "The classification model takes as input the output of the embedding model, and adds 3 Fc layers, with 64, 64 and 32 filters each. The output is the number of types of defects (4). During the pretraining process, all layers will be trained using cross entropy loss.\n",
    "\n",
    "You can skip the next cell and load directly the saved weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 75387,
     "status": "ok",
     "timestamp": 1586447372894,
     "user": {
      "displayName": "Laia Domingo",
      "photoUrl": "",
      "userId": "05713674999451466092"
     },
     "user_tz": -120
    },
    "id": "FqW2peNWEN_s",
    "outputId": "18e476f7-5978-4552-8109-20ff77a34657"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer classification is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "step: 10, loss: 1.242955, accuracy: 0.437500\n",
      "step: 20, loss: 1.116450, accuracy: 0.750000\n",
      "step: 30, loss: 0.934655, accuracy: 0.812500\n",
      "step: 40, loss: 0.938980, accuracy: 0.750000\n",
      "step: 50, loss: 0.803170, accuracy: 1.000000\n",
      "step: 60, loss: 0.816710, accuracy: 0.937500\n",
      "step: 70, loss: 0.772234, accuracy: 1.000000\n",
      "step: 80, loss: 0.808047, accuracy: 0.937500\n",
      "step: 90, loss: 0.796488, accuracy: 0.937500\n",
      "step: 100, loss: 0.754763, accuracy: 1.000000\n",
      "step: 110, loss: 0.784848, accuracy: 1.000000\n",
      "step: 120, loss: 0.835357, accuracy: 0.875000\n",
      "step: 130, loss: 0.751165, accuracy: 1.000000\n",
      "step: 140, loss: 0.747956, accuracy: 1.000000\n",
      "step: 150, loss: 0.748182, accuracy: 1.000000\n",
      "step: 160, loss: 0.743837, accuracy: 1.000000\n",
      "step: 170, loss: 0.744462, accuracy: 1.000000\n",
      "step: 180, loss: 0.744369, accuracy: 1.000000\n",
      "step: 190, loss: 0.743744, accuracy: 1.000000\n",
      "step: 200, loss: 0.743723, accuracy: 1.000000\n",
      "step: 210, loss: 0.743713, accuracy: 1.000000\n",
      "step: 220, loss: 0.743701, accuracy: 1.000000\n",
      "step: 230, loss: 0.743755, accuracy: 1.000000\n",
      "step: 240, loss: 0.743740, accuracy: 1.000000\n",
      "step: 250, loss: 0.744381, accuracy: 1.000000\n",
      "step: 260, loss: 0.806081, accuracy: 0.937500\n",
      "step: 270, loss: 0.797902, accuracy: 0.937500\n",
      "step: 280, loss: 0.766331, accuracy: 1.000000\n",
      "step: 290, loss: 0.744330, accuracy: 1.000000\n",
      "step: 300, loss: 0.743967, accuracy: 1.000000\n",
      "step: 310, loss: 0.743697, accuracy: 1.000000\n",
      "step: 320, loss: 0.743669, accuracy: 1.000000\n",
      "step: 330, loss: 0.743692, accuracy: 1.000000\n",
      "step: 340, loss: 0.743668, accuracy: 1.000000\n",
      "step: 350, loss: 0.743677, accuracy: 1.000000\n",
      "step: 360, loss: 0.744007, accuracy: 1.000000\n",
      "step: 370, loss: 0.743704, accuracy: 1.000000\n",
      "step: 380, loss: 0.743671, accuracy: 1.000000\n",
      "step: 390, loss: 0.743689, accuracy: 1.000000\n",
      "step: 400, loss: 0.743670, accuracy: 1.000000\n",
      "step: 410, loss: 0.743672, accuracy: 1.000000\n",
      "step: 420, loss: 0.743669, accuracy: 1.000000\n",
      "step: 430, loss: 0.743669, accuracy: 1.000000\n",
      "step: 440, loss: 0.743671, accuracy: 1.000000\n",
      "step: 450, loss: 0.743698, accuracy: 1.000000\n",
      "step: 460, loss: 0.743670, accuracy: 1.000000\n",
      "step: 470, loss: 0.743697, accuracy: 1.000000\n",
      "step: 480, loss: 0.744625, accuracy: 1.000000\n",
      "step: 490, loss: 0.743675, accuracy: 1.000000\n",
      "step: 500, loss: 0.743669, accuracy: 1.000000\n",
      "Saved checkpoint for step Weights/EWC/CWRU-noise/classifier/pretraining/ckpt-1\n"
     ]
    }
   ],
   "source": [
    "# Build neural network model.\n",
    "embedding = Embedding()\n",
    "conv_net = Classification(embedding)\n",
    "\n",
    "pretrain = Pretraining(conv_net, learning_rate, training_iters, batch_size, display_step,filepath, restore=False)\n",
    "\n",
    "pretrain.fit( X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 75869,
     "status": "ok",
     "timestamp": 1586447373404,
     "user": {
      "displayName": "Laia Domingo",
      "photoUrl": "",
      "userId": "05713674999451466092"
     },
     "user_tz": -120
    },
    "id": "gn3Zvtn8Og_0",
    "outputId": "39aa1ad7-8cc1-42ec-94de-e3482feb003b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored from Weights/EWC/CWRU-noise/classifier/pretraining/ckpt-1\n",
      "WARNING:tensorflow:Layer classification_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.fc1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.fc1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.fc2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.fc2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.fc3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.fc3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.out.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.out.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.embedding.conv1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.embedding.conv1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.embedding.conv2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.embedding.conv2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.embedding.conv3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.embedding.conv3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.embedding.conv4.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.embedding.conv4.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.embedding.fc1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.embedding.fc1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.embedding.fc2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.embedding.fc2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.embedding.embeddings.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.embedding.embeddings.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.fc1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.fc1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.fc2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.fc2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.fc3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.fc3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.out.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.out.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.embedding.conv1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.embedding.conv1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.embedding.conv2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.embedding.conv2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.embedding.conv3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.embedding.conv3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.embedding.conv4.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.embedding.conv4.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.embedding.fc1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.embedding.fc1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.embedding.fc2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.embedding.fc2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.embedding.embeddings.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.embedding.embeddings.beta\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer embedding_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Test Accuracy: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# Comment this line to use the model you just trained, and not the loaded weights\n",
    "embedding, conv_net = load_model(\"Weights/EWC/CWRU-noise/classifier/pretraining/\")\n",
    "\n",
    "# Test model on validation set.\n",
    "pred= conv_net(X_test)\n",
    "emb = embedding(X_test)\n",
    "y_pred = np.argmax(pred.numpy(), axis=1)\n",
    "print(\"Test Accuracy: %f\" % accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GB-a0fuqDqew"
   },
   "source": [
    "## Triplet loss\n",
    "\n",
    "Here we define the functions that will be used to compute the triplet loss of the embeddings. We use online triplet mining, with both 'batch all' and 'batch hard' strategies. \n",
    "\n",
    "For more information about triplet loss, refer to the notebook *Triplet learning for bearing fault classification*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZlAYHA6xws7Q"
   },
   "source": [
    "## Training Triplet loss\n",
    "\n",
    "Now that we have a good initialization for the Weights from the pretrained model, we perform triplet loss optimization of the embeddings. \n",
    "\n",
    "We first define the hyperparameters for this part: learning rate, training iterations, batch size, margin, triplet strategy, embedding size and input size.  \n",
    "\n",
    "You can skip these three cells and load directly the saved weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RqF2ipvYO6h9"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.0001\n",
    "training_iters = 15\n",
    "batch_size = 64\n",
    "\n",
    "#Triplet parameters\n",
    "margin = 1.0\n",
    "squared=False\n",
    "triplet_strategy='batch_hard'  #'batch_all'\n",
    "filepath = \"Weights/EWC/CWRU-noise/embedding\"\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 1000 # Length of input data\n",
    "embedding_size = 20 # length of embedding features \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sMtbH3Dj3cZt"
   },
   "outputs": [],
   "source": [
    "#Function to get batches\n",
    "def get_all_batches(data,labels,batch_size):\n",
    "  '''\n",
    "  Gets all the batches from existing dataset.\n",
    "\n",
    "  Args:\n",
    "    data (numpy array): X data\n",
    "    labels (numpy array): y data\n",
    "    batch_size (int): Batch size\n",
    "\n",
    "  Returns:\n",
    "    batches_x (list of numpy array): list of batches for X data\n",
    "    batches_y (list of numpy array): list of batches for y data\n",
    "    num_batches (int): Number of batches\n",
    "  '''\n",
    "  idx = np.arange(0,data.shape[0])\n",
    "  np.random.shuffle(idx)\n",
    "\n",
    "  data_shuffle = data[idx,:]\n",
    "  labels_shuffle = labels[idx]\n",
    "\n",
    "  labels_shuffle = labels_shuffle[0:labels.shape[0] - labels.shape[0]%batch_size]\n",
    "  data_shuffle = data_shuffle[0:labels.shape[0] - labels.shape[0]%batch_size,:]\n",
    "  \n",
    "  num_batches = data_shuffle.shape[0]/batch_size \n",
    "  batches_x =np.split(data_shuffle,num_batches)\n",
    "  batches_y =np.split(labels_shuffle,num_batches)\n",
    "\n",
    "  return batches_x,batches_y,num_batches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G1vSPfEz8TdY"
   },
   "source": [
    "We train the embeddings using triplet loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 604
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 83136,
     "status": "ok",
     "timestamp": 1586447380701,
     "user": {
      "displayName": "Laia Domingo",
      "photoUrl": "",
      "userId": "05713674999451466092"
     },
     "user_tz": -120
    },
    "id": "dJzS5VHEO6XQ",
    "outputId": "36a70915-3412-4744-e323-fe2966e0a235"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315.0\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method DescriptorBase.GetOptions of <google.protobuf.descriptor.Descriptor object at 0x0000020DEBA24940>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: LIVE_VARS_IN\n",
      "WARNING: AutoGraph could not transform <bound method DescriptorBase.GetOptions of <google.protobuf.descriptor.Descriptor object at 0x0000020DEBA24940>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: LIVE_VARS_IN\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method DescriptorBase.GetOptions of <google.protobuf.descriptor.Descriptor object at 0x0000020DEBA24940>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: LIVE_VARS_IN\n",
      "WARNING: AutoGraph could not transform <bound method DescriptorBase.GetOptions of <google.protobuf.descriptor.Descriptor object at 0x0000020DEBA24940>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: LIVE_VARS_IN\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method DescriptorBase.GetOptions of <google.protobuf.descriptor.Descriptor object at 0x0000020DEBA24940>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: LIVE_VARS_IN\n",
      "WARNING: AutoGraph could not transform <bound method DescriptorBase.GetOptions of <google.protobuf.descriptor.Descriptor object at 0x0000020DEBA24940>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: LIVE_VARS_IN\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method DescriptorBase.GetOptions of <google.protobuf.descriptor.Descriptor object at 0x0000020DEBA24940>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: LIVE_VARS_IN\n",
      "WARNING: AutoGraph could not transform <bound method DescriptorBase.GetOptions of <google.protobuf.descriptor.Descriptor object at 0x0000020DEBA24940>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: LIVE_VARS_IN\n",
      "step:  10 Loss 1.0780119 Fraction positive triplets 0\n",
      "step:  20 Loss 1.0345991 Fraction positive triplets 0\n",
      "step:  30 Loss 1.0449303 Fraction positive triplets 0\n",
      "step:  40 Loss 1.0258709 Fraction positive triplets 0\n",
      "step:  50 Loss 1.0273192 Fraction positive triplets 0\n",
      "step:  60 Loss 1.0120175 Fraction positive triplets 0\n",
      "step:  70 Loss 1.0087386 Fraction positive triplets 0\n",
      "step:  80 Loss 0.99276537 Fraction positive triplets 0\n",
      "step:  90 Loss 0.9914377 Fraction positive triplets 0\n",
      "step:  100 Loss 0.9909733 Fraction positive triplets 0\n",
      "step:  110 Loss 1.0177479 Fraction positive triplets 0\n",
      "step:  120 Loss 1.0168505 Fraction positive triplets 0\n",
      "step:  130 Loss 0.98151505 Fraction positive triplets 0\n",
      "step:  140 Loss 0.99393046 Fraction positive triplets 0\n",
      "step:  150 Loss 0.90005696 Fraction positive triplets 0\n",
      "step:  160 Loss 0.96509457 Fraction positive triplets 0\n",
      "step:  170 Loss 0.8865309 Fraction positive triplets 0\n",
      "step:  180 Loss 0.93656147 Fraction positive triplets 0\n",
      "step:  190 Loss 0.94095457 Fraction positive triplets 0\n",
      "step:  200 Loss 0.85746783 Fraction positive triplets 0\n",
      "step:  210 Loss 0.8045248 Fraction positive triplets 0\n",
      "step:  220 Loss 0.7083204 Fraction positive triplets 0\n",
      "step:  230 Loss 0.698166 Fraction positive triplets 0\n",
      "step:  240 Loss 0.77338123 Fraction positive triplets 0\n",
      "step:  250 Loss 0.81368816 Fraction positive triplets 0\n",
      "step:  260 Loss 0.7639489 Fraction positive triplets 0\n",
      "step:  270 Loss 0.648652 Fraction positive triplets 0\n",
      "step:  280 Loss 0.7269243 Fraction positive triplets 0\n",
      "step:  290 Loss 0.7010214 Fraction positive triplets 0\n",
      "step:  300 Loss 0.7139871 Fraction positive triplets 0\n",
      "step:  310 Loss 0.66351503 Fraction positive triplets 0\n",
      "Saved checkpoint for step Weights/EWC/CWRU-noise/embedding\\ckpt-1\n"
     ]
    }
   ],
   "source": [
    "# Build neural network model.\n",
    "_,_,num_batches = get_all_batches(X_train,y_train,batch_size)\n",
    "print(num_batches*training_iters)\n",
    "\n",
    "train_emb = Train_Embeddings( embedding, learning_rate, int(num_batches*training_iters), \n",
    "                             batch_size, display_step, triplet_strategy, margin,\n",
    "                             squared, filepath, restore = False)\n",
    "\n",
    "train_emb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H_SuENTyO6PA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored from Weights/EWC/CWRU-noise/embedding\\ckpt-1\n",
      "WARNING:tensorflow:Layer embedding_4 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.conv1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.conv1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.conv2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.conv2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.conv3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.conv3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.conv4.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.conv4.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.fc1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.fc1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.fc2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.fc2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.embeddings.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.embeddings.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.conv1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.conv1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.conv2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.conv2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.conv3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.conv3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.conv4.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.conv4.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.fc1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.fc1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.fc2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.fc2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.embeddings.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.embeddings.beta\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "# Comment this line to use the model you just trained, and not the loaded weights\n",
    "embedding, conv_net = load_model(\"Weights/EWC/CWRU-noise/embedding\", net =\"emb\")\n",
    "\n",
    "emb2 = embedding(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lb9r4Lac8bnt"
   },
   "source": [
    "We visualize the embeddings using UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 89862,
     "status": "ok",
     "timestamp": 1586447387447,
     "user": {
      "displayName": "Laia Domingo",
      "photoUrl": "",
      "userId": "05713674999451466092"
     },
     "user_tz": -120
    },
    "id": "tNNyEMvY7gWc",
    "outputId": "a55c5c1f-533f-4476-b8c7-3a46e0fe6ef8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laia.domingo.colomer\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\umap\\spectral.py:229: UserWarning:\n",
      "\n",
      "Embedding a total of 2 separate connected components using meta-embedding (experimental)\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = emb2\n",
    "\n",
    "embed= umap.UMAP(n_neighbors=10,\n",
    "                      min_dist=0.2,\n",
    "                      metric='correlation').fit_transform(features)\n",
    "\n",
    "color = pd.DataFrame(y_test,columns=['color'])\n",
    "color.replace({0:'red', 1:'blue', 2:'green', 3:'orange'},inplace=True)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "plt.scatter(embed[:,0], embed[:,1], \n",
    "            c=color.values.flatten(),\n",
    "            cmap=\"Spectral\", \n",
    "            s=1.0)\n",
    "plt.setp(ax, xticks=[], yticks=[])\n",
    "plt.title(\"Extracted features CWRU (noisless)\", fontsize=18)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pryaFbkhy-N8"
   },
   "source": [
    "We can see that the embeddings are far apart for different failures, and close together for the same failure.\n",
    "\n",
    "We visualize also the embeddings for the second task (noisy data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2924,
     "status": "ok",
     "timestamp": 1586447390682,
     "user": {
      "displayName": "Laia Domingo",
      "photoUrl": "",
      "userId": "05713674999451466092"
     },
     "user_tz": -120
    },
    "id": "NCA_9n5zoU0N",
    "outputId": "340d0e61-eb9e-42bf-8e14-1eef3358f9cd"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emb = embedding(X_test_noise)\n",
    "\n",
    "features = emb\n",
    "\n",
    "embed= umap.UMAP(n_neighbors=10,\n",
    "                      min_dist=0.2,\n",
    "                      metric='correlation').fit_transform(features)\n",
    "\n",
    "color = pd.DataFrame(y_test_noise,columns=['color'])\n",
    "color.replace({0:'red', 1:'blue', 2:'green', 3:'orange'},inplace=True)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "plt.scatter(embed[:,0], embed[:,1], \n",
    "            c=color.values.flatten(),\n",
    "            cmap=\"Spectral\", \n",
    "            s=1.0)\n",
    "plt.setp(ax, xticks=[], yticks=[])\n",
    "plt.title(\"Extracted features CWRU (noisy)\", fontsize=18)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "00cj7gEDD7TO"
   },
   "source": [
    "## Classification model using triplet loss embeddings\n",
    "\n",
    "Now that we have trained the embeddings using triplet loss, we will train the classifier using cross entropy loss. During this training the embedding layers will be frozen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k6tUtCzD7kkh"
   },
   "outputs": [],
   "source": [
    "#Parameters\n",
    "num_classes = 4\n",
    "batch_size= 64\n",
    "training_iters = 200\n",
    "learning_rate=0.001\n",
    "filepath = \"Weights/EWC/CWRU-noise/classifier/training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2117,
     "status": "ok",
     "timestamp": 1585914967185,
     "user": {
      "displayName": "Laia Domingo",
      "photoUrl": "",
      "userId": "05713674999451466092"
     },
     "user_tz": -120
    },
    "id": "LFPsejs3Fpa3",
    "outputId": "8a9b1f87-6cd6-4d13-de88-6bd60d1e949f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer classification_4 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "step: 10, loss: 1.025661, accuracy: 0.781250\n",
      "step: 20, loss: 0.977135, accuracy: 0.781250\n",
      "step: 30, loss: 0.975504, accuracy: 1.000000\n",
      "step: 40, loss: 0.943703, accuracy: 1.000000\n",
      "step: 50, loss: 0.954870, accuracy: 0.890625\n",
      "step: 60, loss: 0.893557, accuracy: 0.906250\n",
      "step: 70, loss: 0.920396, accuracy: 0.968750\n",
      "step: 80, loss: 0.902006, accuracy: 0.984375\n",
      "step: 90, loss: 0.858667, accuracy: 1.000000\n",
      "step: 100, loss: 0.834314, accuracy: 1.000000\n",
      "step: 110, loss: 0.852035, accuracy: 0.937500\n",
      "step: 120, loss: 0.807706, accuracy: 0.984375\n",
      "step: 130, loss: 0.815920, accuracy: 0.984375\n",
      "step: 140, loss: 0.795545, accuracy: 0.968750\n",
      "step: 150, loss: 0.796471, accuracy: 0.984375\n",
      "step: 160, loss: 0.796791, accuracy: 0.937500\n",
      "step: 170, loss: 0.792184, accuracy: 0.968750\n",
      "step: 180, loss: 0.790510, accuracy: 0.968750\n",
      "step: 190, loss: 0.817588, accuracy: 0.968750\n",
      "step: 200, loss: 0.771460, accuracy: 0.968750\n",
      "Saved checkpoint for step Weights/EWC/CWRU-noise/classifier/training\\ckpt-1\n"
     ]
    }
   ],
   "source": [
    "# Build neural network model.\n",
    "\n",
    "classifier = Training_classifier(conv_net, learning_rate, training_iters, \n",
    "                                 batch_size, display_step, filepath, restore=False)\n",
    "\n",
    "classifier.fit( X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K9mFYSd89A6w"
   },
   "source": [
    "We check the final accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 567,
     "status": "ok",
     "timestamp": 1585911882790,
     "user": {
      "displayName": "Laia Domingo",
      "photoUrl": "",
      "userId": "05713674999451466092"
     },
     "user_tz": -120
    },
    "id": "m6RvHGkZUUZh",
    "outputId": "ea4abd10-04a6-428d-9855-3ef5f4241175"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored from Weights/EWC/CWRU-noise/classifier/training\\ckpt-1\n",
      "WARNING:tensorflow:Layer classification_5 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.fc1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.fc1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.fc2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.fc2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.fc3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.fc3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.out.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.out.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.fc1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.fc1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.fc2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.fc2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.fc3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.fc3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.out.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.out.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Test Accuracy: 0.984716\n"
     ]
    }
   ],
   "source": [
    "# Comment this line to use the model you just trained, and not the loaded weights\n",
    "embedding, conv_net = load_model(\"Weights/EWC/CWRU-noise/classifier/training\")\n",
    "\n",
    "# Test model on test set.\n",
    "pred= conv_net(X_test)\n",
    "y_pred = np.argmax(pred.numpy(), axis=1)\n",
    "print(\"Test Accuracy: %f\" % accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 553,
     "status": "ok",
     "timestamp": 1585911884613,
     "user": {
      "displayName": "Laia Domingo",
      "photoUrl": "",
      "userId": "05713674999451466092"
     },
     "user_tz": -120
    },
    "id": "xQ9TLzMcaezu",
    "outputId": "7a0de6b5-b7e4-42fd-c82f-b3efa9d1104a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[214,   0,   0],\n",
       "       [  0, 116,   6],\n",
       "       [  0,   1, 121]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FMVbB8RaGU4x"
   },
   "source": [
    "Now we test the accuracy on the noisy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 670,
     "status": "ok",
     "timestamp": 1585911887064,
     "user": {
      "displayName": "Laia Domingo",
      "photoUrl": "",
      "userId": "05713674999451466092"
     },
     "user_tz": -120
    },
    "id": "hsBif9c2GSJz",
    "outputId": "31f4e92d-e3d3-449b-939f-5b55fd654e59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.469432\n"
     ]
    }
   ],
   "source": [
    "# Test model on test set.\n",
    "pred= conv_net(X_test_noise)\n",
    "y_pred = np.argmax(pred.numpy(), axis=1)\n",
    "print(\"Test Accuracy: %f\" % accuracy_score(y_pred, y_test_noise))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7JKV2WI7xJQL"
   },
   "source": [
    "We notice that the model has a bad accuracy for noisy data. \n",
    "If this data is thought as a new behaviour that can happen, we want the model to capture both behaviours. For this reason, we will try Elastic weight consolidation approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ywvfYXwVGnrO"
   },
   "source": [
    "## Elastic Weight Consolidation\n",
    "\n",
    "The goal of this technique is to train a model to perform task B without forgetting about task A. In order to do so, we will add a weighted L2 regularization. For more information about EWC refer to the notebook * Elastic weight consolidation- concept drift* or to the Master Thesis pdf.\n",
    "\n",
    "### Fisher information matrix for triplet loss\n",
    "\n",
    "First we create a class that calculates the fisher matrix for an existing model.\n",
    "We will define the two fisher matrices: for the embeddings (triplet loss) and the classifier (cross entropy loss). \n",
    "\n",
    "The fisher information matrix for the embeddings is a bit tricky, since we do not have a loss function for every sample of the dataset, but for every hard/semi-hard triplet. In order to speed up the computations, we will use the batch hard strategy to compute the loss for every hard triplet. We will sample a batch, calculate the hard loss for all the elements of the batch, slice the tensor to get the $ith$ element, calculate its loss function,get the gradients and append the square gradients to a list. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xly5vqtwyQdH"
   },
   "source": [
    "Now we calculate the fisher information matrix for both the embeddings (triplet loss) and the classifier (cross entropy loss).\n",
    "\n",
    "You can skip all these cells (until the validation). The training of EWC may take some hours to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 180703,
     "status": "ok",
     "timestamp": 1585912075106,
     "user": {
      "displayName": "Laia Domingo",
      "photoUrl": "",
      "userId": "05713674999451466092"
     },
     "user_tz": -120
    },
    "id": "r2C-27rOqg7u",
    "outputId": "e15e3025-6bbf-4cb0-c514-c426d2513676"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 12 calls to <function Embedding.call at 0x7f38ad4b0b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).save_counter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "#Triplet loss fisher matrix\n",
    "conv_net.unfreeze()\n",
    "fisher_matrix_TL =  Fisher_matrix(X_train, y_train, embedding, task = 'triplet loss', batch_size = 32,\n",
    "                     triplet_strategy=triplet_strategy, margin=margin, squared = squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aIozUnReERgA"
   },
   "outputs": [],
   "source": [
    "#Cross entropy loss fisher matrix\n",
    "conv_net.freeze()\n",
    "fisher_matrix_CL =  Fisher_matrix(X_train, y_train, conv_net, task = 'classsification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S5IBvgwmyvoc"
   },
   "source": [
    "Now we will train the embeddings with triplet loss and EWC and then the classifier with cross entropy and EWC.\n",
    "\n",
    "## Triplet loss + EWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 604,
     "status": "ok",
     "timestamp": 1585912160277,
     "user": {
      "displayName": "Laia Domingo",
      "photoUrl": "",
      "userId": "05713674999451466092"
     },
     "user_tz": -120
    },
    "id": "ZZPEhwx9IUef",
    "outputId": "e8dc3600-40c8-40fa-f763-9cc065d72c5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10500"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_iters = 500\n",
    "display_step=1\n",
    "learning_rate = 0.0001\n",
    "filepath =\"Weights/EWC/CWRU-noise/fisher/embedding\"\n",
    "lamb = 1000\n",
    "int(num_batches*training_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2504636,
     "status": "ok",
     "timestamp": 1585914814622,
     "user": {
      "displayName": "Laia Domingo",
      "photoUrl": "",
      "userId": "05713674999451466092"
     },
     "user_tz": -120
    },
    "id": "kN9gku4rPUT4",
    "outputId": "27f27370-dbc4-4fb4-86c4-1c29547c3177"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 533 calls to <function Embedding.call at 0x7f38ad4b0b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "step 1 loss 1.42552459 fisher_loss 0.0196445528 triplet loss 1.40588009 l2_loss 0.000499920163 fraction B 0.688044906 lossA 0.427129418 fraction A 0.00572607806\n",
      "step 2 loss 1.33377302 fisher_loss 0.0137187103 triplet loss 1.32005429 l2_loss 0.00153635326 fraction B 0.714368463 lossA 0.413604081 fraction A 0.00585347507\n",
      "step 3 loss 1.24886084 fisher_loss 0.024279831 triplet loss 1.224581 l2_loss 0.00305564608 fraction B 0.732956171 lossA 0.413766086 fraction A 0.00583338458\n",
      "step 4 loss 1.40245092 fisher_loss 0.0288779829 triplet loss 1.37357295 l2_loss 0.00479458692 fraction B 0.718847394 lossA 0.408234298 fraction A 0.0060989568\n",
      "step 5 loss 1.25356853 fisher_loss 0.0326572023 triplet loss 1.22091138 l2_loss 0.00705654547 fraction B 0.642805576 lossA 0.400211036 fraction A 0.00577447051\n",
      "step 6 loss 1.3043083 fisher_loss 0.0374396183 triplet loss 1.26686871 l2_loss 0.00941510685 fraction B 0.711723566 lossA 0.397972941 fraction A 0.00569004\n",
      "step 7 loss 1.27462244 fisher_loss 0.0455957502 triplet loss 1.22902668 l2_loss 0.0121270344 fraction B 0.685948312 lossA 0.39470768 fraction A 0.00553848362\n",
      "step 8 loss 1.26093423 fisher_loss 0.0537369698 triplet loss 1.20719731 l2_loss 0.0151252961 fraction B 0.639425039 lossA 0.389093518 fraction A 0.00541801564\n",
      "step 9 loss 1.45603037 fisher_loss 0.0589966811 triplet loss 1.39703369 l2_loss 0.01821208 fraction B 0.687743306 lossA 0.388379484 fraction A 0.00549243763\n",
      "step 10 loss 1.40673053 fisher_loss 0.0635599643 triplet loss 1.34317052 l2_loss 0.0217190925 fraction B 0.650332153 lossA 0.387658089 fraction A 0.00567130651\n",
      "step 11 loss 1.28637064 fisher_loss 0.0673444346 triplet loss 1.21902621 l2_loss 0.025536865 fraction B 0.612352848 lossA 0.385579646 fraction A 0.00595949823\n",
      "step 12 loss 1.44603801 fisher_loss 0.0708718896 triplet loss 1.37516606 l2_loss 0.0295904037 fraction B 0.713287354 lossA 0.379882127 fraction A 0.00630227849\n",
      "step 13 loss 1.35196471 fisher_loss 0.0743799731 triplet loss 1.27758479 l2_loss 0.0337394401 fraction B 0.661736071 lossA 0.377757072 fraction A 0.00662969751\n",
      "step 14 loss 1.21453977 fisher_loss 0.0788850337 triplet loss 1.13565469 l2_loss 0.037985269 fraction B 0.682905197 lossA 0.374300033 fraction A 0.00692085922\n",
      "step 15 loss 1.29134047 fisher_loss 0.0822423175 triplet loss 1.2090981 l2_loss 0.0424073711 fraction B 0.575924575 lossA 0.367023975 fraction A 0.00697764708\n",
      "step 16 loss 1.35444438 fisher_loss 0.0857859924 triplet loss 1.2686584 l2_loss 0.0468145348 fraction B 0.706493616 lossA 0.361090064 fraction A 0.00698417285\n",
      "step 17 loss 1.26705408 fisher_loss 0.0876078531 triplet loss 1.17944622 l2_loss 0.0512450337 fraction B 0.595325291 lossA 0.356566727 fraction A 0.00696873851\n",
      "step 18 loss 1.27515125 fisher_loss 0.0925434381 triplet loss 1.18260777 l2_loss 0.0561644323 fraction B 0.697502673 lossA 0.353717566 fraction A 0.00697145145\n",
      "step 19 loss 1.37958765 fisher_loss 0.09646184 triplet loss 1.28312576 l2_loss 0.0611972064 fraction B 0.637074232 lossA 0.34785825 fraction A 0.00694791507\n",
      "step 20 loss 1.17753685 fisher_loss 0.099668093 triplet loss 1.0778687 l2_loss 0.0664244 fraction B 0.676531136 lossA 0.347018272 fraction A 0.00713059679\n",
      "step 21 loss 1.32199502 fisher_loss 0.103428602 triplet loss 1.21856642 l2_loss 0.0719195902 fraction B 0.540732384 lossA 0.350565404 fraction A 0.0072932248\n",
      "step 22 loss 1.38123322 fisher_loss 0.107137643 triplet loss 1.27409554 l2_loss 0.0776224062 fraction B 0.641477168 lossA 0.352133036 fraction A 0.00738766324\n",
      "step 23 loss 1.33982992 fisher_loss 0.109741539 triplet loss 1.23008835 l2_loss 0.083338052 fraction B 0.620801032 lossA 0.350737333 fraction A 0.0072176666\n",
      "step 24 loss 1.32038105 fisher_loss 0.109680086 triplet loss 1.21070099 l2_loss 0.0884149745 fraction B 0.645090282 lossA 0.349437535 fraction A 0.00711545581\n",
      "step 25 loss 1.37017488 fisher_loss 0.110026181 triplet loss 1.26014876 l2_loss 0.0937496647 fraction B 0.630418301 lossA 0.347121954 fraction A 0.00694963802\n",
      "step 26 loss 1.34940684 fisher_loss 0.110265762 triplet loss 1.23914111 l2_loss 0.0989892185 fraction B 0.645926714 lossA 0.342128128 fraction A 0.00664208923\n",
      "step 27 loss 1.31995702 fisher_loss 0.110784084 triplet loss 1.20917296 l2_loss 0.104538396 fraction B 0.74352 lossA 0.338750422 fraction A 0.00642685266\n",
      "step 28 loss 1.3011986 fisher_loss 0.110387079 triplet loss 1.19081151 l2_loss 0.109787688 fraction B 0.569503665 lossA 0.333431035 fraction A 0.00626294129\n",
      "step 29 loss 1.27636254 fisher_loss 0.107973441 triplet loss 1.16838908 l2_loss 0.11520908 fraction B 0.5529477 lossA 0.324440122 fraction A 0.0060117403\n",
      "step 30 loss 1.35530865 fisher_loss 0.105896726 triplet loss 1.24941194 l2_loss 0.12049634 fraction B 0.65880233 lossA 0.315135539 fraction A 0.00574176898\n",
      "step 31 loss 1.31306636 fisher_loss 0.103699706 triplet loss 1.20936668 l2_loss 0.125512466 fraction B 0.673988461 lossA 0.310908437 fraction A 0.00569480611\n",
      "step 32 loss 1.36115456 fisher_loss 0.101419158 triplet loss 1.25973535 l2_loss 0.130814686 fraction B 0.705661774 lossA 0.308784217 fraction A 0.00573777268\n",
      "step 33 loss 1.23297882 fisher_loss 0.0996232554 triplet loss 1.13335562 l2_loss 0.136443391 fraction B 0.709756613 lossA 0.311708808 fraction A 0.00599124702\n",
      "step 34 loss 1.19020557 fisher_loss 0.097073935 triplet loss 1.09313166 l2_loss 0.141944498 fraction B 0.705064 lossA 0.320919544 fraction A 0.00640533259\n",
      "step 35 loss 1.41220415 fisher_loss 0.0951939 triplet loss 1.31701028 l2_loss 0.147330478 fraction B 0.760862589 lossA 0.326178402 fraction A 0.00671181828\n",
      "step 36 loss 1.27808166 fisher_loss 0.093031019 triplet loss 1.18505061 l2_loss 0.15227814 fraction B 0.609386206 lossA 0.333767027 fraction A 0.00711472239\n",
      "step 37 loss 1.25651705 fisher_loss 0.0930616334 triplet loss 1.16345537 l2_loss 0.157808229 fraction B 0.662725389 lossA 0.339308321 fraction A 0.00741581898\n",
      "step 38 loss 1.29989696 fisher_loss 0.0936741754 triplet loss 1.20622277 l2_loss 0.163465559 fraction B 0.708713949 lossA 0.343522131 fraction A 0.00762782944\n",
      "step 39 loss 1.25603592 fisher_loss 0.0941333771 triplet loss 1.16190255 l2_loss 0.168908969 fraction B 0.672600746 lossA 0.340761811 fraction A 0.00768927345\n",
      "step 40 loss 1.14088833 fisher_loss 0.0925716534 triplet loss 1.04831672 l2_loss 0.173541278 fraction B 0.597237229 lossA 0.340636134 fraction A 0.00777931279\n",
      "step 41 loss 1.25032687 fisher_loss 0.0915668234 triplet loss 1.15876007 l2_loss 0.178088576 fraction B 0.639516354 lossA 0.336503685 fraction A 0.00780955795\n",
      "step 42 loss 1.33297396 fisher_loss 0.0918523148 triplet loss 1.24112165 l2_loss 0.182682633 fraction B 0.765440643 lossA 0.331347793 fraction A 0.00785105862\n",
      "step 43 loss 1.28913438 fisher_loss 0.0917261764 triplet loss 1.1974082 l2_loss 0.187394068 fraction B 0.663606167 lossA 0.327291578 fraction A 0.00779284071\n",
      "step 44 loss 1.29412007 fisher_loss 0.0915439129 triplet loss 1.20257616 l2_loss 0.192315027 fraction B 0.702633679 lossA 0.323603451 fraction A 0.00775548303\n",
      "step 45 loss 1.23972666 fisher_loss 0.0906598717 triplet loss 1.14906681 l2_loss 0.197000563 fraction B 0.687943399 lossA 0.321549 fraction A 0.00763648143\n",
      "step 46 loss 1.25498104 fisher_loss 0.0889610574 triplet loss 1.16602 l2_loss 0.201692939 fraction B 0.641269147 lossA 0.320497632 fraction A 0.0075592366\n",
      "step 47 loss 1.1994729 fisher_loss 0.0871837437 triplet loss 1.11228919 l2_loss 0.20631054 fraction B 0.578053653 lossA 0.318214655 fraction A 0.00739880838\n",
      "step 48 loss 1.27351594 fisher_loss 0.0870879218 triplet loss 1.18642807 l2_loss 0.211245149 fraction B 0.752824366 lossA 0.313698083 fraction A 0.00718393829\n",
      "step 49 loss 1.18342364 fisher_loss 0.0878540501 triplet loss 1.09556961 l2_loss 0.216451481 fraction B 0.721231639 lossA 0.309724033 fraction A 0.00700213667\n",
      "step 50 loss 1.19101381 fisher_loss 0.0890261531 triplet loss 1.1019876 l2_loss 0.221697673 fraction B 0.652913511 lossA 0.30371353 fraction A 0.00686792098\n",
      "step 51 loss 1.16874647 fisher_loss 0.0914238 triplet loss 1.07732272 l2_loss 0.227002487 fraction B 0.609190762 lossA 0.300818712 fraction A 0.0067688995\n",
      "step 52 loss 1.23689592 fisher_loss 0.094296664 triplet loss 1.14259923 l2_loss 0.232441083 fraction B 0.724883497 lossA 0.300486267 fraction A 0.00675944099\n",
      "step 53 loss 1.20512629 fisher_loss 0.09683685 triplet loss 1.10828948 l2_loss 0.237986207 fraction B 0.651446581 lossA 0.303542823 fraction A 0.0068666744\n",
      "step 54 loss 1.22088146 fisher_loss 0.0989752412 triplet loss 1.12190616 l2_loss 0.243744552 fraction B 0.625919938 lossA 0.309001595 fraction A 0.00716230832\n",
      "step 55 loss 1.29512179 fisher_loss 0.101041824 triplet loss 1.19408 l2_loss 0.249773398 fraction B 0.684481204 lossA 0.312452 fraction A 0.00750219217\n",
      "step 56 loss 1.22416663 fisher_loss 0.10309691 triplet loss 1.12106967 l2_loss 0.2564722 fraction B 0.621121645 lossA 0.313498974 fraction A 0.00788944215\n",
      "step 57 loss 1.19563174 fisher_loss 0.10418798 triplet loss 1.09144378 l2_loss 0.263433278 fraction B 0.636885107 lossA 0.316324383 fraction A 0.00825887453\n",
      "step 58 loss 1.15459454 fisher_loss 0.106135257 triplet loss 1.04845929 l2_loss 0.270690203 fraction B 0.557817221 lossA 0.321315974 fraction A 0.00867417082\n",
      "step 59 loss 1.21891701 fisher_loss 0.109744906 triplet loss 1.10917211 l2_loss 0.278918236 fraction B 0.733519852 lossA 0.323800325 fraction A 0.00889322\n",
      "step 60 loss 1.27481663 fisher_loss 0.113048904 triplet loss 1.16176772 l2_loss 0.286477387 fraction B 0.622423589 lossA 0.32411018 fraction A 0.00915728882\n",
      "step 61 loss 1.35251343 fisher_loss 0.115892336 triplet loss 1.23662114 l2_loss 0.294229656 fraction B 0.694782197 lossA 0.321624815 fraction A 0.00934986863\n",
      "step 62 loss 1.28622282 fisher_loss 0.116741635 triplet loss 1.16948116 l2_loss 0.30167371 fraction B 0.652358711 lossA 0.318611979 fraction A 0.00961415749\n",
      "step 63 loss 1.1187458 fisher_loss 0.116218738 triplet loss 1.00252712 l2_loss 0.308696032 fraction B 0.57541889 lossA 0.314762831 fraction A 0.00991320144\n",
      "step 64 loss 1.17705655 fisher_loss 0.115681849 triplet loss 1.06137466 l2_loss 0.315529376 fraction B 0.713241935 lossA 0.309848666 fraction A 0.00996581\n",
      "step 65 loss 1.1641202 fisher_loss 0.115594096 triplet loss 1.04852605 l2_loss 0.322411358 fraction B 0.667083502 lossA 0.306655765 fraction A 0.0101655386\n",
      "step 66 loss 1.24668157 fisher_loss 0.115733542 triplet loss 1.13094807 l2_loss 0.329487711 fraction B 0.694584846 lossA 0.302164167 fraction A 0.0103310263\n",
      "step 67 loss 1.24141014 fisher_loss 0.114941433 triplet loss 1.12646866 l2_loss 0.336757302 fraction B 0.739924848 lossA 0.300092816 fraction A 0.0105818613\n",
      "step 68 loss 1.20324707 fisher_loss 0.113303274 triplet loss 1.08994377 l2_loss 0.344119072 fraction B 0.671407282 lossA 0.298413217 fraction A 0.0106404088\n",
      "step 69 loss 1.11956346 fisher_loss 0.1117028 triplet loss 1.00786066 l2_loss 0.351501 fraction B 0.664424777 lossA 0.295397192 fraction A 0.0104077579\n",
      "step 70 loss 1.1210146 fisher_loss 0.110724561 triplet loss 1.01029 l2_loss 0.358831137 fraction B 0.646128774 lossA 0.291706145 fraction A 0.0100539429\n",
      "step 71 loss 1.3220886 fisher_loss 0.109831564 triplet loss 1.21225703 l2_loss 0.365793169 fraction B 0.739956558 lossA 0.286966264 fraction A 0.00978349522\n",
      "step 72 loss 1.24048209 fisher_loss 0.108982086 triplet loss 1.1315 l2_loss 0.372703612 fraction B 0.681657851 lossA 0.282355249 fraction A 0.00955836\n",
      "step 73 loss 1.27090096 fisher_loss 0.108091705 triplet loss 1.16280925 l2_loss 0.379894584 fraction B 0.801398635 lossA 0.278154939 fraction A 0.00939734466\n",
      "step 74 loss 1.22561193 fisher_loss 0.10743615 triplet loss 1.11817575 l2_loss 0.387748599 fraction B 0.650787234 lossA 0.275293171 fraction A 0.0092977006\n",
      "step 75 loss 1.0915134 fisher_loss 0.107395217 triplet loss 0.984118223 l2_loss 0.395808041 fraction B 0.706933 lossA 0.271914303 fraction A 0.00896195881\n",
      "step 76 loss 1.16499424 fisher_loss 0.108147316 triplet loss 1.05684698 l2_loss 0.403163016 fraction B 0.6103549 lossA 0.272869647 fraction A 0.00886502769\n",
      "step 77 loss 1.23725462 fisher_loss 0.109729469 triplet loss 1.12752509 l2_loss 0.411298513 fraction B 0.72135222 lossA 0.275578827 fraction A 0.00896951091\n",
      "step 78 loss 1.01949894 fisher_loss 0.110460192 triplet loss 0.909038782 l2_loss 0.419986337 fraction B 0.665360808 lossA 0.277660668 fraction A 0.0093203932\n",
      "step 79 loss 1.19585097 fisher_loss 0.111498944 triplet loss 1.08435202 l2_loss 0.428997 fraction B 0.694929659 lossA 0.280291617 fraction A 0.00969895441\n",
      "step 80 loss 1.32507145 fisher_loss 0.112315156 triplet loss 1.21275628 l2_loss 0.437874913 fraction B 0.614709377 lossA 0.280493826 fraction A 0.0101871323\n",
      "step 81 loss 1.12119198 fisher_loss 0.113228858 triplet loss 1.00796306 l2_loss 0.446847886 fraction B 0.655060291 lossA 0.280974388 fraction A 0.010543\n",
      "step 82 loss 1.07019758 fisher_loss 0.113170445 triplet loss 0.957027197 l2_loss 0.455321759 fraction B 0.58042413 lossA 0.281393975 fraction A 0.0109569766\n",
      "step 83 loss 1.09014356 fisher_loss 0.11369399 triplet loss 0.976449549 l2_loss 0.463724494 fraction B 0.660433352 lossA 0.284392327 fraction A 0.0113809966\n",
      "step 84 loss 1.1888386 fisher_loss 0.11428985 triplet loss 1.07454872 l2_loss 0.471415937 fraction B 0.769827187 lossA 0.285660446 fraction A 0.0116281649\n",
      "step 85 loss 1.24714673 fisher_loss 0.113871306 triplet loss 1.13327539 l2_loss 0.478588104 fraction B 0.740955889 lossA 0.286334604 fraction A 0.0119312052\n",
      "step 86 loss 1.0621736 fisher_loss 0.114351414 triplet loss 0.947822213 l2_loss 0.48594895 fraction B 0.580445886 lossA 0.28658554 fraction A 0.0121378629\n",
      "step 87 loss 1.2658993 fisher_loss 0.11636658 triplet loss 1.14953268 l2_loss 0.493561506 fraction B 0.633417428 lossA 0.286356896 fraction A 0.0122259958\n",
      "step 88 loss 1.23390806 fisher_loss 0.117644213 triplet loss 1.11626387 l2_loss 0.500711262 fraction B 0.660206318 lossA 0.284370691 fraction A 0.011933405\n",
      "step 89 loss 1.13437915 fisher_loss 0.117961653 triplet loss 1.0164175 l2_loss 0.507256687 fraction B 0.656841516 lossA 0.284165144 fraction A 0.011481815\n",
      "step 90 loss 1.14445448 fisher_loss 0.117740281 triplet loss 1.02671421 l2_loss 0.513719797 fraction B 0.705693126 lossA 0.28505367 fraction A 0.0109633915\n",
      "step 91 loss 1.08635306 fisher_loss 0.117520012 triplet loss 0.968833089 l2_loss 0.520135045 fraction B 0.7336092 lossA 0.288607299 fraction A 0.0106871882\n",
      "step 92 loss 1.10752296 fisher_loss 0.116647974 triplet loss 0.990874946 l2_loss 0.527137637 fraction B 0.610556364 lossA 0.292731553 fraction A 0.0106675746\n",
      "step 93 loss 0.855915248 fisher_loss 0.115379862 triplet loss 0.740535378 l2_loss 0.534713387 fraction B 0.450685084 lossA 0.299573 fraction A 0.0107883727\n",
      "step 94 loss 1.179425 fisher_loss 0.115419917 triplet loss 1.06400514 l2_loss 0.542354345 fraction B 0.611263514 lossA 0.30684042 fraction A 0.0109093906\n",
      "step 95 loss 1.16448689 fisher_loss 0.11585255 triplet loss 1.04863429 l2_loss 0.550128281 fraction B 0.710045338 lossA 0.314745128 fraction A 0.0111982422\n",
      "step 96 loss 1.21016169 fisher_loss 0.116378918 triplet loss 1.09378278 l2_loss 0.558178306 fraction B 0.608879507 lossA 0.32246533 fraction A 0.0116367443\n",
      "step 97 loss 1.14187229 fisher_loss 0.117442824 triplet loss 1.02442944 l2_loss 0.56671077 fraction B 0.683175266 lossA 0.329191655 fraction A 0.0120312897\n",
      "step 98 loss 1.14757502 fisher_loss 0.117841512 triplet loss 1.02973354 l2_loss 0.575614452 fraction B 0.62434876 lossA 0.334638804 fraction A 0.0123847378\n",
      "step 99 loss 1.16953611 fisher_loss 0.118729025 triplet loss 1.05080712 l2_loss 0.583578348 fraction B 0.575224102 lossA 0.340330184 fraction A 0.0128509188\n",
      "step 100 loss 1.12563121 fisher_loss 0.11916361 triplet loss 1.00646758 l2_loss 0.591899037 fraction B 0.591995776 lossA 0.344087034 fraction A 0.0130372662\n",
      "step 101 loss 1.20316625 fisher_loss 0.117754452 triplet loss 1.08541179 l2_loss 0.599910378 fraction B 0.642142773 lossA 0.34346962 fraction A 0.0131651405\n",
      "step 102 loss 1.14478326 fisher_loss 0.116579473 triplet loss 1.02820373 l2_loss 0.60786736 fraction B 0.570337594 lossA 0.340612024 fraction A 0.0132663613\n",
      "step 103 loss 1.13380551 fisher_loss 0.11601764 triplet loss 1.01778781 l2_loss 0.61710149 fraction B 0.566782773 lossA 0.336129725 fraction A 0.0133794239\n",
      "step 104 loss 1.12490892 fisher_loss 0.116681315 triplet loss 1.00822759 l2_loss 0.626681089 fraction B 0.527423143 lossA 0.327914178 fraction A 0.0133404527\n",
      "step 105 loss 1.10335469 fisher_loss 0.118865557 triplet loss 0.984489143 l2_loss 0.636876106 fraction B 0.596467137 lossA 0.324182063 fraction A 0.0138017209\n",
      "step 106 loss 1.18721223 fisher_loss 0.122365408 triplet loss 1.06484687 l2_loss 0.648248732 fraction B 0.588183582 lossA 0.324710757 fraction A 0.0143719092\n",
      "step 107 loss 1.00083697 fisher_loss 0.124525703 triplet loss 0.876311243 l2_loss 0.659176767 fraction B 0.54992789 lossA 0.325947195 fraction A 0.0149879605\n",
      "step 108 loss 0.94605875 fisher_loss 0.125806183 triplet loss 0.820252597 l2_loss 0.670564234 fraction B 0.418108672 lossA 0.326300889 fraction A 0.0154556809\n",
      "step 109 loss 1.0894258 fisher_loss 0.127873465 triplet loss 0.961552322 l2_loss 0.681194901 fraction B 0.70537 lossA 0.329976052 fraction A 0.015949212\n",
      "step 110 loss 1.02250278 fisher_loss 0.129848137 triplet loss 0.892654657 l2_loss 0.690980136 fraction B 0.617942154 lossA 0.331886441 fraction A 0.0158153623\n",
      "step 111 loss 0.956389129 fisher_loss 0.13253285 triplet loss 0.823856294 l2_loss 0.700433135 fraction B 0.496085525 lossA 0.338405877 fraction A 0.0163185708\n",
      "step 112 loss 1.18926859 fisher_loss 0.138197199 triplet loss 1.05107141 l2_loss 0.711166918 fraction B 0.655202568 lossA 0.342858046 fraction A 0.016572997\n",
      "step 113 loss 1.16203833 fisher_loss 0.139653102 triplet loss 1.02238524 l2_loss 0.721553147 fraction B 0.558502197 lossA 0.347877592 fraction A 0.0170101803\n",
      "step 114 loss 1.27447701 fisher_loss 0.140615121 triplet loss 1.1338619 l2_loss 0.732960045 fraction B 0.567575276 lossA 0.352462053 fraction A 0.0175255239\n",
      "step 115 loss 1.2079649 fisher_loss 0.14053458 triplet loss 1.06743026 l2_loss 0.744211316 fraction B 0.540162385 lossA 0.357222319 fraction A 0.0179559961\n",
      "step 116 loss 1.02254963 fisher_loss 0.140424654 triplet loss 0.882125 l2_loss 0.755251527 fraction B 0.58885181 lossA 0.360184491 fraction A 0.0181050599\n",
      "step 117 loss 1.1256566 fisher_loss 0.140929803 triplet loss 0.984726787 l2_loss 0.765781462 fraction B 0.56097877 lossA 0.365073 fraction A 0.0185448825\n",
      "step 118 loss 1.15069199 fisher_loss 0.141738072 triplet loss 1.00895393 l2_loss 0.777435243 fraction B 0.63314575 lossA 0.370409936 fraction A 0.018989617\n",
      "step 119 loss 1.14899397 fisher_loss 0.141535163 triplet loss 1.00745881 l2_loss 0.788495481 fraction B 0.651904702 lossA 0.372228414 fraction A 0.0194101185\n",
      "step 120 loss 1.10393345 fisher_loss 0.140968159 triplet loss 0.96296525 l2_loss 0.79987 fraction B 0.585928202 lossA 0.374789119 fraction A 0.0199601427\n",
      "step 121 loss 1.13481069 fisher_loss 0.141665861 triplet loss 0.99314487 l2_loss 0.810716867 fraction B 0.497052372 lossA 0.37346983 fraction A 0.0203544311\n",
      "step 122 loss 1.03280091 fisher_loss 0.140888631 triplet loss 0.891912341 l2_loss 0.820856452 fraction B 0.490343 lossA 0.379870862 fraction A 0.0216608811\n",
      "step 123 loss 1.05862904 fisher_loss 0.143728226 triplet loss 0.91490078 l2_loss 0.832117617 fraction B 0.525153816 lossA 0.38942349 fraction A 0.0236614719\n",
      "step 124 loss 1.0720036 fisher_loss 0.147769079 triplet loss 0.924234509 l2_loss 0.844290614 fraction B 0.567908823 lossA 0.400173098 fraction A 0.0259553846\n",
      "step 125 loss 1.03911364 fisher_loss 0.151980639 triplet loss 0.887133 l2_loss 0.857332051 fraction B 0.539701521 lossA 0.400751293 fraction A 0.0267268792\n",
      "step 126 loss 1.05569518 fisher_loss 0.15187411 triplet loss 0.903821111 l2_loss 0.870880723 fraction B 0.631473064 lossA 0.405651033 fraction A 0.027784327\n",
      "step 127 loss 1.13761282 fisher_loss 0.152452052 triplet loss 0.985160828 l2_loss 0.884015501 fraction B 0.52385062 lossA 0.408711672 fraction A 0.0285506155\n",
      "step 128 loss 1.0594368 fisher_loss 0.1529838 triplet loss 0.906452954 l2_loss 0.896438062 fraction B 0.524955332 lossA 0.411390871 fraction A 0.0289341267\n",
      "step 129 loss 1.20447636 fisher_loss 0.153168544 triplet loss 1.0513078 l2_loss 0.908372223 fraction B 0.515980124 lossA 0.413408816 fraction A 0.0288958158\n",
      "step 130 loss 1.17600834 fisher_loss 0.153957561 triplet loss 1.02205074 l2_loss 0.919700921 fraction B 0.557700634 lossA 0.417521209 fraction A 0.0292288065\n",
      "step 131 loss 1.18122292 fisher_loss 0.154795527 triplet loss 1.02642739 l2_loss 0.931043804 fraction B 0.439598888 lossA 0.419024557 fraction A 0.0290909987\n",
      "step 132 loss 1.06736791 fisher_loss 0.155063778 triplet loss 0.912304103 l2_loss 0.941534102 fraction B 0.528930426 lossA 0.419415504 fraction A 0.0287163593\n",
      "step 133 loss 1.05027568 fisher_loss 0.154451728 triplet loss 0.895823956 l2_loss 0.95211935 fraction B 0.438679427 lossA 0.425495595 fraction A 0.029059764\n",
      "step 134 loss 1.03075349 fisher_loss 0.156531 triplet loss 0.874222457 l2_loss 0.963749945 fraction B 0.499470979 lossA 0.442843616 fraction A 0.0306480266\n",
      "step 135 loss 1.10713387 fisher_loss 0.161944479 triplet loss 0.945189416 l2_loss 0.976756275 fraction B 0.542110562 lossA 0.460015655 fraction A 0.0322332829\n",
      "step 136 loss 1.12728906 fisher_loss 0.166532531 triplet loss 0.960756481 l2_loss 0.98927784 fraction B 0.478696883 lossA 0.479971528 fraction A 0.0335436203\n",
      "step 137 loss 1.14643073 fisher_loss 0.171690732 triplet loss 0.97474 l2_loss 1.00191331 fraction B 0.541766703 lossA 0.486953259 fraction A 0.0336478464\n",
      "step 138 loss 1.09412217 fisher_loss 0.172317982 triplet loss 0.92180419 l2_loss 1.01330876 fraction B 0.419434488 lossA 0.497231424 fraction A 0.03397974\n",
      "step 139 loss 1.11290753 fisher_loss 0.173397228 triplet loss 0.939510345 l2_loss 1.02531397 fraction B 0.537271142 lossA 0.499033123 fraction A 0.0339253359\n",
      "step 140 loss 1.22880363 fisher_loss 0.171875149 triplet loss 1.05692852 l2_loss 1.03793037 fraction B 0.545099556 lossA 0.487407058 fraction A 0.0335325114\n",
      "step 141 loss 1.18357599 fisher_loss 0.167668104 triplet loss 1.01590788 l2_loss 1.04956627 fraction B 0.491514921 lossA 0.46400708 fraction A 0.03252507\n",
      "step 142 loss 1.11171067 fisher_loss 0.163061246 triplet loss 0.948649406 l2_loss 1.05951905 fraction B 0.517373264 lossA 0.450633526 fraction A 0.0324698575\n",
      "step 143 loss 1.22680366 fisher_loss 0.162169218 triplet loss 1.06463444 l2_loss 1.06970298 fraction B 0.474958301 lossA 0.437935621 fraction A 0.0323170535\n",
      "step 144 loss 1.07771409 fisher_loss 0.160610676 triplet loss 0.91710341 l2_loss 1.07856965 fraction B 0.503413498 lossA 0.427224457 fraction A 0.03201079\n",
      "step 145 loss 1.09549379 fisher_loss 0.162323132 triplet loss 0.933170676 l2_loss 1.08691299 fraction B 0.417170435 lossA 0.4231444 fraction A 0.032165572\n",
      "step 146 loss 1.01709151 fisher_loss 0.163725615 triplet loss 0.853365958 l2_loss 1.095788 fraction B 0.456593663 lossA 0.424046487 fraction A 0.0326304697\n",
      "step 147 loss 1.03912973 fisher_loss 0.166893736 triplet loss 0.872236 l2_loss 1.10549569 fraction B 0.522467852 lossA 0.426310241 fraction A 0.0330610871\n",
      "step 148 loss 1.11376369 fisher_loss 0.169131011 triplet loss 0.944632649 l2_loss 1.11584485 fraction B 0.511055529 lossA 0.429171979 fraction A 0.0336376205\n",
      "step 149 loss 1.07724166 fisher_loss 0.169012606 triplet loss 0.908229053 l2_loss 1.12597775 fraction B 0.418109119 lossA 0.437338382 fraction A 0.0349886864\n",
      "step 150 loss 1.04301071 fisher_loss 0.169582441 triplet loss 0.873428226 l2_loss 1.13569331 fraction B 0.516703904 lossA 0.447435498 fraction A 0.036657054\n",
      "step 151 loss 1.06805 fisher_loss 0.17001006 triplet loss 0.89804 l2_loss 1.14628673 fraction B 0.443909109 lossA 0.459089309 fraction A 0.0379694812\n",
      "step 152 loss 1.09603119 fisher_loss 0.170044109 triplet loss 0.925987124 l2_loss 1.15677762 fraction B 0.525393128 lossA 0.467280895 fraction A 0.0382238\n",
      "step 153 loss 1.2336694 fisher_loss 0.168535858 triplet loss 1.06513357 l2_loss 1.16701925 fraction B 0.498748809 lossA 0.476376593 fraction A 0.0383693427\n",
      "step 154 loss 1.20713186 fisher_loss 0.166344106 triplet loss 1.0407877 l2_loss 1.17700446 fraction B 0.520328283 lossA 0.48294434 fraction A 0.0383975357\n",
      "step 155 loss 1.10915041 fisher_loss 0.163520008 triplet loss 0.945630372 l2_loss 1.18622768 fraction B 0.559835196 lossA 0.487254441 fraction A 0.0383052938\n",
      "step 156 loss 1.03750896 fisher_loss 0.160867631 triplet loss 0.876641333 l2_loss 1.19614232 fraction B 0.546869934 lossA 0.489222378 fraction A 0.0383136161\n",
      "step 157 loss 1.05515552 fisher_loss 0.15904136 triplet loss 0.896114171 l2_loss 1.20532382 fraction B 0.414808899 lossA 0.490614861 fraction A 0.0381178483\n",
      "step 158 loss 1.01803982 fisher_loss 0.15783076 triplet loss 0.860209048 l2_loss 1.21512723 fraction B 0.448852867 lossA 0.489624381 fraction A 0.0378239\n",
      "step 159 loss 1.19091749 fisher_loss 0.155114 triplet loss 1.03580344 l2_loss 1.22519696 fraction B 0.546194553 lossA 0.482923239 fraction A 0.0372698419\n",
      "step 160 loss 1.21417522 fisher_loss 0.151160046 triplet loss 1.06301522 l2_loss 1.23441195 fraction B 0.530267715 lossA 0.479305327 fraction A 0.0373210199\n",
      "step 161 loss 0.94435364 fisher_loss 0.149255693 triplet loss 0.795097947 l2_loss 1.2422365 fraction B 0.224038422 lossA 0.479046226 fraction A 0.0371665321\n",
      "step 162 loss 1.15402222 fisher_loss 0.149931699 triplet loss 1.00409055 l2_loss 1.24747956 fraction B 0.498255849 lossA 0.475990772 fraction A 0.0365831442\n",
      "step 163 loss 1.11252451 fisher_loss 0.150725886 triplet loss 0.961798668 l2_loss 1.25317895 fraction B 0.487194777 lossA 0.470961571 fraction A 0.0359345414\n",
      "step 164 loss 1.0928421 fisher_loss 0.150239721 triplet loss 0.942602336 l2_loss 1.25914383 fraction B 0.44851163 lossA 0.472652316 fraction A 0.0360997692\n",
      "step 165 loss 1.13097107 fisher_loss 0.152258024 triplet loss 0.978713036 l2_loss 1.26492107 fraction B 0.446430534 lossA 0.473514944 fraction A 0.0364032499\n",
      "step 166 loss 1.1699934 fisher_loss 0.15334253 triplet loss 1.01665092 l2_loss 1.27092481 fraction B 0.319086164 lossA 0.471676916 fraction A 0.0366625898\n",
      "step 167 loss 1.09064507 fisher_loss 0.150022417 triplet loss 0.940622628 l2_loss 1.27747273 fraction B 0.417152435 lossA 0.461334378 fraction A 0.0360833108\n",
      "step 168 loss 0.987389922 fisher_loss 0.14411436 triplet loss 0.843275547 l2_loss 1.28420842 fraction B 0.457086235 lossA 0.451558203 fraction A 0.0353365242\n",
      "step 169 loss 0.967089295 fisher_loss 0.139370605 triplet loss 0.827718675 l2_loss 1.29199493 fraction B 0.548984289 lossA 0.448997766 fraction A 0.0352445431\n",
      "step 170 loss 0.98259753 fisher_loss 0.13783516 triplet loss 0.844762385 l2_loss 1.30085289 fraction B 0.529170275 lossA 0.448797435 fraction A 0.0353065021\n",
      "step 171 loss 1.04900765 fisher_loss 0.136860967 triplet loss 0.912146628 l2_loss 1.31208229 fraction B 0.483016849 lossA 0.451153368 fraction A 0.0357795\n",
      "step 172 loss 1.08812273 fisher_loss 0.136375442 triplet loss 0.951747298 l2_loss 1.32322598 fraction B 0.504405141 lossA 0.451156348 fraction A 0.0356335156\n",
      "step 173 loss 1.02732635 fisher_loss 0.135904193 triplet loss 0.891422093 l2_loss 1.33431041 fraction B 0.358074307 lossA 0.458121419 fraction A 0.0352633856\n",
      "step 174 loss 1.0088985 fisher_loss 0.136030793 triplet loss 0.872867763 l2_loss 1.34454727 fraction B 0.461961627 lossA 0.475849032 fraction A 0.0358087197\n",
      "step 175 loss 1.14397717 fisher_loss 0.13896066 triplet loss 1.00501645 l2_loss 1.35495949 fraction B 0.499495983 lossA 0.494383514 fraction A 0.0364073925\n",
      "step 176 loss 0.971140385 fisher_loss 0.141909212 triplet loss 0.829231143 l2_loss 1.36519945 fraction B 0.464614838 lossA 0.516955197 fraction A 0.0371252149\n",
      "step 177 loss 1.07776904 fisher_loss 0.145411357 triplet loss 0.932357669 l2_loss 1.37519896 fraction B 0.446634501 lossA 0.526716948 fraction A 0.0371358097\n",
      "step 178 loss 1.29857409 fisher_loss 0.146013126 triplet loss 1.15256095 l2_loss 1.38604712 fraction B 0.473872572 lossA 0.526403666 fraction A 0.0365805812\n",
      "step 179 loss 1.1755985 fisher_loss 0.145199671 triplet loss 1.03039885 l2_loss 1.39530146 fraction B 0.380219668 lossA 0.523810565 fraction A 0.0362295881\n",
      "step 180 loss 0.980136096 fisher_loss 0.143778265 triplet loss 0.836357832 l2_loss 1.40465438 fraction B 0.476158351 lossA 0.515388489 fraction A 0.0357452966\n",
      "step 181 loss 1.09416127 fisher_loss 0.141335547 triplet loss 0.952825785 l2_loss 1.41407859 fraction B 0.448238373 lossA 0.508805215 fraction A 0.0356874429\n",
      "step 182 loss 0.964137554 fisher_loss 0.140034661 triplet loss 0.824102879 l2_loss 1.42375696 fraction B 0.482662976 lossA 0.498955578 fraction A 0.0358313024\n",
      "step 183 loss 1.14783156 fisher_loss 0.13988705 triplet loss 1.00794446 l2_loss 1.43349171 fraction B 0.501262844 lossA 0.485839307 fraction A 0.035747055\n",
      "step 184 loss 1.22612929 fisher_loss 0.139901191 triplet loss 1.08622813 l2_loss 1.44281948 fraction B 0.370504797 lossA 0.47109586 fraction A 0.0352228023\n",
      "step 185 loss 1.11570168 fisher_loss 0.139197037 triplet loss 0.976504624 l2_loss 1.45160592 fraction B 0.486606508 lossA 0.460985422 fraction A 0.0346622579\n",
      "step 186 loss 1.02627766 fisher_loss 0.137407824 triplet loss 0.888869822 l2_loss 1.46088576 fraction B 0.40350455 lossA 0.461606324 fraction A 0.0351982787\n",
      "step 187 loss 1.12117 fisher_loss 0.138964415 triplet loss 0.982205689 l2_loss 1.47186172 fraction B 0.445587695 lossA 0.464233428 fraction A 0.035679087\n",
      "step 188 loss 1.14374089 fisher_loss 0.139816478 triplet loss 1.00392437 l2_loss 1.4826 fraction B 0.557505429 lossA 0.467977256 fraction A 0.0362628736\n",
      "step 189 loss 1.21057773 fisher_loss 0.140675366 triplet loss 1.0699023 l2_loss 1.49330139 fraction B 0.427812487 lossA 0.47282958 fraction A 0.0360236615\n",
      "step 190 loss 1.14231086 fisher_loss 0.139297411 triplet loss 1.00301349 l2_loss 1.50267422 fraction B 0.42989403 lossA 0.479943931 fraction A 0.0361197144\n",
      "step 191 loss 1.09238803 fisher_loss 0.139034346 triplet loss 0.953353703 l2_loss 1.51193392 fraction B 0.476819277 lossA 0.495186388 fraction A 0.0370423608\n",
      "step 192 loss 1.18330431 fisher_loss 0.139997631 triplet loss 1.04330671 l2_loss 1.52113628 fraction B 0.349141657 lossA 0.511069894 fraction A 0.0379700661\n",
      "step 193 loss 1.13950861 fisher_loss 0.140774071 triplet loss 0.998734534 l2_loss 1.52962196 fraction B 0.393982083 lossA 0.523585379 fraction A 0.0383917801\n",
      "step 194 loss 1.27194953 fisher_loss 0.142422587 triplet loss 1.12952697 l2_loss 1.53789496 fraction B 0.501152933 lossA 0.520402491 fraction A 0.0383975\n",
      "step 195 loss 1.0701952 fisher_loss 0.14122276 triplet loss 0.928972423 l2_loss 1.54535377 fraction B 0.456910819 lossA 0.512859643 fraction A 0.0382637568\n",
      "step 196 loss 1.12329531 fisher_loss 0.138554752 triplet loss 0.984740496 l2_loss 1.55251241 fraction B 0.429596245 lossA 0.500168622 fraction A 0.0380186439\n",
      "step 197 loss 1.08286178 fisher_loss 0.136311352 triplet loss 0.946550429 l2_loss 1.55873215 fraction B 0.469736844 lossA 0.494019568 fraction A 0.0383275114\n",
      "step 198 loss 1.13921607 fisher_loss 0.137151152 triplet loss 1.00206494 l2_loss 1.5657897 fraction B 0.440178931 lossA 0.484923303 fraction A 0.0377661586\n",
      "step 199 loss 1.11966753 fisher_loss 0.136641026 triplet loss 0.983026505 l2_loss 1.5731647 fraction B 0.400215894 lossA 0.485575587 fraction A 0.0382956155\n",
      "step 200 loss 1.0722487 fisher_loss 0.137142047 triplet loss 0.935106635 l2_loss 1.58085024 fraction B 0.440817952 lossA 0.487063408 fraction A 0.0390920751\n",
      "step 201 loss 1.09047246 fisher_loss 0.134873196 triplet loss 0.955599248 l2_loss 1.59053051 fraction B 0.469927222 lossA 0.497230321 fraction A 0.0403003842\n",
      "step 202 loss 0.97520417 fisher_loss 0.133673847 triplet loss 0.841530323 l2_loss 1.5993793 fraction B 0.326937735 lossA 0.516575396 fraction A 0.0413542055\n",
      "step 203 loss 1.0232023 fisher_loss 0.134838432 triplet loss 0.888363898 l2_loss 1.61028397 fraction B 0.330108732 lossA 0.544971585 fraction A 0.0413920768\n",
      "step 204 loss 1.01785 fisher_loss 0.1397333 triplet loss 0.878116786 l2_loss 1.62360489 fraction B 0.374135822 lossA 0.575181484 fraction A 0.0414083898\n",
      "step 205 loss 1.07030165 fisher_loss 0.1456801 triplet loss 0.924621582 l2_loss 1.63750339 fraction B 0.439161479 lossA 0.588857055 fraction A 0.0412159935\n",
      "step 206 loss 1.16459846 fisher_loss 0.147956923 triplet loss 1.0166415 l2_loss 1.65059745 fraction B 0.52239722 lossA 0.585544348 fraction A 0.0409378111\n",
      "step 207 loss 1.05057895 fisher_loss 0.146610633 triplet loss 0.903968334 l2_loss 1.66278422 fraction B 0.398341835 lossA 0.57095 fraction A 0.0403384045\n",
      "step 208 loss 1.19463098 fisher_loss 0.141595334 triplet loss 1.05303562 l2_loss 1.67469966 fraction B 0.390849322 lossA 0.546424568 fraction A 0.0399552956\n",
      "step 209 loss 1.0309149 fisher_loss 0.13489072 triplet loss 0.896024168 l2_loss 1.68604922 fraction B 0.367328584 lossA 0.523344636 fraction A 0.0401254743\n",
      "step 210 loss 1.03923976 fisher_loss 0.129708692 triplet loss 0.909531057 l2_loss 1.6976 fraction B 0.382265121 lossA 0.510238767 fraction A 0.0414147675\n",
      "step 211 loss 1.07355487 fisher_loss 0.12774244 triplet loss 0.945812404 l2_loss 1.70957577 fraction B 0.433636755 lossA 0.498945028 fraction A 0.0423170328\n",
      "step 212 loss 1.09203517 fisher_loss 0.127714649 triplet loss 0.964320481 l2_loss 1.72158885 fraction B 0.47409609 lossA 0.494665444 fraction A 0.0436483771\n",
      "step 213 loss 1.04868317 fisher_loss 0.128274396 triplet loss 0.920408785 l2_loss 1.7335887 fraction B 0.368321508 lossA 0.494331598 fraction A 0.0445723049\n",
      "step 214 loss 1.08002722 fisher_loss 0.128251523 triplet loss 0.95177567 l2_loss 1.74620008 fraction B 0.407384 lossA 0.498912513 fraction A 0.0452153\n",
      "step 215 loss 0.930983901 fisher_loss 0.128222376 triplet loss 0.802761495 l2_loss 1.75908113 fraction B 0.400104553 lossA 0.51192534 fraction A 0.046144329\n",
      "step 216 loss 0.947838783 fisher_loss 0.129746273 triplet loss 0.818092525 l2_loss 1.77212489 fraction B 0.333743 lossA 0.524518728 fraction A 0.0464089848\n",
      "step 217 loss 1.2337997 fisher_loss 0.13088204 triplet loss 1.10291767 l2_loss 1.7846905 fraction B 0.422884405 lossA 0.530932963 fraction A 0.0466449335\n",
      "step 218 loss 1.06130338 fisher_loss 0.13123478 triplet loss 0.930068552 l2_loss 1.79586136 fraction B 0.396677226 lossA 0.540496588 fraction A 0.0472458079\n",
      "step 219 loss 1.07628608 fisher_loss 0.133198217 triplet loss 0.943087876 l2_loss 1.80601144 fraction B 0.461239189 lossA 0.552436292 fraction A 0.0480854921\n",
      "step 220 loss 0.937134266 fisher_loss 0.135614485 triplet loss 0.801519752 l2_loss 1.81625462 fraction B 0.352805346 lossA 0.569535375 fraction A 0.0498045981\n",
      "step 221 loss 0.953872085 fisher_loss 0.137650356 triplet loss 0.816221714 l2_loss 1.82735264 fraction B 0.33292526 lossA 0.584522307 fraction A 0.0510611869\n",
      "step 222 loss 1.26458895 fisher_loss 0.138869688 triplet loss 1.12571931 l2_loss 1.83869851 fraction B 0.391883105 lossA 0.600037217 fraction A 0.0518823229\n",
      "step 223 loss 1.0444541 fisher_loss 0.139412671 triplet loss 0.905041456 l2_loss 1.84962416 fraction B 0.361671776 lossA 0.600486457 fraction A 0.0532401353\n",
      "step 224 loss 1.12504804 fisher_loss 0.138652697 triplet loss 0.986395359 l2_loss 1.86180437 fraction B 0.408237606 lossA 0.600547075 fraction A 0.0544405244\n",
      "step 225 loss 1.02731895 fisher_loss 0.139022321 triplet loss 0.888296604 l2_loss 1.87313735 fraction B 0.327304751 lossA 0.592115 fraction A 0.0547146387\n",
      "step 226 loss 0.995907664 fisher_loss 0.13785024 triplet loss 0.858057439 l2_loss 1.88297 fraction B 0.287065834 lossA 0.584442258 fraction A 0.0534100197\n",
      "step 227 loss 1.12913799 fisher_loss 0.134792387 triplet loss 0.994345605 l2_loss 1.89384115 fraction B 0.36358285 lossA 0.56559819 fraction A 0.052339118\n",
      "step 228 loss 0.923567653 fisher_loss 0.131712049 triplet loss 0.791855633 l2_loss 1.90546679 fraction B 0.385779321 lossA 0.554946542 fraction A 0.0514889136\n",
      "step 229 loss 1.02481019 fisher_loss 0.129744455 triplet loss 0.895065725 l2_loss 1.91752601 fraction B 0.246814877 lossA 0.534200251 fraction A 0.0506870262\n",
      "step 230 loss 1.20472729 fisher_loss 0.128971815 triplet loss 1.07575548 l2_loss 1.92965508 fraction B 0.439194798 lossA 0.525262415 fraction A 0.0498434566\n",
      "step 231 loss 1.11169934 fisher_loss 0.127484381 triplet loss 0.984214902 l2_loss 1.94127595 fraction B 0.37555477 lossA 0.522152722 fraction A 0.0487266928\n",
      "step 232 loss 1.01258826 fisher_loss 0.125763714 triplet loss 0.886824489 l2_loss 1.95257246 fraction B 0.261217952 lossA 0.522501 fraction A 0.0476710387\n",
      "step 233 loss 1.08912253 fisher_loss 0.124632888 triplet loss 0.964489698 l2_loss 1.96333516 fraction B 0.379884541 lossA 0.521849096 fraction A 0.0472500958\n",
      "step 234 loss 1.12304819 fisher_loss 0.124001093 triplet loss 0.999047041 l2_loss 1.97351968 fraction B 0.406698555 lossA 0.521622956 fraction A 0.0468071587\n",
      "step 235 loss 1.01209521 fisher_loss 0.123411082 triplet loss 0.888684094 l2_loss 1.98198974 fraction B 0.332137167 lossA 0.522237301 fraction A 0.0465835258\n",
      "step 236 loss 0.947317719 fisher_loss 0.123178966 triplet loss 0.824138761 l2_loss 1.9893142 fraction B 0.336485028 lossA 0.54253304 fraction A 0.0474890172\n",
      "step 237 loss 1.11763656 fisher_loss 0.126022965 triplet loss 0.991613626 l2_loss 1.9973805 fraction B 0.403420717 lossA 0.566825509 fraction A 0.0482089631\n",
      "step 238 loss 1.06250226 fisher_loss 0.129528746 triplet loss 0.932973564 l2_loss 2.00650263 fraction B 0.426420122 lossA 0.578828692 fraction A 0.0483504\n",
      "step 239 loss 0.964671791 fisher_loss 0.130658552 triplet loss 0.834013224 l2_loss 2.01589751 fraction B 0.321697831 lossA 0.588875234 fraction A 0.0495121516\n",
      "step 240 loss 1.01698303 fisher_loss 0.131903246 triplet loss 0.885079741 l2_loss 2.0250535 fraction B 0.213671103 lossA 0.607304037 fraction A 0.0512532927\n",
      "step 241 loss 0.993823349 fisher_loss 0.134930626 triplet loss 0.858892739 l2_loss 2.03424788 fraction B 0.359104 lossA 0.623369336 fraction A 0.0528317317\n",
      "step 242 loss 1.1194706 fisher_loss 0.138265267 triplet loss 0.981205344 l2_loss 2.04317594 fraction B 0.314293504 lossA 0.638643265 fraction A 0.0539530441\n",
      "step 243 loss 0.884889185 fisher_loss 0.139777854 triplet loss 0.745111346 l2_loss 2.0530014 fraction B 0.317072719 lossA 0.642152727 fraction A 0.0543522462\n",
      "step 244 loss 1.09887135 fisher_loss 0.139471725 triplet loss 0.959399581 l2_loss 2.06461763 fraction B 0.356209517 lossA 0.640564322 fraction A 0.0537813604\n",
      "step 245 loss 1.12598157 fisher_loss 0.138837799 triplet loss 0.987143815 l2_loss 2.07533264 fraction B 0.336544 lossA 0.63259685 fraction A 0.0531188585\n",
      "step 246 loss 0.965276182 fisher_loss 0.139104664 triplet loss 0.826171517 l2_loss 2.08458519 fraction B 0.281154394 lossA 0.616228163 fraction A 0.0525549762\n",
      "step 247 loss 0.873698831 fisher_loss 0.139096886 triplet loss 0.734601915 l2_loss 2.09157372 fraction B 0.289897 lossA 0.607815325 fraction A 0.0522717722\n",
      "step 248 loss 1.1394366 fisher_loss 0.138599753 triplet loss 1.00083685 l2_loss 2.09906316 fraction B 0.434636295 lossA 0.609421313 fraction A 0.0529098921\n",
      "step 249 loss 1.16165364 fisher_loss 0.13902615 triplet loss 1.02262747 l2_loss 2.10638714 fraction B 0.311443537 lossA 0.624100506 fraction A 0.0536535978\n",
      "step 250 loss 1.11312449 fisher_loss 0.14070937 triplet loss 0.97241509 l2_loss 2.11445332 fraction B 0.354944855 lossA 0.651386261 fraction A 0.0540861972\n",
      "step 251 loss 1.00894761 fisher_loss 0.144462183 triplet loss 0.864485383 l2_loss 2.12292528 fraction B 0.293143392 lossA 0.679388762 fraction A 0.0535755828\n",
      "step 252 loss 1.14838839 fisher_loss 0.149215147 triplet loss 0.999173224 l2_loss 2.13234472 fraction B 0.267814666 lossA 0.703982711 fraction A 0.052967228\n",
      "step 253 loss 1.1189959 fisher_loss 0.15451993 triplet loss 0.96447593 l2_loss 2.14174843 fraction B 0.234496891 lossA 0.724154353 fraction A 0.0525990427\n",
      "step 254 loss 1.24095547 fisher_loss 0.158297747 triplet loss 1.08265769 l2_loss 2.1514554 fraction B 0.429713368 lossA 0.725983441 fraction A 0.053139098\n",
      "step 255 loss 1.08201969 fisher_loss 0.157911927 triplet loss 0.92410779 l2_loss 2.16040111 fraction B 0.273047864 lossA 0.701355577 fraction A 0.0540137887\n",
      "step 256 loss 1.21594071 fisher_loss 0.156196773 triplet loss 1.059744 l2_loss 2.16803551 fraction B 0.418419152 lossA 0.669123292 fraction A 0.0549901463\n",
      "step 257 loss 0.938408554 fisher_loss 0.15215303 triplet loss 0.786255538 l2_loss 2.17503119 fraction B 0.221751973 lossA 0.64490664 fraction A 0.0561121926\n",
      "step 258 loss 1.19783843 fisher_loss 0.148166656 triplet loss 1.04967177 l2_loss 2.18358231 fraction B 0.340199322 lossA 0.612436891 fraction A 0.0562295429\n",
      "step 259 loss 1.16710615 fisher_loss 0.143397287 triplet loss 1.02370882 l2_loss 2.19204783 fraction B 0.322000712 lossA 0.583206058 fraction A 0.0560145266\n",
      "step 260 loss 0.990902185 fisher_loss 0.139447 triplet loss 0.851455152 l2_loss 2.19945788 fraction B 0.322974861 lossA 0.560771823 fraction A 0.0548922606\n",
      "step 261 loss 1.03629756 fisher_loss 0.13681747 triplet loss 0.899480045 l2_loss 2.20730019 fraction B 0.281452805 lossA 0.550514221 fraction A 0.0538684651\n",
      "step 262 loss 1.15057707 fisher_loss 0.133400232 triplet loss 1.01717687 l2_loss 2.21485782 fraction B 0.334233403 lossA 0.550431848 fraction A 0.0524960645\n",
      "step 263 loss 1.14213014 fisher_loss 0.130194008 triplet loss 1.01193619 l2_loss 2.22201562 fraction B 0.33196485 lossA 0.556729138 fraction A 0.0516866632\n",
      "step 264 loss 0.978009701 fisher_loss 0.127255693 triplet loss 0.850754 l2_loss 2.22964406 fraction B 0.225768536 lossA 0.575168431 fraction A 0.0514132455\n",
      "step 265 loss 0.981676877 fisher_loss 0.124823071 triplet loss 0.856853783 l2_loss 2.23775315 fraction B 0.38576746 lossA 0.593582273 fraction A 0.0513924956\n",
      "step 266 loss 1.19975853 fisher_loss 0.124070033 triplet loss 1.07568848 l2_loss 2.24679494 fraction B 0.37435019 lossA 0.605937421 fraction A 0.0522036925\n",
      "step 267 loss 1.02623069 fisher_loss 0.124549858 triplet loss 0.901680827 l2_loss 2.25547767 fraction B 0.358070493 lossA 0.614825428 fraction A 0.0525420345\n",
      "step 268 loss 0.958567917 fisher_loss 0.12548165 triplet loss 0.833086252 l2_loss 2.2644639 fraction B 0.348216921 lossA 0.629672289 fraction A 0.0532082766\n",
      "step 269 loss 1.22353041 fisher_loss 0.127645373 triplet loss 1.09588504 l2_loss 2.27345657 fraction B 0.425418347 lossA 0.641940176 fraction A 0.0547895357\n",
      "step 270 loss 1.02317369 fisher_loss 0.130708396 triplet loss 0.892465293 l2_loss 2.28257966 fraction B 0.244710892 lossA 0.663845956 fraction A 0.0562376454\n",
      "step 271 loss 0.891601801 fisher_loss 0.134904236 triplet loss 0.756697536 l2_loss 2.29246521 fraction B 0.295035392 lossA 0.674772799 fraction A 0.0575340129\n",
      "step 272 loss 1.16096544 fisher_loss 0.136007488 triplet loss 1.02495801 l2_loss 2.30269885 fraction B 0.315621614 lossA 0.688419461 fraction A 0.0586664341\n",
      "step 273 loss 0.852417648 fisher_loss 0.137889788 triplet loss 0.714527845 l2_loss 2.31158972 fraction B 0.194545448 lossA 0.685846329 fraction A 0.0582941808\n",
      "step 274 loss 1.0759666 fisher_loss 0.135310322 triplet loss 0.940656245 l2_loss 2.3216145 fraction B 0.305935413 lossA 0.681795895 fraction A 0.0573288947\n",
      "step 275 loss 1.12510192 fisher_loss 0.132778615 triplet loss 0.992323339 l2_loss 2.33256316 fraction B 0.450612396 lossA 0.678720534 fraction A 0.0567268133\n",
      "step 276 loss 1.06037319 fisher_loss 0.130908847 triplet loss 0.92946434 l2_loss 2.34291887 fraction B 0.307157069 lossA 0.675858 fraction A 0.0559552461\n",
      "step 277 loss 1.06389868 fisher_loss 0.130334988 triplet loss 0.933563709 l2_loss 2.35337043 fraction B 0.274551332 lossA 0.682495594 fraction A 0.0553292967\n",
      "step 278 loss 1.19397056 fisher_loss 0.130498 triplet loss 1.06347251 l2_loss 2.36225367 fraction B 0.24132584 lossA 0.677974522 fraction A 0.0547978207\n",
      "step 279 loss 1.13502145 fisher_loss 0.130375862 triplet loss 1.00464559 l2_loss 2.3708148 fraction B 0.351861864 lossA 0.666145086 fraction A 0.0543074086\n",
      "step 280 loss 1.14604437 fisher_loss 0.128366679 triplet loss 1.01767766 l2_loss 2.37867332 fraction B 0.361310184 lossA 0.648402393 fraction A 0.0542158671\n",
      "step 281 loss 1.21013701 fisher_loss 0.12560229 triplet loss 1.08453476 l2_loss 2.38566709 fraction B 0.274498165 lossA 0.638707221 fraction A 0.0543453507\n",
      "step 282 loss 1.30085289 fisher_loss 0.122383088 triplet loss 1.17846978 l2_loss 2.39239979 fraction B 0.475388885 lossA 0.633722 fraction A 0.0544514135\n",
      "step 283 loss 1.09766495 fisher_loss 0.11862547 triplet loss 0.979039431 l2_loss 2.3983233 fraction B 0.279900521 lossA 0.62492305 fraction A 0.0550105274\n",
      "step 284 loss 0.956806481 fisher_loss 0.115027465 triplet loss 0.841779 l2_loss 2.40504932 fraction B 0.291977316 lossA 0.618540704 fraction A 0.0562733151\n",
      "step 285 loss 0.978517234 fisher_loss 0.114077874 triplet loss 0.864439368 l2_loss 2.41122 fraction B 0.324625075 lossA 0.612220347 fraction A 0.0582183637\n",
      "step 286 loss 1.02081668 fisher_loss 0.115307465 triplet loss 0.905509174 l2_loss 2.41851544 fraction B 0.351125211 lossA 0.611317515 fraction A 0.0599698052\n",
      "step 287 loss 1.08659923 fisher_loss 0.116220072 triplet loss 0.970379114 l2_loss 2.42674756 fraction B 0.351915866 lossA 0.613346457 fraction A 0.0619339533\n",
      "step 288 loss 1.08644497 fisher_loss 0.117247239 triplet loss 0.96919769 l2_loss 2.43347406 fraction B 0.338483721 lossA 0.615786493 fraction A 0.0632519498\n",
      "step 289 loss 1.12003672 fisher_loss 0.117184654 triplet loss 1.00285208 l2_loss 2.44074202 fraction B 0.417726666 lossA 0.614469111 fraction A 0.0635173395\n",
      "step 290 loss 1.02712083 fisher_loss 0.115219869 triplet loss 0.911900938 l2_loss 2.44856453 fraction B 0.351406306 lossA 0.611400366 fraction A 0.0632352754\n",
      "step 291 loss 1.07236862 fisher_loss 0.114323802 triplet loss 0.958044767 l2_loss 2.45651388 fraction B 0.326157749 lossA 0.606474876 fraction A 0.0617696382\n",
      "step 292 loss 1.19009757 fisher_loss 0.113502368 triplet loss 1.07659519 l2_loss 2.46397185 fraction B 0.357389718 lossA 0.605343163 fraction A 0.0598361753\n",
      "step 293 loss 1.01532674 fisher_loss 0.112975314 triplet loss 0.902351379 l2_loss 2.4713428 fraction B 0.312646449 lossA 0.612834215 fraction A 0.0586691462\n",
      "step 294 loss 1.10472476 fisher_loss 0.114851706 triplet loss 0.989873052 l2_loss 2.47886205 fraction B 0.314151555 lossA 0.626040161 fraction A 0.0574558154\n",
      "step 295 loss 1.18250895 fisher_loss 0.117087752 triplet loss 1.06542122 l2_loss 2.48596978 fraction B 0.2966353 lossA 0.646115601 fraction A 0.0561885945\n",
      "step 296 loss 0.953573942 fisher_loss 0.118709594 triplet loss 0.834864318 l2_loss 2.49306798 fraction B 0.222746983 lossA 0.656781793 fraction A 0.0553949922\n",
      "step 297 loss 1.03432655 fisher_loss 0.118101709 triplet loss 0.916224897 l2_loss 2.50143814 fraction B 0.270997673 lossA 0.666238785 fraction A 0.0557575338\n",
      "step 298 loss 1.01623404 fisher_loss 0.116299778 triplet loss 0.899934292 l2_loss 2.50891089 fraction B 0.355797976 lossA 0.664097786 fraction A 0.0567264445\n",
      "step 299 loss 1.10300064 fisher_loss 0.11430192 triplet loss 0.988698661 l2_loss 2.51665735 fraction B 0.317237914 lossA 0.652387857 fraction A 0.0583863817\n",
      "step 300 loss 1.08372033 fisher_loss 0.112732925 triplet loss 0.970987439 l2_loss 2.52368307 fraction B 0.214172691 lossA 0.641420662 fraction A 0.0606643483\n",
      "step 301 loss 0.905993462 fisher_loss 0.113517873 triplet loss 0.792475581 l2_loss 2.5315702 fraction B 0.344777465 lossA 0.63291961 fraction A 0.0634543598\n",
      "step 302 loss 1.16473198 fisher_loss 0.114658728 triplet loss 1.05007327 l2_loss 2.54127765 fraction B 0.33109349 lossA 0.630275 fraction A 0.0658951\n",
      "step 303 loss 1.03448546 fisher_loss 0.115960948 triplet loss 0.918524504 l2_loss 2.55032921 fraction B 0.251008481 lossA 0.639238536 fraction A 0.0687518716\n",
      "step 304 loss 1.03560901 fisher_loss 0.117604166 triplet loss 0.91800487 l2_loss 2.55915952 fraction B 0.346847653 lossA 0.652929783 fraction A 0.0712833852\n",
      "step 305 loss 1.06634653 fisher_loss 0.119051345 triplet loss 0.947295129 l2_loss 2.56885481 fraction B 0.287408799 lossA 0.658238292 fraction A 0.0724442899\n",
      "step 306 loss 0.931951284 fisher_loss 0.117271371 triplet loss 0.814679921 l2_loss 2.57790756 fraction B 0.407794684 lossA 0.660771 fraction A 0.073360227\n",
      "step 307 loss 0.90338254 fisher_loss 0.115248404 triplet loss 0.788134158 l2_loss 2.5874033 fraction B 0.295842916 lossA 0.661209404 fraction A 0.072989\n",
      "step 308 loss 0.788497269 fisher_loss 0.113555364 triplet loss 0.674941897 l2_loss 2.59845901 fraction B 0.26658234 lossA 0.656154454 fraction A 0.0713245198\n",
      "step 309 loss 0.934677243 fisher_loss 0.113212839 triplet loss 0.821464419 l2_loss 2.61050606 fraction B 0.243118584 lossA 0.659675241 fraction A 0.0691497177\n",
      "step 310 loss 1.02016759 fisher_loss 0.115610167 triplet loss 0.904557467 l2_loss 2.62281799 fraction B 0.287784755 lossA 0.662959576 fraction A 0.0675092861\n",
      "step 311 loss 1.18243539 fisher_loss 0.119111098 triplet loss 1.06332433 l2_loss 2.63534594 fraction B 0.306640267 lossA 0.680780768 fraction A 0.0655075535\n",
      "step 312 loss 1.07596588 fisher_loss 0.123259991 triplet loss 0.95270592 l2_loss 2.64729381 fraction B 0.269275695 lossA 0.708841324 fraction A 0.0634671152\n",
      "step 313 loss 1.01189184 fisher_loss 0.126798272 triplet loss 0.88509357 l2_loss 2.65933299 fraction B 0.310965627 lossA 0.73503226 fraction A 0.0623308085\n",
      "step 314 loss 1.31210148 fisher_loss 0.127680153 triplet loss 1.1844213 l2_loss 2.67132711 fraction B 0.293188661 lossA 0.746192336 fraction A 0.062348187\n",
      "step 315 loss 0.981589198 fisher_loss 0.124394745 triplet loss 0.857194483 l2_loss 2.68089724 fraction B 0.211707234 lossA 0.752245188 fraction A 0.0632785335\n",
      "step 316 loss 1.03644919 fisher_loss 0.120527901 triplet loss 0.91592133 l2_loss 2.69057417 fraction B 0.260609925 lossA 0.746109962 fraction A 0.0643469095\n",
      "step 317 loss 0.989656329 fisher_loss 0.117223389 triplet loss 0.872432947 l2_loss 2.6998477 fraction B 0.290622711 lossA 0.738591194 fraction A 0.0664702356\n",
      "step 318 loss 1.33396971 fisher_loss 0.115477279 triplet loss 1.21849239 l2_loss 2.70850945 fraction B 0.334470421 lossA 0.721481681 fraction A 0.0698164701\n",
      "step 319 loss 1.09111774 fisher_loss 0.115519188 triplet loss 0.975598574 l2_loss 2.71623564 fraction B 0.252656877 lossA 0.706387281 fraction A 0.0721210837\n",
      "step 320 loss 0.910086334 fisher_loss 0.115998037 triplet loss 0.794088304 l2_loss 2.72419763 fraction B 0.294738948 lossA 0.684548378 fraction A 0.0735012591\n",
      "step 321 loss 1.02763462 fisher_loss 0.114540949 triplet loss 0.913093686 l2_loss 2.73297143 fraction B 0.245008186 lossA 0.667355359 fraction A 0.0745874196\n",
      "step 322 loss 1.07090199 fisher_loss 0.113599792 triplet loss 0.957302213 l2_loss 2.74259901 fraction B 0.319384456 lossA 0.656992257 fraction A 0.0743427053\n",
      "step 323 loss 1.02134979 fisher_loss 0.111954361 triplet loss 0.909395456 l2_loss 2.75203109 fraction B 0.179944441 lossA 0.653297544 fraction A 0.074020125\n",
      "step 324 loss 1.06164241 fisher_loss 0.110572979 triplet loss 0.951069415 l2_loss 2.76154184 fraction B 0.269066274 lossA 0.653667748 fraction A 0.0734761134\n",
      "step 325 loss 1.06617534 fisher_loss 0.108601913 triplet loss 0.957573473 l2_loss 2.7715528 fraction B 0.276955187 lossA 0.657221437 fraction A 0.0730448738\n",
      "step 326 loss 0.949722648 fisher_loss 0.106899984 triplet loss 0.842822671 l2_loss 2.78092337 fraction B 0.257780313 lossA 0.662905753 fraction A 0.0728463531\n",
      "step 327 loss 0.965062678 fisher_loss 0.106851391 triplet loss 0.858211279 l2_loss 2.79098964 fraction B 0.225383162 lossA 0.676931918 fraction A 0.0721090585\n",
      "step 328 loss 1.0684824 fisher_loss 0.109548561 triplet loss 0.95893383 l2_loss 2.8006227 fraction B 0.327631354 lossA 0.68041873 fraction A 0.070967108\n",
      "step 329 loss 1.29533732 fisher_loss 0.111687012 triplet loss 1.18365026 l2_loss 2.80844665 fraction B 0.235777825 lossA 0.671311855 fraction A 0.0700817853\n",
      "step 330 loss 0.975825429 fisher_loss 0.111279994 triplet loss 0.864545465 l2_loss 2.81633663 fraction B 0.190936789 lossA 0.668017626 fraction A 0.0684351549\n",
      "step 331 loss 0.945003629 fisher_loss 0.110845514 triplet loss 0.834158123 l2_loss 2.82564282 fraction B 0.229261667 lossA 0.669977665 fraction A 0.0675466731\n",
      "step 332 loss 1.27315974 fisher_loss 0.111636057 triplet loss 1.1615237 l2_loss 2.8350029 fraction B 0.301202446 lossA 0.660843 fraction A 0.0684457868\n",
      "step 333 loss 0.933135 fisher_loss 0.109915778 triplet loss 0.82321918 l2_loss 2.84299302 fraction B 0.110376894 lossA 0.659942865 fraction A 0.0688592494\n",
      "step 334 loss 0.930247 fisher_loss 0.108234704 triplet loss 0.822012305 l2_loss 2.85043859 fraction B 0.186712354 lossA 0.669553 fraction A 0.0686592311\n",
      "step 335 loss 1.12589061 fisher_loss 0.107262008 triplet loss 1.0186286 l2_loss 2.85873222 fraction B 0.290681362 lossA 0.683712304 fraction A 0.0684761405\n",
      "step 336 loss 0.821566463 fisher_loss 0.108122081 triplet loss 0.713444412 l2_loss 2.86669135 fraction B 0.163048953 lossA 0.707604051 fraction A 0.0681056827\n",
      "step 337 loss 1.12261975 fisher_loss 0.113253109 triplet loss 1.00936663 l2_loss 2.87731957 fraction B 0.261010081 lossA 0.713850796 fraction A 0.0688659251\n",
      "step 338 loss 1.05596769 fisher_loss 0.117276348 triplet loss 0.938691318 l2_loss 2.88615465 fraction B 0.299700558 lossA 0.717268944 fraction A 0.0694677085\n",
      "step 339 loss 0.864614069 fisher_loss 0.122015461 triplet loss 0.742598593 l2_loss 2.8943491 fraction B 0.155821413 lossA 0.7056306 fraction A 0.0707279667\n",
      "step 340 loss 1.18702483 fisher_loss 0.122541882 triplet loss 1.06448293 l2_loss 2.90350056 fraction B 0.300752968 lossA 0.689980447 fraction A 0.0730448365\n",
      "step 341 loss 1.21221435 fisher_loss 0.121019222 triplet loss 1.09119511 l2_loss 2.91103387 fraction B 0.350760698 lossA 0.675493896 fraction A 0.0756363273\n",
      "step 342 loss 0.916963279 fisher_loss 0.117564686 triplet loss 0.799398601 l2_loss 2.91714382 fraction B 0.259720415 lossA 0.656068504 fraction A 0.0790780559\n",
      "step 343 loss 1.21077228 fisher_loss 0.114649609 triplet loss 1.09612262 l2_loss 2.92335677 fraction B 0.357263744 lossA 0.638367951 fraction A 0.080952242\n",
      "step 344 loss 1.10585046 fisher_loss 0.112686463 triplet loss 0.993164 l2_loss 2.92971492 fraction B 0.328005105 lossA 0.63404578 fraction A 0.0826948434\n",
      "step 345 loss 1.08778679 fisher_loss 0.113406904 triplet loss 0.974379897 l2_loss 2.93567419 fraction B 0.262812614 lossA 0.640356123 fraction A 0.0836702511\n",
      "step 346 loss 1.04273629 fisher_loss 0.115084656 triplet loss 0.927651644 l2_loss 2.94301367 fraction B 0.273927569 lossA 0.658604145 fraction A 0.0845825896\n",
      "step 347 loss 1.12946761 fisher_loss 0.117558956 triplet loss 1.01190865 l2_loss 2.95053077 fraction B 0.277143568 lossA 0.678784072 fraction A 0.0845938846\n",
      "step 348 loss 1.00125611 fisher_loss 0.119627528 triplet loss 0.881628633 l2_loss 2.95846415 fraction B 0.264613658 lossA 0.691539586 fraction A 0.0838669315\n",
      "step 349 loss 1.14762402 fisher_loss 0.120504841 triplet loss 1.02711916 l2_loss 2.96663189 fraction B 0.230023384 lossA 0.687512875 fraction A 0.0830421\n",
      "step 350 loss 0.93396914 fisher_loss 0.119928889 triplet loss 0.814040244 l2_loss 2.97195244 fraction B 0.239992008 lossA 0.683810234 fraction A 0.0808663443\n",
      "step 351 loss 1.37018573 fisher_loss 0.118905157 triplet loss 1.25128055 l2_loss 2.97865653 fraction B 0.399873644 lossA 0.678571284 fraction A 0.0788924769\n",
      "step 352 loss 0.862731397 fisher_loss 0.118456028 triplet loss 0.744275391 l2_loss 2.98375916 fraction B 0.179059431 lossA 0.670387089 fraction A 0.0787489489\n",
      "step 353 loss 0.964831889 fisher_loss 0.117983475 triplet loss 0.846848428 l2_loss 2.98956966 fraction B 0.334561199 lossA 0.658162057 fraction A 0.0808236301\n",
      "step 354 loss 1.05886769 fisher_loss 0.116826795 triplet loss 0.942040861 l2_loss 2.99601483 fraction B 0.296656221 lossA 0.648007452 fraction A 0.083152011\n",
      "step 355 loss 0.971677 fisher_loss 0.116053984 triplet loss 0.855623 l2_loss 3.00238156 fraction B 0.319979131 lossA 0.653187335 fraction A 0.0842206776\n",
      "step 356 loss 1.16204107 fisher_loss 0.115131751 triplet loss 1.04690933 l2_loss 3.00961542 fraction B 0.349112421 lossA 0.664987087 fraction A 0.0844373778\n",
      "step 357 loss 0.91726613 fisher_loss 0.114533246 triplet loss 0.802732885 l2_loss 3.01650023 fraction B 0.236734912 lossA 0.681769311 fraction A 0.0835008398\n",
      "step 358 loss 1.00973773 fisher_loss 0.11465466 triplet loss 0.895083 l2_loss 3.02484298 fraction B 0.224826545 lossA 0.68845427 fraction A 0.0816516206\n",
      "step 359 loss 0.921257079 fisher_loss 0.11313872 triplet loss 0.808118343 l2_loss 3.03348303 fraction B 0.261639088 lossA 0.686529279 fraction A 0.0789588\n",
      "step 360 loss 1.09069526 fisher_loss 0.111313567 triplet loss 0.97938174 l2_loss 3.0434351 fraction B 0.309758335 lossA 0.686380506 fraction A 0.0758869722\n",
      "step 361 loss 1.04318523 fisher_loss 0.111139588 triplet loss 0.932045639 l2_loss 3.05351472 fraction B 0.276974529 lossA 0.692436695 fraction A 0.0727572665\n",
      "step 362 loss 1.07615376 fisher_loss 0.112518065 triplet loss 0.963635683 l2_loss 3.06363702 fraction B 0.366186231 lossA 0.697152853 fraction A 0.0709038302\n",
      "step 363 loss 0.993483901 fisher_loss 0.112807132 triplet loss 0.880676746 l2_loss 3.07349539 fraction B 0.29891637 lossA 0.708014727 fraction A 0.0694913939\n",
      "step 364 loss 0.978683412 fisher_loss 0.112535536 triplet loss 0.866147876 l2_loss 3.08309221 fraction B 0.292182416 lossA 0.715002835 fraction A 0.0696735606\n",
      "step 365 loss 1.35316312 fisher_loss 0.11159201 triplet loss 1.24157107 l2_loss 3.09243298 fraction B 0.335350037 lossA 0.722344697 fraction A 0.0700864792\n",
      "step 366 loss 0.891147792 fisher_loss 0.110448785 triplet loss 0.780699 l2_loss 3.10022306 fraction B 0.278149515 lossA 0.727553606 fraction A 0.071528025\n",
      "step 367 loss 1.01221836 fisher_loss 0.109259427 triplet loss 0.90295893 l2_loss 3.10720086 fraction B 0.342349 lossA 0.720436633 fraction A 0.0736596\n",
      "step 368 loss 1.12932289 fisher_loss 0.108547471 triplet loss 1.02077544 l2_loss 3.11473322 fraction B 0.348920077 lossA 0.707081318 fraction A 0.0766225085\n",
      "step 369 loss 0.876793 fisher_loss 0.108858325 triplet loss 0.76793468 l2_loss 3.12108564 fraction B 0.138621792 lossA 0.692070186 fraction A 0.0792434365\n",
      "step 370 loss 1.05558848 fisher_loss 0.109846815 triplet loss 0.945741653 l2_loss 3.12665558 fraction B 0.260404497 lossA 0.681688845 fraction A 0.0820811763\n",
      "step 371 loss 1.09290814 fisher_loss 0.113181382 triplet loss 0.979726732 l2_loss 3.13250566 fraction B 0.234761029 lossA 0.684103787 fraction A 0.084370181\n",
      "step 372 loss 0.96171087 fisher_loss 0.117136501 triplet loss 0.844574392 l2_loss 3.13954353 fraction B 0.163667634 lossA 0.681562722 fraction A 0.0857071\n",
      "step 373 loss 1.03749192 fisher_loss 0.11930801 triplet loss 0.918183923 l2_loss 3.1477294 fraction B 0.276851356 lossA 0.67997694 fraction A 0.0868544\n",
      "step 374 loss 0.982033134 fisher_loss 0.120296545 triplet loss 0.861736596 l2_loss 3.15648627 fraction B 0.301374823 lossA 0.679675639 fraction A 0.0862486511\n",
      "step 375 loss 1.03965962 fisher_loss 0.118791565 triplet loss 0.920868099 l2_loss 3.16620517 fraction B 0.212130412 lossA 0.67440021 fraction A 0.0862316042\n",
      "step 376 loss 0.823599637 fisher_loss 0.116176151 triplet loss 0.707423508 l2_loss 3.17564201 fraction B 0.176589385 lossA 0.668881416 fraction A 0.0843645707\n",
      "step 377 loss 0.970571756 fisher_loss 0.112770051 triplet loss 0.857801676 l2_loss 3.18626165 fraction B 0.216387466 lossA 0.665023744 fraction A 0.0807113051\n",
      "step 378 loss 0.88523066 fisher_loss 0.111424811 triplet loss 0.773805857 l2_loss 3.19670463 fraction B 0.193681315 lossA 0.681278229 fraction A 0.0762626\n",
      "step 379 loss 0.987964392 fisher_loss 0.113190733 triplet loss 0.874773681 l2_loss 3.20815444 fraction B 0.29358837 lossA 0.705576539 fraction A 0.0719876066\n",
      "step 380 loss 1.17450225 fisher_loss 0.117027171 triplet loss 1.05747509 l2_loss 3.21905971 fraction B 0.330663294 lossA 0.727798343 fraction A 0.0689591542\n",
      "step 381 loss 1.08802462 fisher_loss 0.120950513 triplet loss 0.967074096 l2_loss 3.22949338 fraction B 0.324991912 lossA 0.750218272 fraction A 0.0669129193\n",
      "step 382 loss 1.06041217 fisher_loss 0.123913355 triplet loss 0.936498761 l2_loss 3.2393918 fraction B 0.285722 lossA 0.766670167 fraction A 0.0659176856\n",
      "step 383 loss 1.05145502 fisher_loss 0.123463996 triplet loss 0.927991033 l2_loss 3.24909282 fraction B 0.250253737 lossA 0.770193279 fraction A 0.0657240376\n",
      "step 384 loss 1.19388235 fisher_loss 0.120455481 triplet loss 1.07342684 l2_loss 3.25617099 fraction B 0.319694906 lossA 0.763818383 fraction A 0.0662743226\n",
      "step 385 loss 1.19355917 fisher_loss 0.116058059 triplet loss 1.07750106 l2_loss 3.26213837 fraction B 0.303682983 lossA 0.745048523 fraction A 0.0680864379\n",
      "step 386 loss 1.04866 fisher_loss 0.11053317 triplet loss 0.938126862 l2_loss 3.26687217 fraction B 0.297622055 lossA 0.730581403 fraction A 0.0705791265\n",
      "step 387 loss 1.08957148 fisher_loss 0.10702128 triplet loss 0.982550204 l2_loss 3.27088904 fraction B 0.210613117 lossA 0.716746628 fraction A 0.0725304037\n",
      "step 388 loss 0.967483819 fisher_loss 0.104828 triplet loss 0.862655818 l2_loss 3.275352 fraction B 0.277681977 lossA 0.703532457 fraction A 0.0755227506\n",
      "step 389 loss 1.02915072 fisher_loss 0.104074404 triplet loss 0.925076365 l2_loss 3.28060484 fraction B 0.280475706 lossA 0.687308073 fraction A 0.0793741345\n",
      "step 390 loss 0.941691875 fisher_loss 0.104988568 triplet loss 0.8367033 l2_loss 3.28644228 fraction B 0.160549447 lossA 0.683936477 fraction A 0.0813342854\n",
      "step 391 loss 1.02912128 fisher_loss 0.106833391 triplet loss 0.922287881 l2_loss 3.2927742 fraction B 0.240262553 lossA 0.684123516 fraction A 0.0822965577\n",
      "step 392 loss 0.931947 fisher_loss 0.108222671 triplet loss 0.823724329 l2_loss 3.29990649 fraction B 0.324184954 lossA 0.684429526 fraction A 0.082116887\n",
      "step 393 loss 0.937240124 fisher_loss 0.107241578 triplet loss 0.829998553 l2_loss 3.30811143 fraction B 0.225924969 lossA 0.681333661 fraction A 0.0806459039\n",
      "step 394 loss 1.14086461 fisher_loss 0.105529152 triplet loss 1.03533542 l2_loss 3.31603074 fraction B 0.251754701 lossA 0.67609781 fraction A 0.0783307627\n",
      "step 395 loss 1.00494421 fisher_loss 0.104198307 triplet loss 0.900745928 l2_loss 3.32276344 fraction B 0.206764862 lossA 0.670474708 fraction A 0.076175645\n",
      "step 396 loss 1.12144911 fisher_loss 0.105305403 triplet loss 1.01614368 l2_loss 3.33005095 fraction B 0.304466754 lossA 0.67131108 fraction A 0.073810868\n",
      "step 397 loss 0.921626806 fisher_loss 0.106568627 triplet loss 0.815058172 l2_loss 3.33828187 fraction B 0.27466315 lossA 0.680740118 fraction A 0.0714201629\n",
      "step 398 loss 1.11881292 fisher_loss 0.109947711 triplet loss 1.00886524 l2_loss 3.34657145 fraction B 0.242019549 lossA 0.705847919 fraction A 0.0689845905\n",
      "step 399 loss 1.07537007 fisher_loss 0.113773584 triplet loss 0.961596429 l2_loss 3.3551476 fraction B 0.24441503 lossA 0.731154203 fraction A 0.0667803511\n",
      "step 400 loss 1.27939332 fisher_loss 0.117363214 triplet loss 1.1620301 l2_loss 3.36266208 fraction B 0.23829788 lossA 0.747164071 fraction A 0.065214932\n",
      "step 401 loss 1.03243 fisher_loss 0.118497297 triplet loss 0.9139328 l2_loss 3.36977792 fraction B 0.213984355 lossA 0.75397 fraction A 0.0639369264\n",
      "step 402 loss 1.01352227 fisher_loss 0.118250869 triplet loss 0.895271361 l2_loss 3.37793112 fraction B 0.234310538 lossA 0.757275164 fraction A 0.0640298277\n",
      "step 403 loss 0.928714931 fisher_loss 0.115918927 triplet loss 0.812796 l2_loss 3.38611412 fraction B 0.165254235 lossA 0.762835 fraction A 0.0638336912\n",
      "step 404 loss 1.25217533 fisher_loss 0.114143588 triplet loss 1.13803172 l2_loss 3.39516854 fraction B 0.337977469 lossA 0.754379094 fraction A 0.0643926933\n",
      "step 405 loss 1.12451482 fisher_loss 0.110876977 triplet loss 1.01363778 l2_loss 3.40282679 fraction B 0.276655823 lossA 0.744558632 fraction A 0.0650527775\n",
      "step 406 loss 1.2470324 fisher_loss 0.108304918 triplet loss 1.13872755 l2_loss 3.41048241 fraction B 0.252379388 lossA 0.734816 fraction A 0.0658963844\n",
      "step 407 loss 1.16043341 fisher_loss 0.106119029 triplet loss 1.05431437 l2_loss 3.41814423 fraction B 0.381190419 lossA 0.718031943 fraction A 0.0680033639\n",
      "step 408 loss 1.10912514 fisher_loss 0.104333431 triplet loss 1.00479174 l2_loss 3.42561698 fraction B 0.271623552 lossA 0.709303439 fraction A 0.0700838\n",
      "step 409 loss 1.10154831 fisher_loss 0.103918597 triplet loss 0.997629762 l2_loss 3.43266916 fraction B 0.302372903 lossA 0.696810901 fraction A 0.0717233121\n",
      "step 410 loss 0.990348399 fisher_loss 0.103150249 triplet loss 0.88719815 l2_loss 3.43924189 fraction B 0.185934812 lossA 0.693969071 fraction A 0.0725982264\n",
      "step 411 loss 0.986905634 fisher_loss 0.103065059 triplet loss 0.883840561 l2_loss 3.44672751 fraction B 0.275681525 lossA 0.690664172 fraction A 0.072652638\n",
      "step 412 loss 1.07397187 fisher_loss 0.101533398 triplet loss 0.972438514 l2_loss 3.45463634 fraction B 0.317721844 lossA 0.683993578 fraction A 0.0727421641\n",
      "step 413 loss 0.956116915 fisher_loss 0.0999081 triplet loss 0.856208801 l2_loss 3.46189499 fraction B 0.257333875 lossA 0.676605225 fraction A 0.0728842914\n",
      "step 414 loss 0.922071576 fisher_loss 0.0985729 triplet loss 0.823498666 l2_loss 3.46942472 fraction B 0.218740866 lossA 0.675927341 fraction A 0.072301127\n",
      "step 415 loss 0.93515563 fisher_loss 0.0978775173 triplet loss 0.837278128 l2_loss 3.47781205 fraction B 0.191507354 lossA 0.674257278 fraction A 0.0711565\n",
      "step 416 loss 1.06907511 fisher_loss 0.0977508053 triplet loss 0.971324265 l2_loss 3.48740935 fraction B 0.357013792 lossA 0.673038125 fraction A 0.0702385455\n",
      "step 417 loss 0.963358402 fisher_loss 0.0986785516 triplet loss 0.864679873 l2_loss 3.49697971 fraction B 0.207258657 lossA 0.666546822 fraction A 0.0702458397\n",
      "step 418 loss 0.957720101 fisher_loss 0.0987243876 triplet loss 0.858995736 l2_loss 3.50585 fraction B 0.319803536 lossA 0.665168226 fraction A 0.069494985\n",
      "step 419 loss 1.10241687 fisher_loss 0.0987695605 triplet loss 1.00364733 l2_loss 3.51574492 fraction B 0.303975224 lossA 0.666009903 fraction A 0.0686508343\n",
      "step 420 loss 0.939450324 fisher_loss 0.0990732163 triplet loss 0.840377092 l2_loss 3.52537823 fraction B 0.190365732 lossA 0.6734972 fraction A 0.0675898269\n",
      "step 421 loss 0.897952318 fisher_loss 0.0986781418 triplet loss 0.799274147 l2_loss 3.53569555 fraction B 0.207951233 lossA 0.690389872 fraction A 0.0668623596\n",
      "step 422 loss 1.18585813 fisher_loss 0.100028031 triplet loss 1.08583009 l2_loss 3.5458951 fraction B 0.335644752 lossA 0.70464 fraction A 0.0659131706\n",
      "step 423 loss 0.97000283 fisher_loss 0.102513321 triplet loss 0.867489517 l2_loss 3.55551076 fraction B 0.246602193 lossA 0.726099849 fraction A 0.0655324459\n",
      "step 424 loss 1.00976646 fisher_loss 0.106144764 triplet loss 0.903621674 l2_loss 3.56551266 fraction B 0.269752949 lossA 0.730668366 fraction A 0.0665139\n",
      "step 425 loss 1.04819024 fisher_loss 0.105147041 triplet loss 0.943043172 l2_loss 3.5768013 fraction B 0.248585626 lossA 0.728825629 fraction A 0.0684421211\n",
      "step 426 loss 0.981591642 fisher_loss 0.10334871 triplet loss 0.87824291 l2_loss 3.58917594 fraction B 0.399260461 lossA 0.731144607 fraction A 0.0701397434\n",
      "step 427 loss 0.931606412 fisher_loss 0.102341637 triplet loss 0.82926476 l2_loss 3.60144329 fraction B 0.248191029 lossA 0.723997176 fraction A 0.0723972544\n",
      "step 428 loss 0.944110274 fisher_loss 0.100783207 triplet loss 0.843327045 l2_loss 3.612185 fraction B 0.190318257 lossA 0.711427391 fraction A 0.0749728\n",
      "step 429 loss 0.927203238 fisher_loss 0.100267805 triplet loss 0.82693541 l2_loss 3.62327 fraction B 0.245393515 lossA 0.702025592 fraction A 0.07628984\n",
      "step 430 loss 1.02878869 fisher_loss 0.0993238837 triplet loss 0.929464757 l2_loss 3.63562465 fraction B 0.291204035 lossA 0.695731044 fraction A 0.0779734626\n",
      "step 431 loss 0.919869125 fisher_loss 0.0996629074 triplet loss 0.820206225 l2_loss 3.64766669 fraction B 0.27169165 lossA 0.692809165 fraction A 0.0788414478\n",
      "step 432 loss 0.95125705 fisher_loss 0.0995087102 triplet loss 0.851748347 l2_loss 3.66113877 fraction B 0.193163693 lossA 0.692825139 fraction A 0.0785204768\n",
      "step 433 loss 0.847718 fisher_loss 0.0987089574 triplet loss 0.749009073 l2_loss 3.67369175 fraction B 0.202913329 lossA 0.693204045 fraction A 0.0789530426\n",
      "step 434 loss 0.891954541 fisher_loss 0.0985832363 triplet loss 0.79337132 l2_loss 3.6871984 fraction B 0.307393849 lossA 0.695337 fraction A 0.078182213\n",
      "step 435 loss 0.993373394 fisher_loss 0.0976969525 triplet loss 0.895676434 l2_loss 3.70042 fraction B 0.244115517 lossA 0.696830153 fraction A 0.0776819\n",
      "step 436 loss 1.13169599 fisher_loss 0.0966923162 triplet loss 1.03500366 l2_loss 3.7129488 fraction B 0.278463215 lossA 0.70949018 fraction A 0.0761480778\n",
      "step 437 loss 0.948814869 fisher_loss 0.0961452276 triplet loss 0.852669656 l2_loss 3.72555685 fraction B 0.226914197 lossA 0.719553351 fraction A 0.0742212087\n",
      "step 438 loss 1.05400527 fisher_loss 0.0969772488 triplet loss 0.957028031 l2_loss 3.73797154 fraction B 0.147361353 lossA 0.736179 fraction A 0.0736004338\n",
      "step 439 loss 0.962747931 fisher_loss 0.0995162055 triplet loss 0.863231719 l2_loss 3.7491622 fraction B 0.224579 lossA 0.758466125 fraction A 0.0726090819\n",
      "step 440 loss 1.08877718 fisher_loss 0.103666112 triplet loss 0.985111058 l2_loss 3.76020312 fraction B 0.269363016 lossA 0.767653227 fraction A 0.0707681105\n",
      "step 441 loss 1.15118086 fisher_loss 0.104887366 triplet loss 1.0462935 l2_loss 3.77269983 fraction B 0.278077 lossA 0.770874202 fraction A 0.0676041245\n",
      "step 442 loss 1.09672284 fisher_loss 0.105086915 triplet loss 0.991635919 l2_loss 3.7855289 fraction B 0.299053609 lossA 0.783409655 fraction A 0.0648499355\n",
      "step 443 loss 1.20402277 fisher_loss 0.107379027 triplet loss 1.09664369 l2_loss 3.79963517 fraction B 0.277994931 lossA 0.782167912 fraction A 0.0628462285\n",
      "step 444 loss 0.894059479 fisher_loss 0.108493909 triplet loss 0.785565555 l2_loss 3.81170201 fraction B 0.15391697 lossA 0.782226205 fraction A 0.0619716793\n",
      "step 445 loss 1.0669142 fisher_loss 0.109443054 triplet loss 0.957471192 l2_loss 3.82429552 fraction B 0.217417583 lossA 0.774013758 fraction A 0.0621630847\n",
      "step 446 loss 0.99044764 fisher_loss 0.108597785 triplet loss 0.881849825 l2_loss 3.83581042 fraction B 0.263201147 lossA 0.761073112 fraction A 0.0628765076\n",
      "step 447 loss 0.891247213 fisher_loss 0.107999742 triplet loss 0.783247471 l2_loss 3.84758878 fraction B 0.173533648 lossA 0.750323951 fraction A 0.0642427877\n",
      "step 448 loss 0.961823881 fisher_loss 0.106848963 triplet loss 0.854974926 l2_loss 3.85996795 fraction B 0.167002946 lossA 0.740431964 fraction A 0.0669620112\n",
      "step 449 loss 1.11268389 fisher_loss 0.104818732 triplet loss 1.00786519 l2_loss 3.87206697 fraction B 0.238628164 lossA 0.735388815 fraction A 0.0697794408\n",
      "step 450 loss 1.0044421 fisher_loss 0.103442289 triplet loss 0.900999844 l2_loss 3.88386035 fraction B 0.230094105 lossA 0.731427073 fraction A 0.0730225071\n",
      "step 451 loss 1.05378211 fisher_loss 0.104292691 triplet loss 0.949489415 l2_loss 3.89565253 fraction B 0.326202452 lossA 0.733945489 fraction A 0.0762843043\n",
      "step 452 loss 1.11269474 fisher_loss 0.105912916 triplet loss 1.00678182 l2_loss 3.90878797 fraction B 0.266435474 lossA 0.734900534 fraction A 0.0799392611\n",
      "step 453 loss 1.0303992 fisher_loss 0.107922927 triplet loss 0.922476232 l2_loss 3.92137551 fraction B 0.295627266 lossA 0.740207613 fraction A 0.0837318376\n",
      "step 454 loss 1.03400981 fisher_loss 0.111485638 triplet loss 0.922524154 l2_loss 3.93422127 fraction B 0.229620934 lossA 0.74952203 fraction A 0.0855707899\n",
      "step 455 loss 1.16632748 fisher_loss 0.112111486 triplet loss 1.05421603 l2_loss 3.94666743 fraction B 0.23237735 lossA 0.746252477 fraction A 0.0853417292\n",
      "step 456 loss 1.09238112 fisher_loss 0.107559487 triplet loss 0.984821618 l2_loss 3.95876598 fraction B 0.285765618 lossA 0.743166625 fraction A 0.083501935\n",
      "step 457 loss 1.0439496 fisher_loss 0.102539279 triplet loss 0.941410363 l2_loss 3.97103882 fraction B 0.267395914 lossA 0.733029485 fraction A 0.0805102885\n",
      "step 458 loss 1.00698781 fisher_loss 0.0986739695 triplet loss 0.908313811 l2_loss 3.9830358 fraction B 0.174059138 lossA 0.724468112 fraction A 0.0775573626\n",
      "step 459 loss 0.902909636 fisher_loss 0.0982696 triplet loss 0.804640055 l2_loss 3.9938159 fraction B 0.171204194 lossA 0.726486921 fraction A 0.074692376\n",
      "step 460 loss 1.11625898 fisher_loss 0.0990397185 triplet loss 1.01721931 l2_loss 4.00382137 fraction B 0.251709044 lossA 0.732661128 fraction A 0.0716576204\n",
      "step 461 loss 0.872036695 fisher_loss 0.0999716818 triplet loss 0.772065 l2_loss 4.01489592 fraction B 0.18565546 lossA 0.746419251 fraction A 0.0690142885\n",
      "step 462 loss 1.11019087 fisher_loss 0.101597831 triplet loss 1.00859308 l2_loss 4.02589893 fraction B 0.239906773 lossA 0.749534905 fraction A 0.0683523715\n",
      "step 463 loss 0.897976 fisher_loss 0.102060564 triplet loss 0.795915425 l2_loss 4.03621387 fraction B 0.24089244 lossA 0.760582924 fraction A 0.0674255863\n",
      "step 464 loss 1.27602351 fisher_loss 0.102972984 triplet loss 1.17305052 l2_loss 4.04540205 fraction B 0.229085341 lossA 0.767004371 fraction A 0.0676808208\n",
      "step 465 loss 0.884544849 fisher_loss 0.102717608 triplet loss 0.781827271 l2_loss 4.0532465 fraction B 0.197776973 lossA 0.765292346 fraction A 0.0691031218\n",
      "step 466 loss 1.20320678 fisher_loss 0.101795122 triplet loss 1.1014117 l2_loss 4.0616765 fraction B 0.244418517 lossA 0.754001856 fraction A 0.071137622\n",
      "step 467 loss 0.911809862 fisher_loss 0.0991286486 triplet loss 0.812681198 l2_loss 4.06947136 fraction B 0.142768338 lossA 0.745839775 fraction A 0.0741401538\n",
      "step 468 loss 0.976466894 fisher_loss 0.0982773453 triplet loss 0.878189564 l2_loss 4.07993746 fraction B 0.269805282 lossA 0.739020407 fraction A 0.0771345124\n",
      "step 469 loss 1.0991329 fisher_loss 0.098275 triplet loss 1.00085795 l2_loss 4.09033823 fraction B 0.269764602 lossA 0.729571462 fraction A 0.0779700503\n",
      "step 470 loss 1.18846011 fisher_loss 0.0978586078 triplet loss 1.09060156 l2_loss 4.10125065 fraction B 0.318627268 lossA 0.722622931 fraction A 0.077826418\n",
      "step 471 loss 1.13427055 fisher_loss 0.0978448465 triplet loss 1.03642571 l2_loss 4.11108065 fraction B 0.200815514 lossA 0.723351896 fraction A 0.0761429071\n",
      "step 472 loss 1.03747416 fisher_loss 0.0981565863 triplet loss 0.939317524 l2_loss 4.12088537 fraction B 0.219771653 lossA 0.725564241 fraction A 0.0747830793\n",
      "step 473 loss 1.07293355 fisher_loss 0.0983744487 triplet loss 0.974559069 l2_loss 4.13078 fraction B 0.265519232 lossA 0.733968318 fraction A 0.0733904\n",
      "step 474 loss 1.05922 fisher_loss 0.099094294 triplet loss 0.960125625 l2_loss 4.14031124 fraction B 0.302777171 lossA 0.747360587 fraction A 0.0720806494\n",
      "step 475 loss 1.0298897 fisher_loss 0.100015856 triplet loss 0.929873824 l2_loss 4.14931297 fraction B 0.271516353 lossA 0.759470761 fraction A 0.071033977\n",
      "step 476 loss 1.00169039 fisher_loss 0.100305513 triplet loss 0.90138489 l2_loss 4.15976048 fraction B 0.24597688 lossA 0.759135246 fraction A 0.0712902\n",
      "step 477 loss 1.05760121 fisher_loss 0.0993316695 triplet loss 0.958269596 l2_loss 4.16970539 fraction B 0.282554746 lossA 0.75568676 fraction A 0.0711307675\n",
      "step 478 loss 0.933739126 fisher_loss 0.0986875892 triplet loss 0.835051537 l2_loss 4.17974377 fraction B 0.222833216 lossA 0.745948911 fraction A 0.0706834644\n",
      "step 479 loss 0.941220105 fisher_loss 0.0969905481 triplet loss 0.844229579 l2_loss 4.18936205 fraction B 0.167597771 lossA 0.738165319 fraction A 0.0711107105\n",
      "step 480 loss 0.852146 fisher_loss 0.0956350267 triplet loss 0.756511033 l2_loss 4.19902706 fraction B 0.162316114 lossA 0.74147594 fraction A 0.0703977644\n",
      "step 481 loss 0.954892 fisher_loss 0.0945039317 triplet loss 0.860388041 l2_loss 4.20983124 fraction B 0.28654781 lossA 0.748425186 fraction A 0.0694446191\n",
      "step 482 loss 0.916062713 fisher_loss 0.0937700495 triplet loss 0.822292686 l2_loss 4.21972036 fraction B 0.229991302 lossA 0.76338774 fraction A 0.0680183172\n",
      "step 483 loss 1.07884705 fisher_loss 0.0945331082 triplet loss 0.984313965 l2_loss 4.22916269 fraction B 0.212053 lossA 0.770440876 fraction A 0.0671732873\n",
      "step 484 loss 0.971657872 fisher_loss 0.0949425399 triplet loss 0.876715362 l2_loss 4.23826027 fraction B 0.23690097 lossA 0.774529696 fraction A 0.0668710172\n",
      "step 485 loss 0.985807598 fisher_loss 0.0950482935 triplet loss 0.890759289 l2_loss 4.24747801 fraction B 0.256908357 lossA 0.7768116 fraction A 0.0674941391\n",
      "step 486 loss 1.07295561 fisher_loss 0.0949569866 triplet loss 0.977998614 l2_loss 4.25624704 fraction B 0.139284745 lossA 0.775149047 fraction A 0.0677457452\n",
      "step 487 loss 0.959678292 fisher_loss 0.0954428241 triplet loss 0.864235461 l2_loss 4.26509476 fraction B 0.149913222 lossA 0.775954247 fraction A 0.0677344203\n",
      "step 488 loss 0.988517582 fisher_loss 0.0959455445 triplet loss 0.892572045 l2_loss 4.27368259 fraction B 0.272212833 lossA 0.781754673 fraction A 0.0671233162\n",
      "step 489 loss 1.17146552 fisher_loss 0.0967073068 triplet loss 1.07475817 l2_loss 4.28307199 fraction B 0.315082788 lossA 0.780382395 fraction A 0.0672111586\n",
      "step 490 loss 0.992617846 fisher_loss 0.0965219438 triplet loss 0.896095932 l2_loss 4.29130459 fraction B 0.222785085 lossA 0.773674369 fraction A 0.0680423304\n",
      "step 491 loss 1.00938773 fisher_loss 0.0948761776 triplet loss 0.914511502 l2_loss 4.29967833 fraction B 0.210077465 lossA 0.774185 fraction A 0.0683113486\n",
      "step 492 loss 0.979241252 fisher_loss 0.0938081592 triplet loss 0.885433078 l2_loss 4.30870533 fraction B 0.248785704 lossA 0.777904 fraction A 0.0684941784\n",
      "step 493 loss 1.15483034 fisher_loss 0.0930892304 triplet loss 1.06174111 l2_loss 4.31898212 fraction B 0.332014948 lossA 0.778476536 fraction A 0.0693809688\n",
      "step 494 loss 0.969103098 fisher_loss 0.0927665904 triplet loss 0.876336515 l2_loss 4.32945776 fraction B 0.202306539 lossA 0.7799052 fraction A 0.0698830038\n",
      "step 495 loss 1.12962055 fisher_loss 0.0927989706 triplet loss 1.0368216 l2_loss 4.3388772 fraction B 0.255663782 lossA 0.778141141 fraction A 0.0706579462\n",
      "step 496 loss 1.11987782 fisher_loss 0.093034029 triplet loss 1.02684379 l2_loss 4.34938097 fraction B 0.260155648 lossA 0.780334234 fraction A 0.0708360821\n",
      "step 497 loss 0.828695536 fisher_loss 0.0933765396 triplet loss 0.735319 l2_loss 4.36092091 fraction B 0.198427618 lossA 0.777373314 fraction A 0.0717688128\n",
      "step 498 loss 0.877506256 fisher_loss 0.0939060748 triplet loss 0.783600211 l2_loss 4.37336969 fraction B 0.207495362 lossA 0.780332386 fraction A 0.0721242055\n",
      "step 499 loss 1.00312257 fisher_loss 0.0950119048 triplet loss 0.908110619 l2_loss 4.38638115 fraction B 0.268129766 lossA 0.782550395 fraction A 0.0718103126\n",
      "step 500 loss 0.887465 fisher_loss 0.094704 triplet loss 0.792760968 l2_loss 4.39895821 fraction B 0.254372448 lossA 0.785461485 fraction A 0.0723497048\n",
      "step 501 loss 0.957254052 fisher_loss 0.0943158939 triplet loss 0.862938166 l2_loss 4.41458607 fraction B 0.238527626 lossA 0.790458202 fraction A 0.0727959797\n",
      "step 502 loss 1.01459849 fisher_loss 0.094186455 triplet loss 0.920412 l2_loss 4.43034506 fraction B 0.190656662 lossA 0.792680144 fraction A 0.0720688105\n",
      "step 503 loss 0.944821715 fisher_loss 0.0937010348 triplet loss 0.85112071 l2_loss 4.44589901 fraction B 0.238763228 lossA 0.788174033 fraction A 0.0723136291\n",
      "step 504 loss 1.01887643 fisher_loss 0.0935115591 triplet loss 0.925364852 l2_loss 4.45907784 fraction B 0.229190961 lossA 0.774348617 fraction A 0.0745627061\n",
      "step 505 loss 0.926787555 fisher_loss 0.094187662 triplet loss 0.832599878 l2_loss 4.46951962 fraction B 0.191391468 lossA 0.754217386 fraction A 0.0768039\n",
      "step 506 loss 0.96319586 fisher_loss 0.0962321311 triplet loss 0.866963744 l2_loss 4.480721 fraction B 0.19689399 lossA 0.740402758 fraction A 0.0787372962\n",
      "step 507 loss 1.03690231 fisher_loss 0.0994960889 triplet loss 0.937406242 l2_loss 4.49233532 fraction B 0.239484131 lossA 0.72951448 fraction A 0.0799716711\n",
      "step 508 loss 0.987362742 fisher_loss 0.102190956 triplet loss 0.885171771 l2_loss 4.50362635 fraction B 0.28158313 lossA 0.729183197 fraction A 0.0793305039\n",
      "step 509 loss 1.12065828 fisher_loss 0.103772752 triplet loss 1.01688552 l2_loss 4.51455 fraction B 0.27503562 lossA 0.732115924 fraction A 0.0779823363\n",
      "step 510 loss 1.10547864 fisher_loss 0.104021773 triplet loss 1.00145686 l2_loss 4.52699041 fraction B 0.284702152 lossA 0.736007035 fraction A 0.0769315585\n",
      "step 511 loss 1.0811069 fisher_loss 0.10170567 triplet loss 0.979401231 l2_loss 4.54151964 fraction B 0.296543032 lossA 0.743884206 fraction A 0.0755354688\n",
      "step 512 loss 1.02409029 fisher_loss 0.100293979 triplet loss 0.923796296 l2_loss 4.5554533 fraction B 0.247404471 lossA 0.755848408 fraction A 0.0742337108\n",
      "step 513 loss 1.10649991 fisher_loss 0.0989544243 triplet loss 1.00754547 l2_loss 4.57136869 fraction B 0.17978102 lossA 0.768755555 fraction A 0.0727941841\n",
      "step 514 loss 1.05684483 fisher_loss 0.0982443765 triplet loss 0.958600461 l2_loss 4.58632946 fraction B 0.260194719 lossA 0.776287436 fraction A 0.0718135\n",
      "step 515 loss 1.00113201 fisher_loss 0.097289376 triplet loss 0.903842628 l2_loss 4.60135603 fraction B 0.262602478 lossA 0.782892 fraction A 0.0710838363\n",
      "step 516 loss 0.859594047 fisher_loss 0.0970931426 triplet loss 0.762500882 l2_loss 4.6156497 fraction B 0.186787724 lossA 0.785203874 fraction A 0.0718792379\n",
      "step 517 loss 0.865198731 fisher_loss 0.0979430154 triplet loss 0.767255723 l2_loss 4.62844801 fraction B 0.146298885 lossA 0.786725402 fraction A 0.0721933097\n",
      "step 518 loss 1.04106617 fisher_loss 0.0991297066 triplet loss 0.941936433 l2_loss 4.64189816 fraction B 0.232372314 lossA 0.796629131 fraction A 0.0724141896\n",
      "step 519 loss 0.898690581 fisher_loss 0.10182023 triplet loss 0.796870351 l2_loss 4.65671921 fraction B 0.223486885 lossA 0.808318138 fraction A 0.0712765306\n",
      "step 520 loss 0.840833604 fisher_loss 0.103460096 triplet loss 0.737373531 l2_loss 4.67612076 fraction B 0.152653262 lossA 0.814520299 fraction A 0.0684521645\n",
      "step 521 loss 0.92643714 fisher_loss 0.102027215 triplet loss 0.824409902 l2_loss 4.69462824 fraction B 0.23469314 lossA 0.813735127 fraction A 0.0659782067\n",
      "step 522 loss 1.05371809 fisher_loss 0.101410821 triplet loss 0.952307284 l2_loss 4.71337271 fraction B 0.218194574 lossA 0.81464088 fraction A 0.064364396\n",
      "step 523 loss 1.03411281 fisher_loss 0.101681307 triplet loss 0.932431459 l2_loss 4.73041344 fraction B 0.174457267 lossA 0.819388509 fraction A 0.0628896728\n",
      "step 524 loss 1.02876437 fisher_loss 0.102584578 triplet loss 0.926179826 l2_loss 4.74628878 fraction B 0.155868173 lossA 0.825594366 fraction A 0.0621001758\n",
      "step 525 loss 1.01618993 fisher_loss 0.102439865 triplet loss 0.913750052 l2_loss 4.76118326 fraction B 0.255092114 lossA 0.827962637 fraction A 0.0617186464\n",
      "step 526 loss 0.967239 fisher_loss 0.102957822 triplet loss 0.864281178 l2_loss 4.77470398 fraction B 0.198447376 lossA 0.824220896 fraction A 0.0621553883\n",
      "step 527 loss 0.968466103 fisher_loss 0.102632165 triplet loss 0.865833938 l2_loss 4.78691912 fraction B 0.153808668 lossA 0.82833147 fraction A 0.0624285117\n",
      "step 528 loss 0.921124876 fisher_loss 0.101748608 triplet loss 0.81937629 l2_loss 4.79849863 fraction B 0.207606807 lossA 0.828415692 fraction A 0.0624601506\n",
      "step 529 loss 1.04764581 fisher_loss 0.100801319 triplet loss 0.946844518 l2_loss 4.80800629 fraction B 0.228200331 lossA 0.832709253 fraction A 0.0623150468\n",
      "step 530 loss 0.923306823 fisher_loss 0.100528665 triplet loss 0.822778165 l2_loss 4.81919 fraction B 0.273749292 lossA 0.829298615 fraction A 0.0641325116\n",
      "step 531 loss 0.972510576 fisher_loss 0.0999457836 triplet loss 0.872564793 l2_loss 4.83244896 fraction B 0.230531856 lossA 0.818421125 fraction A 0.0669701472\n",
      "step 532 loss 1.01262736 fisher_loss 0.100792728 triplet loss 0.911834657 l2_loss 4.84410334 fraction B 0.223223627 lossA 0.809671402 fraction A 0.0693472102\n",
      "step 533 loss 0.937073946 fisher_loss 0.101291686 triplet loss 0.83578223 l2_loss 4.85548925 fraction B 0.230340317 lossA 0.791838646 fraction A 0.0725230724\n",
      "step 534 loss 0.853578687 fisher_loss 0.102223709 triplet loss 0.751355 l2_loss 4.86720943 fraction B 0.199764743 lossA 0.782313108 fraction A 0.0760884285\n",
      "step 535 loss 1.10637772 fisher_loss 0.103899397 triplet loss 1.00247836 l2_loss 4.87988091 fraction B 0.292743027 lossA 0.77446866 fraction A 0.0790417269\n",
      "step 536 loss 1.11324835 fisher_loss 0.104989544 triplet loss 1.00825882 l2_loss 4.89076138 fraction B 0.239469498 lossA 0.782326818 fraction A 0.0778852552\n",
      "step 537 loss 0.953098536 fisher_loss 0.104545839 triplet loss 0.848552704 l2_loss 4.90355206 fraction B 0.222071186 lossA 0.785934389 fraction A 0.0749767199\n",
      "step 538 loss 0.962579 fisher_loss 0.10395354 triplet loss 0.858625472 l2_loss 4.91657305 fraction B 0.201199248 lossA 0.793658435 fraction A 0.071060665\n",
      "step 539 loss 1.02780843 fisher_loss 0.104278162 triplet loss 0.923530221 l2_loss 4.92927885 fraction B 0.224093735 lossA 0.803640962 fraction A 0.066947706\n",
      "step 540 loss 1.27869058 fisher_loss 0.104547732 triplet loss 1.17414284 l2_loss 4.94241762 fraction B 0.225950047 lossA 0.809645 fraction A 0.0634829178\n",
      "step 541 loss 1.04908478 fisher_loss 0.105192713 triplet loss 0.943892062 l2_loss 4.95480347 fraction B 0.209597602 lossA 0.822198927 fraction A 0.0606173128\n",
      "step 542 loss 1.05679536 fisher_loss 0.106559411 triplet loss 0.950235903 l2_loss 4.96733284 fraction B 0.217278242 lossA 0.83084017 fraction A 0.0589841381\n",
      "step 543 loss 0.896903396 fisher_loss 0.106765695 triplet loss 0.790137708 l2_loss 4.97976875 fraction B 0.191762388 lossA 0.85221 fraction A 0.0569299161\n",
      "step 544 loss 1.06614518 fisher_loss 0.108424321 triplet loss 0.957720876 l2_loss 4.99465275 fraction B 0.205389664 lossA 0.863903224 fraction A 0.0558483042\n",
      "step 545 loss 1.21522224 fisher_loss 0.108518593 triplet loss 1.10670364 l2_loss 5.00922441 fraction B 0.253942817 lossA 0.871090055 fraction A 0.0556770265\n",
      "step 546 loss 1.1007477 fisher_loss 0.107450135 triplet loss 0.993297577 l2_loss 5.02292967 fraction B 0.255199701 lossA 0.87324971 fraction A 0.0562002137\n",
      "step 547 loss 1.31940985 fisher_loss 0.106989056 triplet loss 1.21242082 l2_loss 5.03813 fraction B 0.265803963 lossA 0.86952436 fraction A 0.0573896803\n",
      "step 548 loss 0.881842315 fisher_loss 0.107512034 triplet loss 0.774330258 l2_loss 5.0519 fraction B 0.219213158 lossA 0.848316312 fraction A 0.0594832785\n",
      "step 549 loss 0.88201493 fisher_loss 0.105190791 triplet loss 0.776824117 l2_loss 5.06469488 fraction B 0.202462479 lossA 0.816352487 fraction A 0.063093245\n",
      "step 550 loss 0.839342 fisher_loss 0.102800854 triplet loss 0.736541152 l2_loss 5.07592297 fraction B 0.0894061327 lossA 0.788926899 fraction A 0.0670990497\n",
      "step 551 loss 0.938530207 fisher_loss 0.101339042 triplet loss 0.837191164 l2_loss 5.08615446 fraction B 0.249469101 lossA 0.761436403 fraction A 0.0718528405\n",
      "step 552 loss 1.08527422 fisher_loss 0.101433367 triplet loss 0.983840883 l2_loss 5.09609175 fraction B 0.151548356 lossA 0.734897852 fraction A 0.0760648176\n",
      "step 553 loss 0.924399614 fisher_loss 0.101959363 triplet loss 0.822440267 l2_loss 5.10480404 fraction B 0.149402112 lossA 0.717654109 fraction A 0.0783870742\n",
      "step 554 loss 1.0689038 fisher_loss 0.101997122 triplet loss 0.966906667 l2_loss 5.11301851 fraction B 0.156314552 lossA 0.712844431 fraction A 0.0780554712\n",
      "step 555 loss 0.988095462 fisher_loss 0.101323739 triplet loss 0.886771739 l2_loss 5.12061453 fraction B 0.200993627 lossA 0.719881296 fraction A 0.0747474432\n",
      "step 556 loss 1.09231019 fisher_loss 0.10037034 triplet loss 0.991939902 l2_loss 5.12846088 fraction B 0.230649814 lossA 0.736436844 fraction A 0.0701810643\n",
      "step 557 loss 1.12304318 fisher_loss 0.101054229 triplet loss 1.02198899 l2_loss 5.1360383 fraction B 0.250559151 lossA 0.75387764 fraction A 0.0662564\n",
      "step 558 loss 1.06963944 fisher_loss 0.102672964 triplet loss 0.96696651 l2_loss 5.14402151 fraction B 0.194983408 lossA 0.779571414 fraction A 0.0619287118\n",
      "step 559 loss 1.04960322 fisher_loss 0.104215041 triplet loss 0.945388198 l2_loss 5.1530323 fraction B 0.235375792 lossA 0.801387608 fraction A 0.0592222884\n",
      "step 560 loss 1.19238448 fisher_loss 0.104692698 triplet loss 1.08769178 l2_loss 5.16246843 fraction B 0.242268786 lossA 0.822328746 fraction A 0.0575566329\n",
      "step 561 loss 1.04719985 fisher_loss 0.10532508 triplet loss 0.941874802 l2_loss 5.17209435 fraction B 0.280352026 lossA 0.831211507 fraction A 0.056964267\n",
      "step 562 loss 0.979336202 fisher_loss 0.104159974 triplet loss 0.875176251 l2_loss 5.18100119 fraction B 0.226236671 lossA 0.830566585 fraction A 0.0565302372\n",
      "step 563 loss 1.1224966 fisher_loss 0.102109179 triplet loss 1.02038741 l2_loss 5.19005966 fraction B 0.241582185 lossA 0.818843722 fraction A 0.0569760725\n",
      "step 564 loss 0.902465224 fisher_loss 0.100082643 triplet loss 0.802382588 l2_loss 5.19793034 fraction B 0.199853703 lossA 0.792787194 fraction A 0.0585746728\n",
      "step 565 loss 1.16372478 fisher_loss 0.0987743139 triplet loss 1.06495047 l2_loss 5.20759058 fraction B 0.246543616 lossA 0.768083453 fraction A 0.0603976771\n",
      "step 566 loss 1.06089258 fisher_loss 0.0982699171 triplet loss 0.962622643 l2_loss 5.21730947 fraction B 0.209795922 lossA 0.74235177 fraction A 0.0631204173\n",
      "step 567 loss 1.01265752 fisher_loss 0.0980760455 triplet loss 0.914581478 l2_loss 5.2277956 fraction B 0.20029293 lossA 0.729923964 fraction A 0.0654712245\n",
      "step 568 loss 0.922718763 fisher_loss 0.0977791846 triplet loss 0.824939609 l2_loss 5.2404213 fraction B 0.172575027 lossA 0.723372161 fraction A 0.0672181919\n",
      "step 569 loss 1.14172554 fisher_loss 0.0969933718 triplet loss 1.04473221 l2_loss 5.25255346 fraction B 0.336822808 lossA 0.721839905 fraction A 0.0684962347\n",
      "step 570 loss 0.937495649 fisher_loss 0.0964644402 triplet loss 0.841031194 l2_loss 5.26488495 fraction B 0.282744944 lossA 0.721639931 fraction A 0.0689608\n",
      "step 571 loss 0.906204343 fisher_loss 0.0953824893 triplet loss 0.810821831 l2_loss 5.27575064 fraction B 0.160065234 lossA 0.72952038 fraction A 0.0675947368\n",
      "step 572 loss 0.919658542 fisher_loss 0.0952184498 triplet loss 0.824440062 l2_loss 5.28682 fraction B 0.138841256 lossA 0.746191263 fraction A 0.0659126639\n",
      "step 573 loss 0.964973807 fisher_loss 0.0973064601 triplet loss 0.867667377 l2_loss 5.29907131 fraction B 0.218883738 lossA 0.761899352 fraction A 0.064329274\n",
      "step 574 loss 1.06927121 fisher_loss 0.100281261 triplet loss 0.968989909 l2_loss 5.31069231 fraction B 0.222594753 lossA 0.781958878 fraction A 0.0629104897\n",
      "step 575 loss 0.785751 fisher_loss 0.104058608 triplet loss 0.681692362 l2_loss 5.32405472 fraction B 0.19597289 lossA 0.800166309 fraction A 0.0621620603\n",
      "step 576 loss 0.9862414 fisher_loss 0.106566466 triplet loss 0.879674911 l2_loss 5.33814383 fraction B 0.290805876 lossA 0.812679648 fraction A 0.0615217\n",
      "step 577 loss 1.06620347 fisher_loss 0.106976472 triplet loss 0.959227 l2_loss 5.35409498 fraction B 0.244951144 lossA 0.817478955 fraction A 0.0616990328\n",
      "step 578 loss 0.816224098 fisher_loss 0.105353668 triplet loss 0.710870445 l2_loss 5.36975193 fraction B 0.207688376 lossA 0.816124082 fraction A 0.061988689\n",
      "step 579 loss 1.00772727 fisher_loss 0.10262756 triplet loss 0.90509975 l2_loss 5.38652754 fraction B 0.220097244 lossA 0.813875139 fraction A 0.0625883862\n",
      "step 580 loss 1.16919816 fisher_loss 0.100724898 triplet loss 1.06847322 l2_loss 5.40373135 fraction B 0.281480938 lossA 0.801324725 fraction A 0.0641224682\n",
      "step 581 loss 1.05350089 fisher_loss 0.0989495739 triplet loss 0.95455128 l2_loss 5.41757822 fraction B 0.213592052 lossA 0.783848464 fraction A 0.0657709688\n",
      "step 582 loss 1.16781723 fisher_loss 0.0981266573 triplet loss 1.06969059 l2_loss 5.43155336 fraction B 0.3178204 lossA 0.765115142 fraction A 0.0664466247\n",
      "step 583 loss 0.980825543 fisher_loss 0.0972876623 triplet loss 0.883537889 l2_loss 5.44377947 fraction B 0.249578908 lossA 0.751751125 fraction A 0.0670378208\n",
      "step 584 loss 0.967960536 fisher_loss 0.096910812 triplet loss 0.871049702 l2_loss 5.45752096 fraction B 0.214497209 lossA 0.743642747 fraction A 0.067018725\n",
      "step 585 loss 0.914230108 fisher_loss 0.0958925635 triplet loss 0.81833756 l2_loss 5.46979761 fraction B 0.25999 lossA 0.738939762 fraction A 0.067703329\n",
      "step 586 loss 1.1300385 fisher_loss 0.0943450853 triplet loss 1.03569341 l2_loss 5.48094 fraction B 0.281999648 lossA 0.734683 fraction A 0.0686945319\n",
      "step 587 loss 0.841750801 fisher_loss 0.0929713473 triplet loss 0.748779476 l2_loss 5.49123669 fraction B 0.183740199 lossA 0.734240294 fraction A 0.0691933781\n",
      "step 588 loss 0.820234597 fisher_loss 0.0914513 triplet loss 0.728783309 l2_loss 5.50009489 fraction B 0.205134735 lossA 0.730974138 fraction A 0.0688866\n",
      "step 589 loss 0.924985051 fisher_loss 0.0902445 triplet loss 0.83474052 l2_loss 5.50756693 fraction B 0.143329024 lossA 0.736789346 fraction A 0.06819693\n",
      "step 590 loss 0.931717336 fisher_loss 0.0892393813 triplet loss 0.842478 l2_loss 5.51425505 fraction B 0.164372027 lossA 0.746596694 fraction A 0.0660376772\n",
      "step 591 loss 0.933951378 fisher_loss 0.089364782 triplet loss 0.844586611 l2_loss 5.52225542 fraction B 0.2684201 lossA 0.764432847 fraction A 0.0637891442\n",
      "step 592 loss 0.896548331 fisher_loss 0.090448305 triplet loss 0.8061 l2_loss 5.5302577 fraction B 0.147919059 lossA 0.787281394 fraction A 0.0622061975\n",
      "step 593 loss 0.754283369 fisher_loss 0.0921787694 triplet loss 0.662104607 l2_loss 5.53902102 fraction B 0.114676505 lossA 0.821489394 fraction A 0.0602952838\n",
      "step 594 loss 0.901750088 fisher_loss 0.0972667485 triplet loss 0.804483354 l2_loss 5.54861546 fraction B 0.21085538 lossA 0.840464473 fraction A 0.0592604168\n",
      "step 595 loss 1.04459786 fisher_loss 0.100619353 triplet loss 0.943978548 l2_loss 5.55877 fraction B 0.165488303 lossA 0.852533758 fraction A 0.0594760925\n",
      "step 596 loss 1.0302496 fisher_loss 0.103428304 triplet loss 0.926821232 l2_loss 5.56771 fraction B 0.126216516 lossA 0.843198895 fraction A 0.0598329864\n",
      "step 597 loss 1.1108973 fisher_loss 0.101716362 triplet loss 1.0091809 l2_loss 5.57672787 fraction B 0.184761494 lossA 0.826906 fraction A 0.0603992902\n",
      "step 598 loss 1.08612156 fisher_loss 0.100029185 triplet loss 0.986092389 l2_loss 5.58558083 fraction B 0.140100852 lossA 0.810539722 fraction A 0.0612203106\n",
      "step 599 loss 0.976690054 fisher_loss 0.0984365642 triplet loss 0.87825352 l2_loss 5.59497118 fraction B 0.179419577 lossA 0.788945615 fraction A 0.0625379086\n",
      "step 600 loss 1.18858099 fisher_loss 0.0971058831 triplet loss 1.09147513 l2_loss 5.60486031 fraction B 0.1333296 lossA 0.776642501 fraction A 0.0638101175\n",
      "step 601 loss 0.918118596 fisher_loss 0.0951128602 triplet loss 0.823005736 l2_loss 5.61591053 fraction B 0.212935969 lossA 0.7756 fraction A 0.0638816059\n",
      "step 602 loss 0.857188284 fisher_loss 0.0936078504 triplet loss 0.763580441 l2_loss 5.6270442 fraction B 0.164815485 lossA 0.785427332 fraction A 0.0628490895\n",
      "step 603 loss 1.10544515 fisher_loss 0.0936441347 triplet loss 1.011801 l2_loss 5.63858795 fraction B 0.310676455 lossA 0.799923599 fraction A 0.0614717342\n",
      "step 604 loss 0.982694864 fisher_loss 0.0963136107 triplet loss 0.886381269 l2_loss 5.64953423 fraction B 0.198458016 lossA 0.82067281 fraction A 0.059715014\n",
      "step 605 loss 1.11759973 fisher_loss 0.100374162 triplet loss 1.0172255 l2_loss 5.66072655 fraction B 0.175566658 lossA 0.828614295 fraction A 0.0594808236\n",
      "step 606 loss 1.12576616 fisher_loss 0.102361947 triplet loss 1.02340424 l2_loss 5.66998434 fraction B 0.247008234 lossA 0.821848571 fraction A 0.0599526837\n",
      "step 607 loss 0.848975837 fisher_loss 0.099669531 triplet loss 0.749306321 l2_loss 5.67823076 fraction B 0.152481616 lossA 0.812049627 fraction A 0.0611717738\n",
      "step 608 loss 0.907386243 fisher_loss 0.0961052179 triplet loss 0.811281 l2_loss 5.68713045 fraction B 0.130975604 lossA 0.801041365 fraction A 0.0626148582\n",
      "step 609 loss 1.02476072 fisher_loss 0.0929639 triplet loss 0.931796849 l2_loss 5.69807529 fraction B 0.261574477 lossA 0.785736859 fraction A 0.064818\n",
      "step 610 loss 0.802647948 fisher_loss 0.0917932615 triplet loss 0.710854709 l2_loss 5.70843649 fraction B 0.198221549 lossA 0.779640198 fraction A 0.0664868429\n",
      "step 611 loss 0.994460106 fisher_loss 0.0929133594 triplet loss 0.901546776 l2_loss 5.71966 fraction B 0.208657146 lossA 0.777350128 fraction A 0.0678799599\n",
      "step 612 loss 1.11273801 fisher_loss 0.0949687511 triplet loss 1.01776922 l2_loss 5.73002911 fraction B 0.272196084 lossA 0.774991035 fraction A 0.068797\n",
      "step 613 loss 1.045717 fisher_loss 0.096090287 triplet loss 0.949626744 l2_loss 5.74055147 fraction B 0.15164575 lossA 0.773704827 fraction A 0.0686013\n",
      "step 614 loss 0.906616926 fisher_loss 0.0959205478 triplet loss 0.810696363 l2_loss 5.75097227 fraction B 0.140128642 lossA 0.783927 fraction A 0.0674349368\n",
      "step 615 loss 1.22482526 fisher_loss 0.0952171758 triplet loss 1.12960804 l2_loss 5.76286793 fraction B 0.279848874 lossA 0.792096138 fraction A 0.0658329576\n",
      "step 616 loss 0.987734199 fisher_loss 0.0943580717 triplet loss 0.893376112 l2_loss 5.77431154 fraction B 0.256413 lossA 0.802455 fraction A 0.0637713298\n",
      "step 617 loss 1.10505915 fisher_loss 0.0939899459 triplet loss 1.01106918 l2_loss 5.78487968 fraction B 0.257307619 lossA 0.800128877 fraction A 0.0625236109\n",
      "step 618 loss 0.788349926 fisher_loss 0.0927075 triplet loss 0.695642412 l2_loss 5.79521227 fraction B 0.170037478 lossA 0.79124403 fraction A 0.0622484311\n",
      "step 619 loss 0.996053457 fisher_loss 0.090626128 triplet loss 0.905427337 l2_loss 5.80738878 fraction B 0.21112518 lossA 0.78321135 fraction A 0.0619156957\n",
      "step 620 loss 0.7571944 fisher_loss 0.0900652707 triplet loss 0.667129099 l2_loss 5.8202 fraction B 0.141611308 lossA 0.77725 fraction A 0.0614209212\n",
      "step 621 loss 1.06865942 fisher_loss 0.0898367614 triplet loss 0.978822649 l2_loss 5.83508 fraction B 0.272261083 lossA 0.773624897 fraction A 0.0603946336\n",
      "step 622 loss 0.917584121 fisher_loss 0.0906776041 triplet loss 0.826906502 l2_loss 5.8497715 fraction B 0.177783027 lossA 0.775398076 fraction A 0.0596681237\n",
      "step 623 loss 0.918578327 fisher_loss 0.0909602419 triplet loss 0.827618062 l2_loss 5.86375093 fraction B 0.193977937 lossA 0.778334141 fraction A 0.0596067533\n",
      "step 624 loss 1.10724843 fisher_loss 0.090515919 triplet loss 1.01673245 l2_loss 5.8769145 fraction B 0.267916292 lossA 0.780204237 fraction A 0.0602477677\n",
      "step 625 loss 1.1277684 fisher_loss 0.0902066231 triplet loss 1.03756177 l2_loss 5.89030313 fraction B 0.228519723 lossA 0.781783 fraction A 0.0613843687\n",
      "step 626 loss 1.07151294 fisher_loss 0.0903531089 triplet loss 0.981159866 l2_loss 5.90249538 fraction B 0.267076612 lossA 0.789766133 fraction A 0.0618967786\n",
      "step 627 loss 1.17863 fisher_loss 0.0911319554 triplet loss 1.08749807 l2_loss 5.91413546 fraction B 0.217008531 lossA 0.802834332 fraction A 0.0619882494\n",
      "step 628 loss 0.925372958 fisher_loss 0.0922688842 triplet loss 0.833104074 l2_loss 5.92481852 fraction B 0.1740008 lossA 0.816322267 fraction A 0.0619099401\n",
      "step 629 loss 0.985071421 fisher_loss 0.0934376791 triplet loss 0.891633749 l2_loss 5.9360342 fraction B 0.18827562 lossA 0.830105722 fraction A 0.060265515\n",
      "step 630 loss 1.04074931 fisher_loss 0.0940616801 triplet loss 0.946687579 l2_loss 5.94755125 fraction B 0.231259972 lossA 0.837132692 fraction A 0.0585726574\n",
      "step 631 loss 0.874568 fisher_loss 0.0935990065 triplet loss 0.780968964 l2_loss 5.95857239 fraction B 0.163693026 lossA 0.843556643 fraction A 0.0576261431\n",
      "step 632 loss 1.11654234 fisher_loss 0.0937717631 triplet loss 1.02277052 l2_loss 5.97031116 fraction B 0.179776296 lossA 0.839323044 fraction A 0.0568562262\n",
      "step 633 loss 1.10796392 fisher_loss 0.0921086594 triplet loss 1.01585531 l2_loss 5.98125648 fraction B 0.2605142 lossA 0.829341233 fraction A 0.0563342832\n",
      "step 634 loss 1.18039358 fisher_loss 0.0906536952 triplet loss 1.08973992 l2_loss 5.99044228 fraction B 0.217010647 lossA 0.815282881 fraction A 0.0570877045\n",
      "step 635 loss 1.07172096 fisher_loss 0.0900336877 triplet loss 0.981687307 l2_loss 5.99885416 fraction B 0.252303481 lossA 0.802118301 fraction A 0.0583428666\n",
      "step 636 loss 0.850122631 fisher_loss 0.0904085189 triplet loss 0.759714127 l2_loss 6.00777054 fraction B 0.12471243 lossA 0.789182246 fraction A 0.0606614165\n",
      "step 637 loss 1.22343898 fisher_loss 0.0905723125 triplet loss 1.13286662 l2_loss 6.01722574 fraction B 0.206694618 lossA 0.784163 fraction A 0.0621317402\n",
      "step 638 loss 0.757794678 fisher_loss 0.0896288231 triplet loss 0.668165863 l2_loss 6.02911949 fraction B 0.115176253 lossA 0.784418404 fraction A 0.0632654801\n",
      "step 639 loss 0.885031521 fisher_loss 0.0889848694 triplet loss 0.796046674 l2_loss 6.04091406 fraction B 0.156259194 lossA 0.788075924 fraction A 0.0635211542\n",
      "step 640 loss 1.14816058 fisher_loss 0.0899872929 triplet loss 1.0581733 l2_loss 6.05589962 fraction B 0.204013079 lossA 0.798101723 fraction A 0.0628644824\n",
      "step 641 loss 1.02933347 fisher_loss 0.0933022946 triplet loss 0.936031222 l2_loss 6.0700922 fraction B 0.215648025 lossA 0.811062396 fraction A 0.0613095798\n",
      "step 642 loss 0.96076721 fisher_loss 0.0969583467 triplet loss 0.86380887 l2_loss 6.08544683 fraction B 0.267724574 lossA 0.817529321 fraction A 0.0597275868\n",
      "step 643 loss 1.05490124 fisher_loss 0.0978744403 triplet loss 0.957026839 l2_loss 6.09941244 fraction B 0.208309293 lossA 0.819131732 fraction A 0.0584997\n",
      "step 644 loss 0.733601689 fisher_loss 0.0974519402 triplet loss 0.636149764 l2_loss 6.1127944 fraction B 0.193786711 lossA 0.819940925 fraction A 0.0577000529\n",
      "step 645 loss 0.918467283 fisher_loss 0.0959018692 triplet loss 0.822565436 l2_loss 6.12640762 fraction B 0.238457933 lossA 0.815451801 fraction A 0.0569721498\n",
      "step 646 loss 1.01115072 fisher_loss 0.0941960588 triplet loss 0.916954637 l2_loss 6.13964558 fraction B 0.194385275 lossA 0.815699 fraction A 0.0557099096\n",
      "step 647 loss 0.924895763 fisher_loss 0.0944482386 triplet loss 0.830447555 l2_loss 6.1537776 fraction B 0.221820131 lossA 0.814806163 fraction A 0.055058483\n",
      "step 648 loss 1.14202917 fisher_loss 0.0950730816 triplet loss 1.04695606 l2_loss 6.16758823 fraction B 0.238905936 lossA 0.802649379 fraction A 0.0557825\n",
      "step 649 loss 0.912643731 fisher_loss 0.0954031199 triplet loss 0.817240596 l2_loss 6.17997026 fraction B 0.25931856 lossA 0.795860946 fraction A 0.0565122\n",
      "step 650 loss 0.933244407 fisher_loss 0.0959993154 triplet loss 0.837245107 l2_loss 6.19245243 fraction B 0.220246792 lossA 0.783796608 fraction A 0.0579400361\n",
      "step 651 loss 1.02179646 fisher_loss 0.0958640873 triplet loss 0.925932407 l2_loss 6.20200396 fraction B 0.216121376 lossA 0.768493891 fraction A 0.0601458512\n",
      "step 652 loss 1.04209089 fisher_loss 0.0949718952 triplet loss 0.947119057 l2_loss 6.21133947 fraction B 0.27211538 lossA 0.766518235 fraction A 0.0611360297\n",
      "step 653 loss 1.04826891 fisher_loss 0.0925266296 triplet loss 0.95574224 l2_loss 6.22194 fraction B 0.219193 lossA 0.770212591 fraction A 0.0610416979\n",
      "step 654 loss 1.00993109 fisher_loss 0.0902922079 triplet loss 0.919638932 l2_loss 6.23304462 fraction B 0.179456398 lossA 0.779026568 fraction A 0.0602943674\n",
      "step 655 loss 1.07012784 fisher_loss 0.0901702121 triplet loss 0.97995764 l2_loss 6.24444151 fraction B 0.225062698 lossA 0.784612 fraction A 0.0605501868\n",
      "step 656 loss 0.971975803 fisher_loss 0.0922754779 triplet loss 0.879700303 l2_loss 6.25478077 fraction B 0.168222576 lossA 0.789988637 fraction A 0.0612441786\n",
      "step 657 loss 0.863451481 fisher_loss 0.0957755744 triplet loss 0.767675936 l2_loss 6.26587105 fraction B 0.148891479 lossA 0.795859277 fraction A 0.0617372692\n",
      "step 658 loss 0.903241515 fisher_loss 0.0993778 triplet loss 0.803863704 l2_loss 6.27811193 fraction B 0.175448552 lossA 0.805060744 fraction A 0.0617092587\n",
      "step 659 loss 1.09145606 fisher_loss 0.101247199 triplet loss 0.990208805 l2_loss 6.29294252 fraction B 0.265099 lossA 0.808787942 fraction A 0.0625419393\n",
      "step 660 loss 0.903204679 fisher_loss 0.102332115 triplet loss 0.800872564 l2_loss 6.30634975 fraction B 0.268401146 lossA 0.814306676 fraction A 0.062717475\n",
      "step 661 loss 0.85710144 fisher_loss 0.101867445 triplet loss 0.755234 l2_loss 6.32093859 fraction B 0.230072662 lossA 0.809807956 fraction A 0.0620827265\n",
      "step 662 loss 0.95706296 fisher_loss 0.0972097069 triplet loss 0.859853268 l2_loss 6.33673763 fraction B 0.218956143 lossA 0.800253 fraction A 0.0609763339\n",
      "step 663 loss 1.06533337 fisher_loss 0.0931353867 triplet loss 0.97219795 l2_loss 6.35144186 fraction B 0.241747156 lossA 0.788628221 fraction A 0.0601736046\n",
      "step 664 loss 0.856506109 fisher_loss 0.0929689 triplet loss 0.763537228 l2_loss 6.36414051 fraction B 0.244635582 lossA 0.778461158 fraction A 0.0592214465\n",
      "step 665 loss 1.16241455 fisher_loss 0.0961934254 triplet loss 1.06622112 l2_loss 6.37679243 fraction B 0.228181988 lossA 0.763310432 fraction A 0.0596775822\n",
      "step 666 loss 0.899112463 fisher_loss 0.10096316 triplet loss 0.798149288 l2_loss 6.38823891 fraction B 0.224802583 lossA 0.756299615 fraction A 0.0596047342\n",
      "step 667 loss 1.03151822 fisher_loss 0.103900559 triplet loss 0.927617669 l2_loss 6.40096664 fraction B 0.212383673 lossA 0.75750041 fraction A 0.059538234\n",
      "step 668 loss 0.979422271 fisher_loss 0.103116259 triplet loss 0.876306 l2_loss 6.41311264 fraction B 0.176567599 lossA 0.769348145 fraction A 0.0587541275\n",
      "step 669 loss 0.920568764 fisher_loss 0.0998361334 triplet loss 0.820732653 l2_loss 6.4252634 fraction B 0.209024936 lossA 0.790273726 fraction A 0.056994915\n",
      "step 670 loss 0.91176635 fisher_loss 0.0978390798 triplet loss 0.813927293 l2_loss 6.43752384 fraction B 0.0728015527 lossA 0.814265847 fraction A 0.0559947304\n",
      "step 671 loss 1.11422336 fisher_loss 0.0992798507 triplet loss 1.01494348 l2_loss 6.44899178 fraction B 0.200306863 lossA 0.824552417 fraction A 0.0566824526\n",
      "step 672 loss 0.852074862 fisher_loss 0.101205781 triplet loss 0.750869095 l2_loss 6.45896244 fraction B 0.144137934 lossA 0.821432233 fraction A 0.0591618344\n",
      "step 673 loss 1.06649232 fisher_loss 0.102878504 triplet loss 0.963613868 l2_loss 6.47044134 fraction B 0.152337655 lossA 0.817664444 fraction A 0.0612475127\n",
      "step 674 loss 1.05527735 fisher_loss 0.104457192 triplet loss 0.950820148 l2_loss 6.48153591 fraction B 0.163221672 lossA 0.817389309 fraction A 0.0637460724\n",
      "step 675 loss 0.971443892 fisher_loss 0.106556 triplet loss 0.864887893 l2_loss 6.49305344 fraction B 0.196827278 lossA 0.816149354 fraction A 0.0657844171\n",
      "step 676 loss 1.08693206 fisher_loss 0.107727781 triplet loss 0.979204237 l2_loss 6.50492764 fraction B 0.178769335 lossA 0.812777519 fraction A 0.0675013661\n",
      "step 677 loss 1.13513815 fisher_loss 0.10833481 triplet loss 1.02680337 l2_loss 6.51525784 fraction B 0.182519749 lossA 0.800747216 fraction A 0.069972463\n",
      "step 678 loss 1.01275742 fisher_loss 0.106968805 triplet loss 0.9057886 l2_loss 6.5246315 fraction B 0.224193841 lossA 0.790118039 fraction A 0.0712619\n",
      "step 679 loss 1.16819847 fisher_loss 0.105016127 triplet loss 1.06318235 l2_loss 6.53365946 fraction B 0.270971566 lossA 0.783228636 fraction A 0.0711776167\n",
      "step 680 loss 1.04671252 fisher_loss 0.10078039 triplet loss 0.94593209 l2_loss 6.54348946 fraction B 0.221824199 lossA 0.777276158 fraction A 0.0705667734\n",
      "step 681 loss 1.04854429 fisher_loss 0.0971527323 triplet loss 0.951391518 l2_loss 6.55471468 fraction B 0.226359844 lossA 0.777198195 fraction A 0.0688566118\n",
      "step 682 loss 1.09208632 fisher_loss 0.0955897 triplet loss 0.996496618 l2_loss 6.56532812 fraction B 0.251830041 lossA 0.775889516 fraction A 0.0679828674\n",
      "step 683 loss 1.13942957 fisher_loss 0.0950440466 triplet loss 1.04438555 l2_loss 6.57625675 fraction B 0.317638576 lossA 0.77577 fraction A 0.0673155636\n",
      "step 684 loss 0.884820342 fisher_loss 0.095656611 triplet loss 0.789163709 l2_loss 6.58673382 fraction B 0.188776791 lossA 0.778072059 fraction A 0.0658146665\n",
      "step 685 loss 0.961880326 fisher_loss 0.095897384 triplet loss 0.86598295 l2_loss 6.59467411 fraction B 0.225144714 lossA 0.782288611 fraction A 0.0630515665\n",
      "step 686 loss 0.843243957 fisher_loss 0.0958078206 triplet loss 0.747436166 l2_loss 6.60290813 fraction B 0.160632223 lossA 0.795382559 fraction A 0.059474919\n",
      "step 687 loss 1.05300283 fisher_loss 0.0963937 triplet loss 0.95660919 l2_loss 6.61201715 fraction B 0.244884387 lossA 0.811443031 fraction A 0.0562974401\n",
      "step 688 loss 1.00040805 fisher_loss 0.098052904 triplet loss 0.902355134 l2_loss 6.62022638 fraction B 0.243891448 lossA 0.826334298 fraction A 0.0535777062\n",
      "step 689 loss 0.918587148 fisher_loss 0.0999075174 triplet loss 0.818679631 l2_loss 6.62789726 fraction B 0.199870169 lossA 0.840972424 fraction A 0.0512914211\n",
      "step 690 loss 1.18498528 fisher_loss 0.101871751 triplet loss 1.08311355 l2_loss 6.63678312 fraction B 0.223771319 lossA 0.843014717 fraction A 0.0504491329\n",
      "step 691 loss 0.832675636 fisher_loss 0.102725647 triplet loss 0.72995 l2_loss 6.64517164 fraction B 0.158523411 lossA 0.844439864 fraction A 0.0508973151\n",
      "step 692 loss 1.07935441 fisher_loss 0.10159938 triplet loss 0.97775507 l2_loss 6.65537262 fraction B 0.168345645 lossA 0.841213107 fraction A 0.0516616963\n",
      "step 693 loss 0.980987608 fisher_loss 0.0988213345 triplet loss 0.882166266 l2_loss 6.66362619 fraction B 0.182395607 lossA 0.843306661 fraction A 0.0522615798\n",
      "step 694 loss 0.979251146 fisher_loss 0.0967466384 triplet loss 0.882504523 l2_loss 6.67259 fraction B 0.219444439 lossA 0.844739199 fraction A 0.053808488\n",
      "step 695 loss 1.08465648 fisher_loss 0.0964129 triplet loss 0.988243639 l2_loss 6.68157721 fraction B 0.192458585 lossA 0.842651665 fraction A 0.0562414229\n",
      "step 696 loss 1.0756861 fisher_loss 0.0984351113 triplet loss 0.977251 l2_loss 6.6913538 fraction B 0.220472291 lossA 0.836070716 fraction A 0.0595223233\n",
      "step 697 loss 0.931497216 fisher_loss 0.100982659 triplet loss 0.83051455 l2_loss 6.70262766 fraction B 0.164328694 lossA 0.832621276 fraction A 0.0621293932\n",
      "step 698 loss 1.25564623 fisher_loss 0.102877595 triplet loss 1.15276861 l2_loss 6.71473646 fraction B 0.205608159 lossA 0.827401459 fraction A 0.0645237938\n",
      "step 699 loss 1.05325246 fisher_loss 0.104409367 triplet loss 0.948843062 l2_loss 6.72668028 fraction B 0.14380987 lossA 0.827932239 fraction A 0.0647606626\n",
      "step 700 loss 1.008865 fisher_loss 0.104099542 triplet loss 0.904765487 l2_loss 6.7383 fraction B 0.135477945 lossA 0.820495725 fraction A 0.065276593\n",
      "step 701 loss 0.991093934 fisher_loss 0.102224462 triplet loss 0.888869464 l2_loss 6.7494278 fraction B 0.252791584 lossA 0.810606837 fraction A 0.0642684922\n",
      "step 702 loss 0.927980781 fisher_loss 0.0994925573 triplet loss 0.828488231 l2_loss 6.76152802 fraction B 0.226273239 lossA 0.798507154 fraction A 0.0626372918\n",
      "step 703 loss 0.937240958 fisher_loss 0.0987821221 triplet loss 0.838458836 l2_loss 6.77480316 fraction B 0.160003558 lossA 0.793879807 fraction A 0.06216437\n",
      "step 704 loss 0.943561852 fisher_loss 0.102506943 triplet loss 0.841054916 l2_loss 6.78752661 fraction B 0.136544064 lossA 0.787023604 fraction A 0.0631297603\n",
      "step 705 loss 0.771238625 fisher_loss 0.105676487 triplet loss 0.665562153 l2_loss 6.7992363 fraction B 0.19385469 lossA 0.79411155 fraction A 0.0626014397\n",
      "step 706 loss 1.00686979 fisher_loss 0.107749835 triplet loss 0.899119914 l2_loss 6.81186867 fraction B 0.202880055 lossA 0.801625 fraction A 0.0623353571\n",
      "step 707 loss 0.738812089 fisher_loss 0.105929956 triplet loss 0.632882118 l2_loss 6.82379818 fraction B 0.11941392 lossA 0.815247476 fraction A 0.061058782\n",
      "step 708 loss 1.05712342 fisher_loss 0.102549449 triplet loss 0.954574 l2_loss 6.83583164 fraction B 0.222754791 lossA 0.82576412 fraction A 0.0595854148\n",
      "step 709 loss 0.893336415 fisher_loss 0.0998125598 triplet loss 0.793523848 l2_loss 6.84871817 fraction B 0.124956079 lossA 0.828719676 fraction A 0.0591245145\n",
      "step 710 loss 0.936571181 fisher_loss 0.0980539694 triplet loss 0.838517189 l2_loss 6.86329746 fraction B 0.160347953 lossA 0.834479272 fraction A 0.0581499934\n",
      "step 711 loss 0.807446659 fisher_loss 0.0970190689 triplet loss 0.710427582 l2_loss 6.87761593 fraction B 0.149619132 lossA 0.83361 fraction A 0.0572895221\n",
      "step 712 loss 0.915192962 fisher_loss 0.0962563828 triplet loss 0.818936586 l2_loss 6.89281321 fraction B 0.133978248 lossA 0.832865417 fraction A 0.0567836389\n",
      "step 713 loss 0.769913733 fisher_loss 0.096938245 triplet loss 0.672975481 l2_loss 6.91029119 fraction B 0.126776367 lossA 0.830589235 fraction A 0.0570807755\n",
      "step 714 loss 1.10013735 fisher_loss 0.0976367146 triplet loss 1.00250065 l2_loss 6.92904758 fraction B 0.231434524 lossA 0.825943112 fraction A 0.0577210598\n",
      "step 715 loss 0.972382426 fisher_loss 0.0973675251 triplet loss 0.875014901 l2_loss 6.94803381 fraction B 0.13986735 lossA 0.831409097 fraction A 0.0576197654\n",
      "step 716 loss 0.931578577 fisher_loss 0.0971595272 triplet loss 0.834419072 l2_loss 6.96722 fraction B 0.134372279 lossA 0.837356031 fraction A 0.056955725\n",
      "step 717 loss 1.12790084 fisher_loss 0.0969503522 triplet loss 1.03095043 l2_loss 6.98524618 fraction B 0.224409163 lossA 0.846306503 fraction A 0.0565675944\n",
      "step 718 loss 0.957195163 fisher_loss 0.0982504636 triplet loss 0.858944714 l2_loss 7.00521803 fraction B 0.145212531 lossA 0.853322923 fraction A 0.0552919395\n",
      "step 719 loss 1.10331476 fisher_loss 0.10015808 triplet loss 1.00315666 l2_loss 7.02484846 fraction B 0.072232984 lossA 0.858091474 fraction A 0.0549594611\n",
      "step 720 loss 1.05334735 fisher_loss 0.102581888 triplet loss 0.950765431 l2_loss 7.04166889 fraction B 0.143815801 lossA 0.854888082 fraction A 0.0558887422\n",
      "step 721 loss 0.913247705 fisher_loss 0.102903038 triplet loss 0.810344696 l2_loss 7.05715942 fraction B 0.178302571 lossA 0.849829078 fraction A 0.0574494377\n",
      "step 722 loss 0.772356808 fisher_loss 0.103515938 triplet loss 0.668840885 l2_loss 7.0715 fraction B 0.145125166 lossA 0.849897 fraction A 0.0571900606\n",
      "step 723 loss 0.955797255 fisher_loss 0.101954922 triplet loss 0.853842318 l2_loss 7.08448935 fraction B 0.12721388 lossA 0.851133704 fraction A 0.0574087799\n",
      "step 724 loss 0.952385962 fisher_loss 0.100934282 triplet loss 0.851451695 l2_loss 7.09611559 fraction B 0.201445878 lossA 0.848087251 fraction A 0.0576323383\n",
      "step 725 loss 0.997485101 fisher_loss 0.100712769 triplet loss 0.896772325 l2_loss 7.10922718 fraction B 0.23292999 lossA 0.845684052 fraction A 0.0579121709\n",
      "step 726 loss 0.934339285 fisher_loss 0.102044687 triplet loss 0.832294583 l2_loss 7.12183475 fraction B 0.177352622 lossA 0.844075561 fraction A 0.0578468777\n",
      "step 727 loss 1.05256093 fisher_loss 0.103384122 triplet loss 0.949176848 l2_loss 7.13576317 fraction B 0.170658469 lossA 0.84801054 fraction A 0.0569373555\n",
      "step 728 loss 0.821061492 fisher_loss 0.104340553 triplet loss 0.716720939 l2_loss 7.14935923 fraction B 0.159794375 lossA 0.848275304 fraction A 0.0561090745\n",
      "step 729 loss 1.14839625 fisher_loss 0.104307771 triplet loss 1.04408848 l2_loss 7.16108418 fraction B 0.177654952 lossA 0.846670032 fraction A 0.0551266335\n",
      "step 730 loss 1.01294649 fisher_loss 0.10431359 triplet loss 0.908632874 l2_loss 7.17149973 fraction B 0.217287958 lossA 0.847069144 fraction A 0.0537090637\n",
      "step 731 loss 0.916903496 fisher_loss 0.103468984 triplet loss 0.813434541 l2_loss 7.18219709 fraction B 0.164103493 lossA 0.841757774 fraction A 0.0542006157\n",
      "step 732 loss 0.949772239 fisher_loss 0.101139657 triplet loss 0.848632574 l2_loss 7.19377518 fraction B 0.107136227 lossA 0.84411484 fraction A 0.053863775\n",
      "step 733 loss 1.1192323 fisher_loss 0.0981215537 triplet loss 1.02111077 l2_loss 7.20568705 fraction B 0.211773157 lossA 0.844345391 fraction A 0.0537185967\n",
      "step 734 loss 0.835695803 fisher_loss 0.0962520763 triplet loss 0.739443719 l2_loss 7.2175355 fraction B 0.140695229 lossA 0.849338293 fraction A 0.0534993261\n",
      "step 735 loss 1.17656493 fisher_loss 0.0954945534 triplet loss 1.08107042 l2_loss 7.23046541 fraction B 0.126897573 lossA 0.855009317 fraction A 0.0531470515\n",
      "step 736 loss 1.03697193 fisher_loss 0.0958190113 triplet loss 0.94115293 l2_loss 7.24251223 fraction B 0.215108737 lossA 0.867338419 fraction A 0.0525510535\n",
      "step 737 loss 0.982730091 fisher_loss 0.0963886753 triplet loss 0.886341393 l2_loss 7.25439787 fraction B 0.14704603 lossA 0.876214564 fraction A 0.0520266928\n",
      "step 738 loss 0.984591842 fisher_loss 0.0962669551 triplet loss 0.888324916 l2_loss 7.26552296 fraction B 0.20585376 lossA 0.88891238 fraction A 0.0514001548\n",
      "step 739 loss 1.09197426 fisher_loss 0.0972810239 triplet loss 0.99469322 l2_loss 7.27772856 fraction B 0.16744481 lossA 0.892024577 fraction A 0.051543355\n",
      "step 740 loss 0.895072758 fisher_loss 0.0973780528 triplet loss 0.797694683 l2_loss 7.29034042 fraction B 0.17180641 lossA 0.895807743 fraction A 0.0512311123\n",
      "step 741 loss 0.824827254 fisher_loss 0.0978389382 triplet loss 0.726988316 l2_loss 7.30316639 fraction B 0.151311949 lossA 0.895740151 fraction A 0.0505545698\n",
      "step 742 loss 0.990806162 fisher_loss 0.0954731554 triplet loss 0.895333 l2_loss 7.31414557 fraction B 0.222764045 lossA 0.897356272 fraction A 0.0498351\n",
      "step 743 loss 1.02750194 fisher_loss 0.094566 triplet loss 0.932935953 l2_loss 7.32475376 fraction B 0.223876566 lossA 0.89690721 fraction A 0.0491783172\n",
      "step 744 loss 1.15542161 fisher_loss 0.0944641456 triplet loss 1.06095743 l2_loss 7.33444214 fraction B 0.252594769 lossA 0.890238941 fraction A 0.0491890609\n",
      "step 745 loss 1.04364836 fisher_loss 0.0948821381 triplet loss 0.948766232 l2_loss 7.34510803 fraction B 0.274363697 lossA 0.870367348 fraction A 0.0507776178\n",
      "step 746 loss 1.01182652 fisher_loss 0.0951252952 triplet loss 0.916701198 l2_loss 7.35318756 fraction B 0.184451655 lossA 0.851879 fraction A 0.0531896167\n",
      "step 747 loss 1.0153085 fisher_loss 0.0957643837 triplet loss 0.919544101 l2_loss 7.36052227 fraction B 0.180172727 lossA 0.832517207 fraction A 0.0562993102\n",
      "step 748 loss 1.07961273 fisher_loss 0.0941512808 triplet loss 0.985461473 l2_loss 7.36751 fraction B 0.207293734 lossA 0.825957835 fraction A 0.057926286\n",
      "step 749 loss 1.09050882 fisher_loss 0.0919764563 triplet loss 0.998532355 l2_loss 7.37591648 fraction B 0.248470888 lossA 0.827107131 fraction A 0.0587789826\n",
      "step 750 loss 1.07163072 fisher_loss 0.0909598321 triplet loss 0.980670929 l2_loss 7.38528538 fraction B 0.245945647 lossA 0.830852151 fraction A 0.0595081337\n",
      "step 751 loss 1.0647012 fisher_loss 0.091148831 triplet loss 0.973552406 l2_loss 7.39481783 fraction B 0.298448086 lossA 0.840278924 fraction A 0.060090825\n",
      "step 752 loss 0.836142123 fisher_loss 0.0928979665 triplet loss 0.743244171 l2_loss 7.40330553 fraction B 0.17485106 lossA 0.85672152 fraction A 0.0599372499\n",
      "step 753 loss 0.929233 fisher_loss 0.0963760689 triplet loss 0.832856953 l2_loss 7.41177464 fraction B 0.204397395 lossA 0.873982787 fraction A 0.0598607026\n",
      "step 754 loss 0.962198377 fisher_loss 0.100704581 triplet loss 0.861493766 l2_loss 7.42140818 fraction B 0.155577615 lossA 0.887523413 fraction A 0.0603245\n",
      "step 755 loss 0.908773899 fisher_loss 0.103193954 triplet loss 0.80557996 l2_loss 7.43194 fraction B 0.142875701 lossA 0.894532144 fraction A 0.0608018637\n",
      "step 756 loss 1.04749632 fisher_loss 0.102581233 triplet loss 0.944915056 l2_loss 7.44432116 fraction B 0.241183445 lossA 0.887027 fraction A 0.0597785451\n",
      "step 757 loss 0.912763417 fisher_loss 0.0976387486 triplet loss 0.815124691 l2_loss 7.45783 fraction B 0.128578484 lossA 0.873669803 fraction A 0.0590015538\n",
      "step 758 loss 0.994733 fisher_loss 0.0930816308 triplet loss 0.901651323 l2_loss 7.47378492 fraction B 0.212121218 lossA 0.867177248 fraction A 0.056551829\n",
      "step 759 loss 0.837168634 fisher_loss 0.0911138877 triplet loss 0.746054769 l2_loss 7.48777199 fraction B 0.20292744 lossA 0.871279955 fraction A 0.0529838\n",
      "step 760 loss 1.16357052 fisher_loss 0.0931197181 triplet loss 1.07045078 l2_loss 7.50200319 fraction B 0.173913047 lossA 0.876661658 fraction A 0.0505099893\n",
      "step 761 loss 0.91839695 fisher_loss 0.0971881598 triplet loss 0.821208775 l2_loss 7.51566553 fraction B 0.0780607238 lossA 0.873085082 fraction A 0.0499298312\n",
      "step 762 loss 1.1921066 fisher_loss 0.0995840728 triplet loss 1.0925225 l2_loss 7.53157234 fraction B 0.189552456 lossA 0.868058741 fraction A 0.0495210625\n",
      "step 763 loss 0.997294247 fisher_loss 0.102564454 triplet loss 0.894729793 l2_loss 7.54550076 fraction B 0.181494206 lossA 0.859334 fraction A 0.0497259945\n",
      "step 764 loss 1.02215993 fisher_loss 0.103411965 triplet loss 0.918747962 l2_loss 7.56035042 fraction B 0.138191134 lossA 0.850144327 fraction A 0.0502124131\n",
      "step 765 loss 1.17379236 fisher_loss 0.102852501 triplet loss 1.0709399 l2_loss 7.57513142 fraction B 0.161539853 lossA 0.844685 fraction A 0.0506424122\n",
      "step 766 loss 1.25078809 fisher_loss 0.0998731777 triplet loss 1.15091491 l2_loss 7.58735943 fraction B 0.254669547 lossA 0.839276791 fraction A 0.0515638851\n",
      "step 767 loss 0.969616234 fisher_loss 0.0959075764 triplet loss 0.873708665 l2_loss 7.59786034 fraction B 0.160527274 lossA 0.842971087 fraction A 0.0517940037\n",
      "step 768 loss 0.929454625 fisher_loss 0.0933532789 triplet loss 0.836101353 l2_loss 7.60931063 fraction B 0.201191634 lossA 0.85623455 fraction A 0.0512675159\n",
      "step 769 loss 1.17055666 fisher_loss 0.0932391137 triplet loss 1.0773176 l2_loss 7.62010098 fraction B 0.317082822 lossA 0.869604349 fraction A 0.0502727926\n",
      "step 770 loss 0.707495809 fisher_loss 0.094627142 triplet loss 0.612868667 l2_loss 7.62993813 fraction B 0.103525639 lossA 0.881226 fraction A 0.049228359\n",
      "step 771 loss 1.09577882 fisher_loss 0.0957177058 triplet loss 1.00006115 l2_loss 7.64109707 fraction B 0.221255422 lossA 0.885329723 fraction A 0.0492656082\n",
      "step 772 loss 0.950270176 fisher_loss 0.097999312 triplet loss 0.852270842 l2_loss 7.6525321 fraction B 0.119467571 lossA 0.885253668 fraction A 0.0490915775\n",
      "step 773 loss 0.719405234 fisher_loss 0.0991362408 triplet loss 0.620269 l2_loss 7.66398096 fraction B 0.133123606 lossA 0.877677262 fraction A 0.0500050224\n",
      "step 774 loss 1.0387063 fisher_loss 0.0994342715 triplet loss 0.939272 l2_loss 7.6774559 fraction B 0.143075481 lossA 0.867338419 fraction A 0.0508589298\n",
      "step 775 loss 0.901055515 fisher_loss 0.0981361046 triplet loss 0.802919388 l2_loss 7.68873596 fraction B 0.202481583 lossA 0.861323476 fraction A 0.0510015786\n",
      "step 776 loss 0.963764131 fisher_loss 0.0955674 triplet loss 0.868196726 l2_loss 7.6986208 fraction B 0.165733233 lossA 0.840675473 fraction A 0.0535460711\n",
      "step 777 loss 0.984639883 fisher_loss 0.0943067446 triplet loss 0.890333116 l2_loss 7.70562458 fraction B 0.137370437 lossA 0.821317255 fraction A 0.0566701703\n",
      "step 778 loss 0.961619914 fisher_loss 0.0952025205 triplet loss 0.866417408 l2_loss 7.71199274 fraction B 0.141318679 lossA 0.806817055 fraction A 0.058874961\n",
      "step 779 loss 0.925353467 fisher_loss 0.0959216133 triplet loss 0.829431832 l2_loss 7.71870756 fraction B 0.165123016 lossA 0.80719614 fraction A 0.0598484576\n",
      "step 780 loss 0.904812515 fisher_loss 0.0964841321 triplet loss 0.80832839 l2_loss 7.72657967 fraction B 0.16790843 lossA 0.813402891 fraction A 0.0585913546\n",
      "step 781 loss 0.961184859 fisher_loss 0.0949865729 triplet loss 0.866198301 l2_loss 7.7348 fraction B 0.0623187385 lossA 0.835866034 fraction A 0.0551964752\n",
      "step 782 loss 0.849624932 fisher_loss 0.0932810381 triplet loss 0.756343901 l2_loss 7.74524069 fraction B 0.195935547 lossA 0.856811702 fraction A 0.0519833229\n",
      "step 783 loss 0.952358842 fisher_loss 0.092540741 triplet loss 0.859818101 l2_loss 7.75748 fraction B 0.172168106 lossA 0.879240394 fraction A 0.0491276905\n",
      "step 784 loss 0.995506585 fisher_loss 0.0943777 triplet loss 0.901128888 l2_loss 7.76917124 fraction B 0.180582702 lossA 0.89610666 fraction A 0.0471907072\n",
      "step 785 loss 0.790650427 fisher_loss 0.0964000151 triplet loss 0.694250405 l2_loss 7.77959299 fraction B 0.149045199 lossA 0.894256949 fraction A 0.0464969687\n",
      "step 786 loss 0.835560381 fisher_loss 0.0961321369 triplet loss 0.739428222 l2_loss 7.79123402 fraction B 0.117840305 lossA 0.882417738 fraction A 0.04691872\n",
      "step 787 loss 1.10194874 fisher_loss 0.0959316343 triplet loss 1.00601709 l2_loss 7.80402803 fraction B 0.217276171 lossA 0.873004079 fraction A 0.0476631932\n",
      "step 788 loss 0.977470458 fisher_loss 0.0954711288 triplet loss 0.881999314 l2_loss 7.81681347 fraction B 0.150625139 lossA 0.872365296 fraction A 0.0479205512\n",
      "step 789 loss 0.972247958 fisher_loss 0.0951538607 triplet loss 0.87709409 l2_loss 7.83033895 fraction B 0.215568751 lossA 0.87340486 fraction A 0.0484372154\n",
      "step 790 loss 1.19981956 fisher_loss 0.0945436805 triplet loss 1.10527587 l2_loss 7.84352827 fraction B 0.299567729 lossA 0.876011968 fraction A 0.0491510406\n",
      "step 791 loss 0.949861169 fisher_loss 0.093801409 triplet loss 0.85605979 l2_loss 7.85545254 fraction B 0.140778989 lossA 0.884141743 fraction A 0.0497129075\n",
      "step 792 loss 1.02314484 fisher_loss 0.0935636088 triplet loss 0.929581225 l2_loss 7.86737251 fraction B 0.204921305 lossA 0.892718256 fraction A 0.0508447066\n",
      "step 793 loss 1.05184484 fisher_loss 0.0941003114 triplet loss 0.957744479 l2_loss 7.87885 fraction B 0.118722044 lossA 0.895574689 fraction A 0.0518072024\n",
      "step 794 loss 0.913869798 fisher_loss 0.093332015 triplet loss 0.820537806 l2_loss 7.88894415 fraction B 0.161524728 lossA 0.905307591 fraction A 0.0522514954\n",
      "step 795 loss 0.857573628 fisher_loss 0.0936437547 triplet loss 0.763929844 l2_loss 7.8975997 fraction B 0.143240571 lossA 0.903812766 fraction A 0.0533081777\n",
      "step 796 loss 0.81397742 fisher_loss 0.0936761051 triplet loss 0.72030133 l2_loss 7.90559769 fraction B 0.105645344 lossA 0.899659514 fraction A 0.0538268574\n",
      "step 797 loss 1.01928782 fisher_loss 0.0951142162 triplet loss 0.924173653 l2_loss 7.91449165 fraction B 0.222756639 lossA 0.895095706 fraction A 0.0540748313\n",
      "step 798 loss 0.951789141 fisher_loss 0.0982653424 triplet loss 0.853523791 l2_loss 7.92413712 fraction B 0.17507492 lossA 0.894228399 fraction A 0.0545888171\n",
      "step 799 loss 1.02851272 fisher_loss 0.103601471 triplet loss 0.924911261 l2_loss 7.93272 fraction B 0.177926391 lossA 0.895333648 fraction A 0.0549192056\n",
      "step 800 loss 0.915566206 fisher_loss 0.108124629 triplet loss 0.807441592 l2_loss 7.94079065 fraction B 0.216182575 lossA 0.896247864 fraction A 0.0543262511\n",
      "step 801 loss 0.674396217 fisher_loss 0.107595794 triplet loss 0.566800416 l2_loss 7.94951344 fraction B 0.0829460397 lossA 0.893528521 fraction A 0.0541569889\n",
      "step 802 loss 1.00283289 fisher_loss 0.105144948 triplet loss 0.897687912 l2_loss 7.96110058 fraction B 0.217279941 lossA 0.89221704 fraction A 0.0539308637\n",
      "step 803 loss 1.00911152 fisher_loss 0.102626696 triplet loss 0.906484842 l2_loss 7.97196388 fraction B 0.201335981 lossA 0.896489859 fraction A 0.0531289056\n",
      "step 804 loss 0.980992913 fisher_loss 0.100428425 triplet loss 0.880564511 l2_loss 7.98314285 fraction B 0.15850842 lossA 0.898998618 fraction A 0.0524091385\n",
      "step 805 loss 0.834079742 fisher_loss 0.0990705714 triplet loss 0.735009193 l2_loss 7.99612713 fraction B 0.13123104 lossA 0.907554507 fraction A 0.0507860482\n",
      "step 806 loss 1.08809853 fisher_loss 0.098625131 triplet loss 0.989473403 l2_loss 8.00893 fraction B 0.0920761377 lossA 0.908510923 fraction A 0.0496763922\n",
      "step 807 loss 1.04141331 fisher_loss 0.0984357744 triplet loss 0.942977548 l2_loss 8.02037239 fraction B 0.164120063 lossA 0.900693655 fraction A 0.049741026\n",
      "step 808 loss 1.03817749 fisher_loss 0.0980567411 triplet loss 0.940120757 l2_loss 8.0306282 fraction B 0.16383864 lossA 0.894636929 fraction A 0.0493308641\n",
      "step 809 loss 1.12438512 fisher_loss 0.0977166519 triplet loss 1.02666843 l2_loss 8.03966236 fraction B 0.287221 lossA 0.889411271 fraction A 0.048829414\n",
      "step 810 loss 1.03099203 fisher_loss 0.0969031379 triplet loss 0.934088945 l2_loss 8.04854298 fraction B 0.208647698 lossA 0.877436399 fraction A 0.0495261922\n",
      "step 811 loss 0.991311312 fisher_loss 0.0958573744 triplet loss 0.89545393 l2_loss 8.05592823 fraction B 0.117193006 lossA 0.88023448 fraction A 0.0491639115\n",
      "step 812 loss 0.979282081 fisher_loss 0.0936194584 triplet loss 0.885662615 l2_loss 8.06541252 fraction B 0.20450063 lossA 0.893716335 fraction A 0.0480965637\n",
      "step 813 loss 0.790176153 fisher_loss 0.0915057957 triplet loss 0.698670328 l2_loss 8.07528877 fraction B 0.150082886 lossA 0.918331683 fraction A 0.0462759063\n",
      "step 814 loss 0.950658202 fisher_loss 0.0915690511 triplet loss 0.859089136 l2_loss 8.08647251 fraction B 0.18078512 lossA 0.934212565 fraction A 0.0449657887\n",
      "step 815 loss 1.01177263 fisher_loss 0.0917839482 triplet loss 0.919988692 l2_loss 8.09687519 fraction B 0.168902531 lossA 0.944987774 fraction A 0.0442264825\n",
      "step 816 loss 0.694010437 fisher_loss 0.0932082683 triplet loss 0.600802183 l2_loss 8.107934 fraction B 0.156286448 lossA 0.945510805 fraction A 0.0437923074\n",
      "step 817 loss 0.878737 fisher_loss 0.0928638577 triplet loss 0.785873115 l2_loss 8.12101 fraction B 0.15544802 lossA 0.946550727 fraction A 0.042897705\n",
      "step 818 loss 0.974136353 fisher_loss 0.0919295475 triplet loss 0.882206798 l2_loss 8.13358 fraction B 0.186886907 lossA 0.941045344 fraction A 0.0422183424\n",
      "step 819 loss 0.819323599 fisher_loss 0.0909971744 triplet loss 0.72832644 l2_loss 8.14404392 fraction B 0.172348484 lossA 0.937497 fraction A 0.0419017375\n",
      "step 820 loss 0.968028367 fisher_loss 0.0917270929 triplet loss 0.876301289 l2_loss 8.15738487 fraction B 0.153925613 lossA 0.929225802 fraction A 0.0420735292\n",
      "step 821 loss 0.910359144 fisher_loss 0.0920843482 triplet loss 0.818274796 l2_loss 8.16941833 fraction B 0.161118731 lossA 0.922588766 fraction A 0.042481713\n",
      "step 822 loss 0.899815619 fisher_loss 0.0920981914 triplet loss 0.807717443 l2_loss 8.17993546 fraction B 0.190836802 lossA 0.9204458 fraction A 0.0427187271\n",
      "step 823 loss 0.93576175 fisher_loss 0.0918139219 triplet loss 0.843947828 l2_loss 8.19126606 fraction B 0.159338236 lossA 0.930463493 fraction A 0.0422188528\n",
      "step 824 loss 1.22609329 fisher_loss 0.0916965902 triplet loss 1.13439667 l2_loss 8.2041 fraction B 0.18809779 lossA 0.933560431 fraction A 0.0422900878\n",
      "step 825 loss 0.998757 fisher_loss 0.0914319828 triplet loss 0.907325 l2_loss 8.2158 fraction B 0.161074921 lossA 0.937335134 fraction A 0.0424139649\n",
      "step 826 loss 1.10083723 fisher_loss 0.0912319794 triplet loss 1.00960529 l2_loss 8.22756672 fraction B 0.252340645 lossA 0.940210283 fraction A 0.042359449\n",
      "step 827 loss 0.944352388 fisher_loss 0.0914176777 triplet loss 0.852934718 l2_loss 8.23915672 fraction B 0.134823248 lossA 0.942163467 fraction A 0.0425967574\n",
      "step 828 loss 1.05901682 fisher_loss 0.0922436193 triplet loss 0.966773212 l2_loss 8.25095367 fraction B 0.218590155 lossA 0.942355633 fraction A 0.0425937846\n",
      "step 829 loss 1.01864731 fisher_loss 0.0926946774 triplet loss 0.925952673 l2_loss 8.26231194 fraction B 0.204378515 lossA 0.938089788 fraction A 0.0429648682\n",
      "step 830 loss 1.03209841 fisher_loss 0.0924494192 triplet loss 0.939649045 l2_loss 8.27283192 fraction B 0.201203689 lossA 0.921630561 fraction A 0.0438369587\n",
      "step 831 loss 0.882249713 fisher_loss 0.090628095 triplet loss 0.791621625 l2_loss 8.28160191 fraction B 0.171981364 lossA 0.910693645 fraction A 0.0441886857\n",
      "step 832 loss 1.00026619 fisher_loss 0.0899482444 triplet loss 0.910317898 l2_loss 8.29052448 fraction B 0.197575092 lossA 0.881003 fraction A 0.0464765131\n",
      "step 833 loss 1.0470984 fisher_loss 0.0907746553 triplet loss 0.956323683 l2_loss 8.29934788 fraction B 0.134950563 lossA 0.854375601 fraction A 0.048974555\n",
      "step 834 loss 1.08719683 fisher_loss 0.0919023529 triplet loss 0.995294452 l2_loss 8.30812263 fraction B 0.155306861 lossA 0.837700844 fraction A 0.0508287959\n",
      "step 835 loss 0.898062766 fisher_loss 0.0914487764 triplet loss 0.806614 l2_loss 8.31685638 fraction B 0.16400218 lossA 0.83364296 fraction A 0.0511317253\n",
      "step 836 loss 1.00182736 fisher_loss 0.0899963677 triplet loss 0.911831 l2_loss 8.32912922 fraction B 0.15476191 lossA 0.840586185 fraction A 0.0498896502\n",
      "step 837 loss 0.863426328 fisher_loss 0.0898019746 triplet loss 0.773624361 l2_loss 8.34398174 fraction B 0.118773028 lossA 0.852328062 fraction A 0.0486609228\n",
      "step 838 loss 1.03625154 fisher_loss 0.0918729454 triplet loss 0.944378555 l2_loss 8.35872841 fraction B 0.143698305 lossA 0.872102797 fraction A 0.0471073762\n",
      "step 839 loss 1.27933025 fisher_loss 0.0956111625 triplet loss 1.18371904 l2_loss 8.37260056 fraction B 0.20173724 lossA 0.889191628 fraction A 0.0461461246\n",
      "step 840 loss 0.981875181 fisher_loss 0.0986568 triplet loss 0.883218348 l2_loss 8.385005 fraction B 0.139615238 lossA 0.891835451 fraction A 0.0455539413\n",
      "step 841 loss 0.893525124 fisher_loss 0.0987181216 triplet loss 0.794807 l2_loss 8.39803791 fraction B 0.117415734 lossA 0.889449656 fraction A 0.0455989614\n",
      "step 842 loss 0.906167626 fisher_loss 0.0980324745 triplet loss 0.808135152 l2_loss 8.40976906 fraction B 0.144452915 lossA 0.88242358 fraction A 0.0465369299\n",
      "step 843 loss 0.86206913 fisher_loss 0.0982181057 triplet loss 0.763851047 l2_loss 8.42136 fraction B 0.198244408 lossA 0.871487677 fraction A 0.0466507263\n",
      "step 844 loss 1.02254 fisher_loss 0.0959695876 triplet loss 0.926570415 l2_loss 8.43168736 fraction B 0.169798762 lossA 0.858487785 fraction A 0.0474316776\n",
      "step 845 loss 0.999137044 fisher_loss 0.0955162346 triplet loss 0.90362078 l2_loss 8.44084835 fraction B 0.136551753 lossA 0.841746211 fraction A 0.048444\n",
      "step 846 loss 1.01116467 fisher_loss 0.0950528905 triplet loss 0.916111767 l2_loss 8.44774532 fraction B 0.231944442 lossA 0.818652332 fraction A 0.0509537719\n",
      "step 847 loss 0.974386871 fisher_loss 0.095146358 triplet loss 0.879240513 l2_loss 8.45367146 fraction B 0.128737897 lossA 0.801741838 fraction A 0.0535099953\n",
      "step 848 loss 1.04642308 fisher_loss 0.0953341424 triplet loss 0.951088965 l2_loss 8.4599123 fraction B 0.1514709 lossA 0.792748094 fraction A 0.0558016747\n",
      "step 849 loss 1.10616469 fisher_loss 0.0956025496 triplet loss 1.01056218 l2_loss 8.46581841 fraction B 0.166846 lossA 0.801082909 fraction A 0.0549071468\n",
      "step 850 loss 1.13838625 fisher_loss 0.0942422077 triplet loss 1.04414403 l2_loss 8.47238636 fraction B 0.192003608 lossA 0.817566693 fraction A 0.0524220057\n",
      "step 851 loss 1.00893009 fisher_loss 0.0934893042 triplet loss 0.915440798 l2_loss 8.48037052 fraction B 0.188208 lossA 0.832532406 fraction A 0.0495673269\n",
      "step 852 loss 1.06483757 fisher_loss 0.0946158841 triplet loss 0.970221639 l2_loss 8.48917484 fraction B 0.10236761 lossA 0.850699604 fraction A 0.0465243198\n",
      "step 853 loss 1.19065118 fisher_loss 0.0967370942 triplet loss 1.09391403 l2_loss 8.49891663 fraction B 0.230570048 lossA 0.866920292 fraction A 0.0436025485\n",
      "step 854 loss 1.05279851 fisher_loss 0.0988979638 triplet loss 0.953900516 l2_loss 8.5085659 fraction B 0.182848364 lossA 0.882695496 fraction A 0.0412175693\n",
      "step 855 loss 0.871315181 fisher_loss 0.100684769 triplet loss 0.770630419 l2_loss 8.51993942 fraction B 0.179709569 lossA 0.895039141 fraction A 0.0401561968\n",
      "step 856 loss 0.853135 fisher_loss 0.100890689 triplet loss 0.752244294 l2_loss 8.53320503 fraction B 0.0865619928 lossA 0.904133439 fraction A 0.0396787636\n",
      "step 857 loss 0.954217494 fisher_loss 0.10019552 triplet loss 0.854021966 l2_loss 8.54661083 fraction B 0.146122456 lossA 0.895979047 fraction A 0.0411673449\n",
      "step 858 loss 0.87702024 fisher_loss 0.0968912542 triplet loss 0.780129 l2_loss 8.56125832 fraction B 0.17802079 lossA 0.884515107 fraction A 0.0427820049\n",
      "step 859 loss 1.08584297 fisher_loss 0.0949642435 triplet loss 0.990878761 l2_loss 8.57502 fraction B 0.155940592 lossA 0.864174306 fraction A 0.0452128835\n",
      "step 860 loss 0.915882349 fisher_loss 0.0941918045 triplet loss 0.821690559 l2_loss 8.58599186 fraction B 0.193414971 lossA 0.850215733 fraction A 0.0478253812\n",
      "step 861 loss 1.07743108 fisher_loss 0.0957319 triplet loss 0.981699169 l2_loss 8.59765434 fraction B 0.151219949 lossA 0.83734113 fraction A 0.0498710275\n",
      "step 862 loss 1.21071804 fisher_loss 0.09728311 triplet loss 1.11343491 l2_loss 8.60857391 fraction B 0.139481381 lossA 0.835515916 fraction A 0.0505670719\n",
      "step 863 loss 0.969872892 fisher_loss 0.0972681865 triplet loss 0.872604728 l2_loss 8.61787224 fraction B 0.169609264 lossA 0.833883584 fraction A 0.0515761636\n",
      "step 864 loss 0.898599505 fisher_loss 0.0969009176 triplet loss 0.801698565 l2_loss 8.62828159 fraction B 0.169150203 lossA 0.839909077 fraction A 0.0512357317\n",
      "step 865 loss 1.03010142 fisher_loss 0.0960079 triplet loss 0.934093535 l2_loss 8.63967419 fraction B 0.165821284 lossA 0.851383686 fraction A 0.0496005416\n",
      "step 866 loss 1.01280177 fisher_loss 0.0948750079 triplet loss 0.917926788 l2_loss 8.65097904 fraction B 0.154650748 lossA 0.861340404 fraction A 0.0479117185\n",
      "step 867 loss 0.972147465 fisher_loss 0.0939534307 triplet loss 0.878194034 l2_loss 8.66036 fraction B 0.124580048 lossA 0.871433794 fraction A 0.0461296625\n",
      "step 868 loss 0.813806474 fisher_loss 0.0925763473 triplet loss 0.721230149 l2_loss 8.66829681 fraction B 0.162799388 lossA 0.870260119 fraction A 0.0456532165\n",
      "step 869 loss 1.17300165 fisher_loss 0.0918505415 triplet loss 1.08115113 l2_loss 8.67790794 fraction B 0.0944781527 lossA 0.863360226 fraction A 0.0458431952\n",
      "step 870 loss 1.13493562 fisher_loss 0.0915525109 triplet loss 1.04338312 l2_loss 8.68612289 fraction B 0.215266049 lossA 0.860572875 fraction A 0.0454866663\n",
      "step 871 loss 0.869322896 fisher_loss 0.0914093405 triplet loss 0.77791357 l2_loss 8.69403553 fraction B 0.154064447 lossA 0.860452473 fraction A 0.0453032516\n",
      "step 872 loss 0.792661726 fisher_loss 0.091000542 triplet loss 0.70166117 l2_loss 8.70498943 fraction B 0.130861089 lossA 0.858713031 fraction A 0.0455237664\n",
      "step 873 loss 0.84146589 fisher_loss 0.0907477811 triplet loss 0.750718117 l2_loss 8.71745872 fraction B 0.139232054 lossA 0.866870344 fraction A 0.0453863256\n",
      "step 874 loss 1.04849327 fisher_loss 0.0915441662 triplet loss 0.956949115 l2_loss 8.72993946 fraction B 0.188536108 lossA 0.872237802 fraction A 0.0453600772\n",
      "step 875 loss 1.00908613 fisher_loss 0.0922633 triplet loss 0.916822791 l2_loss 8.74313259 fraction B 0.166210189 lossA 0.875603616 fraction A 0.0455216765\n",
      "step 876 loss 0.913060308 fisher_loss 0.0927044302 triplet loss 0.820355892 l2_loss 8.75919819 fraction B 0.157996014 lossA 0.870468736 fraction A 0.04625028\n",
      "step 877 loss 0.937727332 fisher_loss 0.0922549 triplet loss 0.845472455 l2_loss 8.77476788 fraction B 0.200627074 lossA 0.858555257 fraction A 0.047371041\n",
      "step 878 loss 0.943479598 fisher_loss 0.0917155743 triplet loss 0.851764 l2_loss 8.79083061 fraction B 0.166540399 lossA 0.852845371 fraction A 0.047646217\n",
      "step 879 loss 0.835138559 fisher_loss 0.0918613449 triplet loss 0.743277192 l2_loss 8.80594158 fraction B 0.165112942 lossA 0.848904788 fraction A 0.0471508913\n",
      "step 880 loss 0.806972623 fisher_loss 0.0915507749 triplet loss 0.715421855 l2_loss 8.82043743 fraction B 0.181927487 lossA 0.845628679 fraction A 0.0466220193\n",
      "step 881 loss 0.825166106 fisher_loss 0.0922879 triplet loss 0.732878208 l2_loss 8.83453178 fraction B 0.153168514 lossA 0.845808 fraction A 0.0456713289\n",
      "step 882 loss 0.942585707 fisher_loss 0.0935644805 triplet loss 0.849021256 l2_loss 8.84793472 fraction B 0.140186921 lossA 0.848988414 fraction A 0.0445813611\n",
      "step 883 loss 1.03351653 fisher_loss 0.0949214399 triplet loss 0.938595116 l2_loss 8.86277103 fraction B 0.140674949 lossA 0.856180727 fraction A 0.0436978303\n",
      "step 884 loss 0.992917359 fisher_loss 0.0954560265 triplet loss 0.897461355 l2_loss 8.87593842 fraction B 0.123938881 lossA 0.865119636 fraction A 0.0430453755\n",
      "step 885 loss 0.988272488 fisher_loss 0.0943165272 triplet loss 0.893955946 l2_loss 8.88724613 fraction B 0.167290971 lossA 0.871498048 fraction A 0.0428331085\n",
      "step 886 loss 0.823918939 fisher_loss 0.0938198492 triplet loss 0.730099082 l2_loss 8.89922619 fraction B 0.122357875 lossA 0.874713719 fraction A 0.0426830202\n",
      "step 887 loss 0.984559596 fisher_loss 0.0934932 triplet loss 0.891066372 l2_loss 8.91299629 fraction B 0.162662804 lossA 0.878727317 fraction A 0.0428073369\n",
      "step 888 loss 0.978546739 fisher_loss 0.0930203423 triplet loss 0.885526419 l2_loss 8.92510128 fraction B 0.145574629 lossA 0.884101093 fraction A 0.0428474806\n",
      "step 889 loss 0.978817046 fisher_loss 0.0930441692 triplet loss 0.885772884 l2_loss 8.93572712 fraction B 0.162265569 lossA 0.890972078 fraction A 0.0429661162\n",
      "step 890 loss 1.0971365 fisher_loss 0.0936699584 triplet loss 1.00346649 l2_loss 8.94599819 fraction B 0.198623106 lossA 0.890918791 fraction A 0.0436193757\n",
      "step 891 loss 0.99329859 fisher_loss 0.0934877619 triplet loss 0.899810851 l2_loss 8.95561504 fraction B 0.110506192 lossA 0.889362454 fraction A 0.0445525832\n",
      "step 892 loss 0.940824449 fisher_loss 0.0936454 triplet loss 0.847179055 l2_loss 8.96442604 fraction B 0.190318257 lossA 0.879036844 fraction A 0.0462581255\n",
      "step 893 loss 1.01723373 fisher_loss 0.092789337 triplet loss 0.924444377 l2_loss 8.97411919 fraction B 0.158259019 lossA 0.868029416 fraction A 0.04771173\n",
      "step 894 loss 0.979042888 fisher_loss 0.0916451365 triplet loss 0.887397766 l2_loss 8.98283195 fraction B 0.180886582 lossA 0.857243538 fraction A 0.0487932675\n",
      "step 895 loss 0.876988888 fisher_loss 0.0905540809 triplet loss 0.786434829 l2_loss 8.99222088 fraction B 0.170675844 lossA 0.853585899 fraction A 0.0485844091\n",
      "step 896 loss 0.847262204 fisher_loss 0.089535974 triplet loss 0.757726252 l2_loss 9.00442505 fraction B 0.115441091 lossA 0.860584497 fraction A 0.0469076112\n",
      "step 897 loss 0.997296751 fisher_loss 0.0895529 triplet loss 0.907743871 l2_loss 9.01962376 fraction B 0.155065119 lossA 0.865743399 fraction A 0.0454100072\n",
      "step 898 loss 0.782327056 fisher_loss 0.0920184553 triplet loss 0.690308571 l2_loss 9.03434086 fraction B 0.128470466 lossA 0.883654535 fraction A 0.0427224673\n",
      "step 899 loss 0.879730821 fisher_loss 0.095276475 triplet loss 0.784454346 l2_loss 9.04969597 fraction B 0.0903596506 lossA 0.908054411 fraction A 0.0405622534\n",
      "step 900 loss 1.06498051 fisher_loss 0.0987292528 triplet loss 0.966251254 l2_loss 9.06638241 fraction B 0.18403779 lossA 0.921537042 fraction A 0.03989565\n",
      "step 901 loss 1.15974772 fisher_loss 0.101005554 triplet loss 1.05874217 l2_loss 9.08281708 fraction B 0.233688608 lossA 0.919653 fraction A 0.040612407\n",
      "step 902 loss 1.02041566 fisher_loss 0.0996239707 triplet loss 0.920791745 l2_loss 9.09680557 fraction B 0.185936034 lossA 0.905661762 fraction A 0.0426272564\n",
      "step 903 loss 0.817821085 fisher_loss 0.0966045335 triplet loss 0.721216559 l2_loss 9.1100626 fraction B 0.0894258916 lossA 0.893400729 fraction A 0.0445963182\n",
      "step 904 loss 1.06919408 fisher_loss 0.0930022895 triplet loss 0.976191759 l2_loss 9.12113476 fraction B 0.147095591 lossA 0.875157952 fraction A 0.0468309149\n",
      "step 905 loss 0.821332276 fisher_loss 0.0901116952 triplet loss 0.731220603 l2_loss 9.13087749 fraction B 0.126772508 lossA 0.854216814 fraction A 0.0507724844\n",
      "step 906 loss 1.04894352 fisher_loss 0.0912298635 triplet loss 0.957713664 l2_loss 9.1400938 fraction B 0.141989455 lossA 0.829649627 fraction A 0.0568963699\n",
      "step 907 loss 0.970302165 fisher_loss 0.0964136943 triplet loss 0.873888493 l2_loss 9.14903 fraction B 0.166678622 lossA 0.813681364 fraction A 0.0614091903\n",
      "step 908 loss 0.880826354 fisher_loss 0.101974413 triplet loss 0.778851926 l2_loss 9.15812778 fraction B 0.131245419 lossA 0.808808625 fraction A 0.063438341\n",
      "step 909 loss 0.824531853 fisher_loss 0.10546767 triplet loss 0.719064176 l2_loss 9.17068863 fraction B 0.102256358 lossA 0.811598957 fraction A 0.0631118715\n",
      "step 910 loss 1.09425533 fisher_loss 0.10770952 triplet loss 0.986545861 l2_loss 9.18493748 fraction B 0.202385664 lossA 0.821237326 fraction A 0.0619096868\n",
      "step 911 loss 0.866598129 fisher_loss 0.110051386 triplet loss 0.756546736 l2_loss 9.19718456 fraction B 0.107075594 lossA 0.845162094 fraction A 0.0587755032\n",
      "step 912 loss 1.08479404 fisher_loss 0.112647034 triplet loss 0.972147048 l2_loss 9.21026134 fraction B 0.29210487 lossA 0.87468189 fraction A 0.0557096153\n",
      "step 913 loss 1.19880354 fisher_loss 0.114384651 triplet loss 1.08441889 l2_loss 9.22383 fraction B 0.17767404 lossA 0.892916739 fraction A 0.0531979725\n",
      "step 914 loss 1.01253021 fisher_loss 0.111576505 triplet loss 0.90095371 l2_loss 9.23564911 fraction B 0.193788573 lossA 0.905469477 fraction A 0.0509621687\n",
      "step 915 loss 0.898445904 fisher_loss 0.108062737 triplet loss 0.79038316 l2_loss 9.24658585 fraction B 0.193138838 lossA 0.909472466 fraction A 0.0492552333\n",
      "step 916 loss 0.819802582 fisher_loss 0.1029386 triplet loss 0.716864 l2_loss 9.25720882 fraction B 0.102687247 lossA 0.913715839 fraction A 0.0475704037\n",
      "step 917 loss 0.960598588 fisher_loss 0.100644857 triplet loss 0.859953761 l2_loss 9.26850319 fraction B 0.16101788 lossA 0.913447261 fraction A 0.046384789\n",
      "step 918 loss 0.928427637 fisher_loss 0.101003416 triplet loss 0.827424228 l2_loss 9.27871 fraction B 0.199027732 lossA 0.915865 fraction A 0.045282539\n",
      "step 919 loss 0.75758 fisher_loss 0.10484577 triplet loss 0.65273422 l2_loss 9.28905392 fraction B 0.102165624 lossA 0.913880587 fraction A 0.0447695777\n",
      "step 920 loss 1.01301956 fisher_loss 0.108328618 triplet loss 0.904691 l2_loss 9.29993534 fraction B 0.161548972 lossA 0.910494745 fraction A 0.0445922874\n",
      "step 921 loss 1.14840961 fisher_loss 0.111769058 triplet loss 1.03664052 l2_loss 9.31171 fraction B 0.172189236 lossA 0.908739448 fraction A 0.0445418023\n",
      "step 922 loss 1.02054656 fisher_loss 0.113097943 triplet loss 0.907448649 l2_loss 9.32582664 fraction B 0.121901497 lossA 0.916299582 fraction A 0.0439279526\n",
      "step 923 loss 1.19136024 fisher_loss 0.111349776 triplet loss 1.08001041 l2_loss 9.33957481 fraction B 0.203671083 lossA 0.926401556 fraction A 0.0434296206\n",
      "step 924 loss 1.38613391 fisher_loss 0.107860714 triplet loss 1.27827322 l2_loss 9.35147858 fraction B 0.187930733 lossA 0.930276155 fraction A 0.0434702039\n",
      "step 925 loss 0.858083546 fisher_loss 0.104394175 triplet loss 0.753689349 l2_loss 9.36350918 fraction B 0.110881194 lossA 0.929653645 fraction A 0.0440193117\n",
      "step 926 loss 1.04657543 fisher_loss 0.10272596 triplet loss 0.943849444 l2_loss 9.37873 fraction B 0.14185515 lossA 0.929157376 fraction A 0.0440511703\n",
      "step 927 loss 1.00708771 fisher_loss 0.102433689 triplet loss 0.904653966 l2_loss 9.3957386 fraction B 0.123270601 lossA 0.919199526 fraction A 0.0455820225\n",
      "step 928 loss 0.86030674 fisher_loss 0.105842225 triplet loss 0.754464507 l2_loss 9.4122448 fraction B 0.078711547 lossA 0.903713822 fraction A 0.0473824441\n",
      "step 929 loss 1.16457438 fisher_loss 0.108520947 triplet loss 1.0560534 l2_loss 9.42828846 fraction B 0.151739925 lossA 0.886572599 fraction A 0.049119588\n",
      "step 930 loss 1.01575422 fisher_loss 0.109291546 triplet loss 0.906462669 l2_loss 9.44338894 fraction B 0.214997843 lossA 0.870957673 fraction A 0.050935626\n",
      "step 931 loss 1.09603202 fisher_loss 0.109035008 triplet loss 0.986997 l2_loss 9.45682907 fraction B 0.236504227 lossA 0.856687188 fraction A 0.0529157929\n",
      "step 932 loss 0.714520812 fisher_loss 0.107865125 triplet loss 0.606655657 l2_loss 9.46823502 fraction B 0.107964113 lossA 0.846599579 fraction A 0.0534774773\n",
      "step 933 loss 0.917565 fisher_loss 0.104179218 triplet loss 0.813385785 l2_loss 9.47961712 fraction B 0.152641803 lossA 0.835469842 fraction A 0.0546530485\n",
      "step 934 loss 1.04416263 fisher_loss 0.101151891 triplet loss 0.943010747 l2_loss 9.48984 fraction B 0.118392073 lossA 0.83260715 fraction A 0.0552117229\n",
      "step 935 loss 0.896547318 fisher_loss 0.0989322513 triplet loss 0.797615051 l2_loss 9.49978924 fraction B 0.168877035 lossA 0.833679497 fraction A 0.0548069142\n",
      "step 936 loss 1.11274731 fisher_loss 0.0972489417 triplet loss 1.0154984 l2_loss 9.508605 fraction B 0.167813987 lossA 0.842056394 fraction A 0.0532302335\n",
      "step 937 loss 0.986833632 fisher_loss 0.0964217782 triplet loss 0.890411854 l2_loss 9.51727104 fraction B 0.205176771 lossA 0.85013938 fraction A 0.0516031496\n",
      "step 938 loss 1.06622756 fisher_loss 0.0965320468 triplet loss 0.969695508 l2_loss 9.52548885 fraction B 0.202794179 lossA 0.859042525 fraction A 0.0499820374\n",
      "step 939 loss 0.990765214 fisher_loss 0.0971223712 triplet loss 0.893642843 l2_loss 9.5342989 fraction B 0.133752406 lossA 0.869683802 fraction A 0.0481311716\n",
      "step 940 loss 1.06323946 fisher_loss 0.0978861 triplet loss 0.96535337 l2_loss 9.54326057 fraction B 0.148436934 lossA 0.877860129 fraction A 0.0467213\n",
      "step 941 loss 1.10765922 fisher_loss 0.0980933 triplet loss 1.00956595 l2_loss 9.54992104 fraction B 0.202017292 lossA 0.882846177 fraction A 0.0454941466\n",
      "step 942 loss 0.945185959 fisher_loss 0.0965920687 triplet loss 0.848593891 l2_loss 9.55634785 fraction B 0.116194136 lossA 0.885006309 fraction A 0.0442007482\n",
      "step 943 loss 0.938909173 fisher_loss 0.0950894505 triplet loss 0.843819737 l2_loss 9.56588554 fraction B 0.119771659 lossA 0.891361415 fraction A 0.0427330248\n",
      "step 944 loss 0.847099 fisher_loss 0.0940778852 triplet loss 0.753021121 l2_loss 9.57611465 fraction B 0.175431892 lossA 0.885952592 fraction A 0.042657759\n",
      "step 945 loss 0.969926894 fisher_loss 0.0924630538 triplet loss 0.877463818 l2_loss 9.58971596 fraction B 0.0912172 lossA 0.868177652 fraction A 0.0437000319\n",
      "step 946 loss 0.851671159 fisher_loss 0.0908657685 triplet loss 0.760805368 l2_loss 9.60086346 fraction B 0.102293015 lossA 0.855178237 fraction A 0.0442641713\n",
      "step 947 loss 0.73128897 fisher_loss 0.0903137103 triplet loss 0.640975237 l2_loss 9.61622238 fraction B 0.071065791 lossA 0.855125844 fraction A 0.044104293\n",
      "step 948 loss 0.849429786 fisher_loss 0.0902675539 triplet loss 0.759162247 l2_loss 9.63441 fraction B 0.0895761847 lossA 0.863094449 fraction A 0.0429904573\n",
      "step 949 loss 0.957766771 fisher_loss 0.0906209946 triplet loss 0.867145777 l2_loss 9.65340137 fraction B 0.161184207 lossA 0.865324259 fraction A 0.0423649848\n",
      "step 950 loss 1.00011277 fisher_loss 0.0913424268 triplet loss 0.908770382 l2_loss 9.67447758 fraction B 0.0892729387 lossA 0.85922581 fraction A 0.0424889363\n",
      "step 951 loss 0.83144629 fisher_loss 0.0920534432 triplet loss 0.739392817 l2_loss 9.69398499 fraction B 0.130368814 lossA 0.8550632 fraction A 0.0423560776\n",
      "step 952 loss 0.946733177 fisher_loss 0.0934965611 triplet loss 0.853236616 l2_loss 9.71339321 fraction B 0.0982284 lossA 0.850915492 fraction A 0.0423350334\n",
      "step 953 loss 0.909782 fisher_loss 0.0950638205 triplet loss 0.814718187 l2_loss 9.73053837 fraction B 0.145426854 lossA 0.846901178 fraction A 0.0427048318\n",
      "step 954 loss 1.08285809 fisher_loss 0.0973294 triplet loss 0.985528648 l2_loss 9.74542141 fraction B 0.212113038 lossA 0.851092935 fraction A 0.042523507\n",
      "step 955 loss 0.931620538 fisher_loss 0.0993173569 triplet loss 0.832303166 l2_loss 9.75929451 fraction B 0.104270816 lossA 0.863521278 fraction A 0.0412874073\n",
      "step 956 loss 0.979301691 fisher_loss 0.0998466611 triplet loss 0.87945503 l2_loss 9.77358055 fraction B 0.0946541727 lossA 0.888530493 fraction A 0.0388074778\n",
      "step 957 loss 0.816665173 fisher_loss 0.0999437347 triplet loss 0.716721416 l2_loss 9.78838921 fraction B 0.165796489 lossA 0.912752569 fraction A 0.0368997119\n",
      "step 958 loss 1.06472695 fisher_loss 0.100169487 triplet loss 0.964557409 l2_loss 9.80460835 fraction B 0.209559485 lossA 0.939769089 fraction A 0.0351098143\n",
      "step 959 loss 0.956655324 fisher_loss 0.100696303 triplet loss 0.855959 l2_loss 9.81863594 fraction B 0.164219126 lossA 0.961858571 fraction A 0.0339824148\n",
      "step 960 loss 1.08722758 fisher_loss 0.101780847 triplet loss 0.985446751 l2_loss 9.83408451 fraction B 0.128761321 lossA 0.97552377 fraction A 0.0338426642\n",
      "step 961 loss 1.06535149 fisher_loss 0.102897786 triplet loss 0.962453663 l2_loss 9.84911442 fraction B 0.17091009 lossA 0.982423961 fraction A 0.0343605019\n",
      "step 962 loss 0.794656873 fisher_loss 0.105823159 triplet loss 0.688833714 l2_loss 9.86425591 fraction B 0.115046166 lossA 0.984721124 fraction A 0.0349567905\n",
      "step 963 loss 0.924069881 fisher_loss 0.107473902 triplet loss 0.816596 l2_loss 9.87986279 fraction B 0.164365247 lossA 0.975216866 fraction A 0.0364653915\n",
      "step 964 loss 1.0795486 fisher_loss 0.109354712 triplet loss 0.970193923 l2_loss 9.89460468 fraction B 0.139064088 lossA 0.962486267 fraction A 0.038090609\n",
      "step 965 loss 0.933114 fisher_loss 0.110102363 triplet loss 0.823011637 l2_loss 9.9088974 fraction B 0.131678984 lossA 0.929113865 fraction A 0.0394796915\n",
      "step 966 loss 1.10329497 fisher_loss 0.107472152 triplet loss 0.995822847 l2_loss 9.92425156 fraction B 0.245865092 lossA 0.899634421 fraction A 0.0400091521\n",
      "step 967 loss 0.946501195 fisher_loss 0.103578329 triplet loss 0.842922866 l2_loss 9.93935299 fraction B 0.166027501 lossA 0.874574602 fraction A 0.0409337766\n",
      "step 968 loss 0.967936575 fisher_loss 0.103339873 triplet loss 0.864596725 l2_loss 9.95536 fraction B 0.168118566 lossA 0.858880818 fraction A 0.0427291393\n",
      "step 969 loss 0.847207904 fisher_loss 0.106235169 triplet loss 0.740972757 l2_loss 9.97032356 fraction B 0.0808309 lossA 0.855455339 fraction A 0.0445885472\n",
      "step 970 loss 0.956889153 fisher_loss 0.111378819 triplet loss 0.845510304 l2_loss 9.98607063 fraction B 0.145704746 lossA 0.866210222 fraction A 0.0458206125\n",
      "step 971 loss 0.972852826 fisher_loss 0.11645934 triplet loss 0.856393456 l2_loss 10.000041 fraction B 0.19072406 lossA 0.884861588 fraction A 0.0465014428\n",
      "step 972 loss 1.10173905 fisher_loss 0.11959406 triplet loss 0.982145 l2_loss 10.0121346 fraction B 0.113573059 lossA 0.909310579 fraction A 0.0457075499\n",
      "step 973 loss 1.30867386 fisher_loss 0.120384522 triplet loss 1.18828928 l2_loss 10.0233507 fraction B 0.177596822 lossA 0.928713202 fraction A 0.0438551418\n",
      "step 974 loss 0.969357252 fisher_loss 0.118007369 triplet loss 0.85134989 l2_loss 10.032732 fraction B 0.205419511 lossA 0.942400515 fraction A 0.0422900878\n",
      "step 975 loss 0.864903569 fisher_loss 0.116198242 triplet loss 0.748705328 l2_loss 10.0422125 fraction B 0.136086687 lossA 0.947969913 fraction A 0.0396190397\n",
      "step 976 loss 1.1893 fisher_loss 0.110315464 triplet loss 1.0789845 l2_loss 10.0531464 fraction B 0.179564565 lossA 0.956176162 fraction A 0.0375123173\n",
      "step 977 loss 0.912667215 fisher_loss 0.106924541 triplet loss 0.805742681 l2_loss 10.0620327 fraction B 0.134267166 lossA 0.958411515 fraction A 0.0355788171\n",
      "step 978 loss 0.935248077 fisher_loss 0.103456393 triplet loss 0.831791699 l2_loss 10.072154 fraction B 0.117494091 lossA 0.96065104 fraction A 0.0345897786\n",
      "step 979 loss 1.07930982 fisher_loss 0.104229607 triplet loss 0.975080252 l2_loss 10.0809507 fraction B 0.155322611 lossA 0.956069589 fraction A 0.0348511711\n",
      "step 980 loss 0.753012061 fisher_loss 0.106330976 triplet loss 0.64668107 l2_loss 10.0879765 fraction B 0.103012808 lossA 0.950042367 fraction A 0.0356971584\n",
      "step 981 loss 0.917231202 fisher_loss 0.109908201 triplet loss 0.807323 l2_loss 10.0948763 fraction B 0.154996395 lossA 0.955691099 fraction A 0.0359508544\n",
      "step 982 loss 0.962290883 fisher_loss 0.11236833 triplet loss 0.849922538 l2_loss 10.1022596 fraction B 0.169302821 lossA 0.953079283 fraction A 0.0362272412\n",
      "step 983 loss 0.925632 fisher_loss 0.109776013 triplet loss 0.815856 l2_loss 10.1102057 fraction B 0.166798711 lossA 0.953796268 fraction A 0.0363411829\n",
      "step 984 loss 1.04698408 fisher_loss 0.106761955 triplet loss 0.940222144 l2_loss 10.1175213 fraction B 0.11004594 lossA 0.956238091 fraction A 0.035865359\n",
      "step 985 loss 1.03268349 fisher_loss 0.103465803 triplet loss 0.929217637 l2_loss 10.1266527 fraction B 0.146886066 lossA 0.962100506 fraction A 0.0353746153\n",
      "step 986 loss 0.870171726 fisher_loss 0.102078907 triplet loss 0.768092811 l2_loss 10.1386271 fraction B 0.147032961 lossA 0.953758597 fraction A 0.0358235314\n",
      "step 987 loss 0.886326313 fisher_loss 0.101326793 triplet loss 0.784999549 l2_loss 10.1500444 fraction B 0.137239113 lossA 0.942606 fraction A 0.0367213227\n",
      "step 988 loss 0.860894084 fisher_loss 0.101694129 triplet loss 0.7592 l2_loss 10.1636581 fraction B 0.162132412 lossA 0.924269855 fraction A 0.038736023\n",
      "step 989 loss 1.35353506 fisher_loss 0.102821022 triplet loss 1.25071406 l2_loss 10.1777172 fraction B 0.142280772 lossA 0.888745785 fraction A 0.0418495685\n",
      "step 990 loss 1.04994965 fisher_loss 0.101340428 triplet loss 0.948609233 l2_loss 10.1896172 fraction B 0.130589947 lossA 0.859785557 fraction A 0.0450675972\n",
      "step 991 loss 1.08598459 fisher_loss 0.100239687 triplet loss 0.985744894 l2_loss 10.2006063 fraction B 0.217534572 lossA 0.832948446 fraction A 0.0492197797\n",
      "step 992 loss 0.999551773 fisher_loss 0.101093881 triplet loss 0.898457885 l2_loss 10.2108641 fraction B 0.10047704 lossA 0.810417473 fraction A 0.052227851\n",
      "step 993 loss 0.915894032 fisher_loss 0.101808578 triplet loss 0.814085484 l2_loss 10.223278 fraction B 0.146376282 lossA 0.798810542 fraction A 0.0535742976\n",
      "step 994 loss 1.04757774 fisher_loss 0.102265231 triplet loss 0.9453125 l2_loss 10.2346783 fraction B 0.103881359 lossA 0.796790123 fraction A 0.0532501414\n",
      "step 995 loss 1.31674612 fisher_loss 0.102349922 triplet loss 1.21439624 l2_loss 10.2454844 fraction B 0.133492827 lossA 0.799832 fraction A 0.0520061255\n",
      "step 996 loss 1.03201127 fisher_loss 0.103315711 triplet loss 0.928695619 l2_loss 10.2559042 fraction B 0.148412526 lossA 0.816546559 fraction A 0.0493100397\n",
      "step 997 loss 1.08668458 fisher_loss 0.108356506 triplet loss 0.978328049 l2_loss 10.2661276 fraction B 0.201695949 lossA 0.850442 fraction A 0.045898445\n",
      "step 998 loss 1.07367229 fisher_loss 0.115311049 triplet loss 0.958361208 l2_loss 10.2755766 fraction B 0.230952039 lossA 0.893681645 fraction A 0.0418544821\n",
      "step 999 loss 1.00270236 fisher_loss 0.120618008 triplet loss 0.88208437 l2_loss 10.285738 fraction B 0.171881691 lossA 0.933381915 fraction A 0.0391255841\n",
      "step 1000 loss 1.02740717 fisher_loss 0.124641798 triplet loss 0.902765334 l2_loss 10.295785 fraction B 0.180607259 lossA 0.960939705 fraction A 0.0374149829\n",
      "step 1001 loss 1.11335278 fisher_loss 0.125314802 triplet loss 0.988038 l2_loss 10.3067684 fraction B 0.207959816 lossA 0.970773 fraction A 0.0368665345\n",
      "step 1002 loss 1.00281489 fisher_loss 0.122600392 triplet loss 0.880214512 l2_loss 10.3160095 fraction B 0.154125899 lossA 0.963079274 fraction A 0.036745958\n",
      "step 1003 loss 0.766062379 fisher_loss 0.115471579 triplet loss 0.650590777 l2_loss 10.3245306 fraction B 0.128030792 lossA 0.932391882 fraction A 0.03761255\n",
      "step 1004 loss 1.06552553 fisher_loss 0.105176352 triplet loss 0.960349143 l2_loss 10.3325682 fraction B 0.196480572 lossA 0.896635234 fraction A 0.0398746766\n",
      "step 1005 loss 0.94704318 fisher_loss 0.0990613401 triplet loss 0.84798187 l2_loss 10.3417225 fraction B 0.195950329 lossA 0.877524137 fraction A 0.0412956588\n",
      "step 1006 loss 0.920015574 fisher_loss 0.0968571752 triplet loss 0.823158383 l2_loss 10.3517179 fraction B 0.14396067 lossA 0.863606513 fraction A 0.0429001637\n",
      "step 1007 loss 1.06922448 fisher_loss 0.0971055925 triplet loss 0.972118855 l2_loss 10.3612576 fraction B 0.129243061 lossA 0.856944144 fraction A 0.0444426723\n",
      "step 1008 loss 1.00401711 fisher_loss 0.0980183259 triplet loss 0.905998826 l2_loss 10.3690834 fraction B 0.123411946 lossA 0.851296067 fraction A 0.0464154\n",
      "step 1009 loss 0.968589902 fisher_loss 0.0991546735 triplet loss 0.869435251 l2_loss 10.3769016 fraction B 0.122131087 lossA 0.861425102 fraction A 0.0464514\n",
      "step 1010 loss 0.892232418 fisher_loss 0.100300401 triplet loss 0.791932046 l2_loss 10.3855028 fraction B 0.144735485 lossA 0.870838284 fraction A 0.045910798\n",
      "step 1011 loss 0.945965469 fisher_loss 0.0997068733 triplet loss 0.846258581 l2_loss 10.3966713 fraction B 0.138665363 lossA 0.882178187 fraction A 0.0450696833\n",
      "step 1012 loss 1.01641905 fisher_loss 0.0986396298 triplet loss 0.917779446 l2_loss 10.4089441 fraction B 0.0842904076 lossA 0.90177238 fraction A 0.0429162197\n",
      "step 1013 loss 0.950604439 fisher_loss 0.0973832756 triplet loss 0.853221178 l2_loss 10.4206944 fraction B 0.17526646 lossA 0.920206249 fraction A 0.0407109894\n",
      "step 1014 loss 1.11020279 fisher_loss 0.0961540267 triplet loss 1.01404881 l2_loss 10.4326096 fraction B 0.131652504 lossA 0.937097669 fraction A 0.0396805964\n",
      "step 1015 loss 0.977083743 fisher_loss 0.0983057171 triplet loss 0.87877804 l2_loss 10.446867 fraction B 0.143583789 lossA 0.94980216 fraction A 0.039396178\n",
      "step 1016 loss 0.905369341 fisher_loss 0.101543628 triplet loss 0.803825736 l2_loss 10.4606295 fraction B 0.140675589 lossA 0.953662634 fraction A 0.0395934507\n",
      "step 1017 loss 0.899552405 fisher_loss 0.103408732 triplet loss 0.796143651 l2_loss 10.4740248 fraction B 0.167120755 lossA 0.950298905 fraction A 0.039723929\n",
      "step 1018 loss 1.10969102 fisher_loss 0.101771139 triplet loss 1.00791991 l2_loss 10.4834538 fraction B 0.210353538 lossA 0.948319435 fraction A 0.039778\n",
      "step 1019 loss 1.11904669 fisher_loss 0.100382753 triplet loss 1.01866388 l2_loss 10.4929562 fraction B 0.174393088 lossA 0.940018594 fraction A 0.0403265245\n",
      "step 1020 loss 1.02487922 fisher_loss 0.0987038091 triplet loss 0.926175356 l2_loss 10.5017881 fraction B 0.175356567 lossA 0.910082519 fraction A 0.0426252782\n",
      "step 1021 loss 0.990125716 fisher_loss 0.0960708708 triplet loss 0.89405483 l2_loss 10.5102777 fraction B 0.235151187 lossA 0.888472438 fraction A 0.045097217\n",
      "step 1022 loss 1.09693098 fisher_loss 0.0949757695 triplet loss 1.00195515 l2_loss 10.5187197 fraction B 0.219953179 lossA 0.877456725 fraction A 0.0466616899\n",
      "step 1023 loss 0.913228333 fisher_loss 0.0943617895 triplet loss 0.818866551 l2_loss 10.527916 fraction B 0.151237 lossA 0.868323684 fraction A 0.0481962785\n",
      "step 1024 loss 0.766911328 fisher_loss 0.0950694308 triplet loss 0.671841919 l2_loss 10.5378656 fraction B 0.129893363 lossA 0.874425292 fraction A 0.0475475639\n",
      "step 1025 loss 0.899968 fisher_loss 0.0949348509 triplet loss 0.805033207 l2_loss 10.5489168 fraction B 0.105171271 lossA 0.880726516 fraction A 0.0467808358\n",
      "step 1026 loss 0.927649617 fisher_loss 0.095491 triplet loss 0.832158625 l2_loss 10.5628433 fraction B 0.142450348 lossA 0.892820239 fraction A 0.0456010476\n",
      "step 1027 loss 0.959800065 fisher_loss 0.0975608826 triplet loss 0.862239182 l2_loss 10.5797443 fraction B 0.120004348 lossA 0.911409736 fraction A 0.0444044359\n",
      "step 1028 loss 0.956540465 fisher_loss 0.101857804 triplet loss 0.854682684 l2_loss 10.5961905 fraction B 0.101318195 lossA 0.937979102 fraction A 0.0425348\n",
      "step 1029 loss 1.08910298 fisher_loss 0.106483072 triplet loss 0.982619941 l2_loss 10.6111975 fraction B 0.188089237 lossA 0.959008515 fraction A 0.0402291156\n",
      "step 1030 loss 1.07041836 fisher_loss 0.108063497 triplet loss 0.962354839 l2_loss 10.6278629 fraction B 0.223367453 lossA 0.9764539 fraction A 0.0385641567\n",
      "step 1031 loss 0.942625344 fisher_loss 0.108673386 triplet loss 0.83395195 l2_loss 10.6429224 fraction B 0.205032364 lossA 0.980794191 fraction A 0.0381202288\n",
      "step 1032 loss 0.874995 fisher_loss 0.108314924 triplet loss 0.766680062 l2_loss 10.6594524 fraction B 0.150365919 lossA 0.968960464 fraction A 0.0371255465\n",
      "step 1033 loss 1.06506574 fisher_loss 0.10384728 triplet loss 0.961218476 l2_loss 10.6705532 fraction B 0.175124958 lossA 0.95812571 fraction A 0.0358599722\n",
      "step 1034 loss 0.91745156 fisher_loss 0.100237913 triplet loss 0.817213655 l2_loss 10.6799049 fraction B 0.102187499 lossA 0.95272404 fraction A 0.035557922\n",
      "step 1035 loss 0.929312348 fisher_loss 0.101583153 triplet loss 0.827729225 l2_loss 10.6901 fraction B 0.114089847 lossA 0.950882196 fraction A 0.0361612514\n",
      "step 1036 loss 1.06012368 fisher_loss 0.105306722 triplet loss 0.954817 l2_loss 10.6991081 fraction B 0.134211957 lossA 0.938695252 fraction A 0.0378267951\n",
      "step 1037 loss 1.0382905 fisher_loss 0.109578371 triplet loss 0.92871207 l2_loss 10.7090054 fraction B 0.146786362 lossA 0.919030428 fraction A 0.0394407585\n",
      "step 1038 loss 1.00224626 fisher_loss 0.109859377 triplet loss 0.892386913 l2_loss 10.7177925 fraction B 0.254235774 lossA 0.89841491 fraction A 0.0411937051\n",
      "step 1039 loss 0.886858821 fisher_loss 0.106736816 triplet loss 0.780122 l2_loss 10.7268782 fraction B 0.0807875469 lossA 0.881651819 fraction A 0.0431951\n",
      "step 1040 loss 0.95443958 fisher_loss 0.104370348 triplet loss 0.850069225 l2_loss 10.734663 fraction B 0.217267588 lossA 0.867400348 fraction A 0.0452091061\n",
      "step 1041 loss 0.934204876 fisher_loss 0.101866782 triplet loss 0.832338095 l2_loss 10.7422419 fraction B 0.0946356654 lossA 0.86283195 fraction A 0.0459694564\n",
      "step 1042 loss 1.04253447 fisher_loss 0.0994841605 triplet loss 0.943050325 l2_loss 10.749815 fraction B 0.136206776 lossA 0.860988319 fraction A 0.0462124459\n",
      "step 1043 loss 0.879366755 fisher_loss 0.097675927 triplet loss 0.781690836 l2_loss 10.7566395 fraction B 0.127043113 lossA 0.862771511 fraction A 0.0456187576\n",
      "step 1044 loss 1.14970398 fisher_loss 0.0986097232 triplet loss 1.05109429 l2_loss 10.7656994 fraction B 0.209516615 lossA 0.861283243 fraction A 0.0455195904\n",
      "step 1045 loss 0.949393153 fisher_loss 0.101780929 triplet loss 0.847612202 l2_loss 10.7762928 fraction B 0.154786333 lossA 0.869541824 fraction A 0.0447003618\n",
      "step 1046 loss 0.879610479 fisher_loss 0.106722102 triplet loss 0.772888362 l2_loss 10.7886677 fraction B 0.138172835 lossA 0.876622558 fraction A 0.0442096926\n",
      "step 1047 loss 0.939473271 fisher_loss 0.109390691 triplet loss 0.830082595 l2_loss 10.8021116 fraction B 0.128463522 lossA 0.872383833 fraction A 0.0448848046\n",
      "step 1048 loss 1.26143515 fisher_loss 0.106929831 triplet loss 1.15450537 l2_loss 10.8133183 fraction B 0.217870042 lossA 0.866446495 fraction A 0.0452315062\n",
      "step 1049 loss 0.962825775 fisher_loss 0.103381246 triplet loss 0.859444499 l2_loss 10.8232708 fraction B 0.144422382 lossA 0.859822869 fraction A 0.0454786755\n",
      "step 1050 loss 0.883158267 fisher_loss 0.100362636 triplet loss 0.782795608 l2_loss 10.8333693 fraction B 0.166660637 lossA 0.866481602 fraction A 0.0433721729\n",
      "step 1051 loss 0.993579865 fisher_loss 0.0982971862 triplet loss 0.895282686 l2_loss 10.8466921 fraction B 0.146012932 lossA 0.873391509 fraction A 0.0420652814\n",
      "step 1052 loss 0.997308969 fisher_loss 0.0976729617 triplet loss 0.89963603 l2_loss 10.8579855 fraction B 0.161592126 lossA 0.878770292 fraction A 0.0407946482\n",
      "step 1053 loss 0.895593 fisher_loss 0.0983180851 triplet loss 0.797274888 l2_loss 10.8699751 fraction B 0.122942105 lossA 0.884871304 fraction A 0.0401409827\n",
      "step 1054 loss 0.888112545 fisher_loss 0.0982562676 triplet loss 0.789856255 l2_loss 10.8813152 fraction B 0.105602965 lossA 0.89425844 fraction A 0.0393060297\n",
      "step 1055 loss 0.827654362 fisher_loss 0.0984072 triplet loss 0.729247153 l2_loss 10.8932791 fraction B 0.131399751 lossA 0.907329679 fraction A 0.038177751\n",
      "step 1056 loss 0.876031697 fisher_loss 0.0987210646 triplet loss 0.77731061 l2_loss 10.9081059 fraction B 0.090380989 lossA 0.925237536 fraction A 0.0366433784\n",
      "step 1057 loss 1.03511953 fisher_loss 0.100211799 triplet loss 0.934907794 l2_loss 10.9242592 fraction B 0.152052954 lossA 0.940558314 fraction A 0.0357643217\n",
      "step 1058 loss 0.970139503 fisher_loss 0.101307631 triplet loss 0.868831873 l2_loss 10.9406099 fraction B 0.146859303 lossA 0.951166391 fraction A 0.0356330387\n",
      "step 1059 loss 1.04352283 fisher_loss 0.102130204 triplet loss 0.941392601 l2_loss 10.9559107 fraction B 0.163997829 lossA 0.952902257 fraction A 0.036126826\n",
      "step 1060 loss 1.03437901 fisher_loss 0.101963781 triplet loss 0.932415187 l2_loss 10.9710894 fraction B 0.15387547 lossA 0.939466655 fraction A 0.0374214351\n",
      "step 1061 loss 1.10880947 fisher_loss 0.100979917 triplet loss 1.00782955 l2_loss 10.987875 fraction B 0.181277052 lossA 0.917937398 fraction A 0.0392879546\n",
      "step 1062 loss 0.952322185 fisher_loss 0.0995013937 triplet loss 0.852820814 l2_loss 11.0028238 fraction B 0.202697828 lossA 0.906507671 fraction A 0.040675316\n",
      "step 1063 loss 0.95977062 fisher_loss 0.0980873182 triplet loss 0.861683309 l2_loss 11.0159893 fraction B 0.215144753 lossA 0.89763093 fraction A 0.042363517\n",
      "step 1064 loss 1.04732883 fisher_loss 0.0976929814 triplet loss 0.949635863 l2_loss 11.0283537 fraction B 0.260895401 lossA 0.889408052 fraction A 0.0441193581\n",
      "step 1065 loss 1.00236368 fisher_loss 0.0974716619 triplet loss 0.904892 l2_loss 11.0387154 fraction B 0.177112162 lossA 0.887034178 fraction A 0.0450277813\n",
      "step 1066 loss 0.867599249 fisher_loss 0.0972761139 triplet loss 0.770323157 l2_loss 11.0510588 fraction B 0.148180366 lossA 0.886521637 fraction A 0.0450861827\n",
      "step 1067 loss 0.768749774 fisher_loss 0.0972270444 triplet loss 0.671522737 l2_loss 11.0641184 fraction B 0.127051279 lossA 0.890276849 fraction A 0.0447494872\n",
      "step 1068 loss 0.854129314 fisher_loss 0.0945683569 triplet loss 0.759560943 l2_loss 11.0788479 fraction B 0.152113155 lossA 0.888325214 fraction A 0.0452761948\n",
      "step 1069 loss 0.819116 fisher_loss 0.0922311246 triplet loss 0.726884902 l2_loss 11.0936375 fraction B 0.10477151 lossA 0.884737 fraction A 0.0451135673\n",
      "step 1070 loss 0.843644381 fisher_loss 0.091057688 triplet loss 0.752586663 l2_loss 11.1093626 fraction B 0.123335399 lossA 0.887497902 fraction A 0.0440642945\n",
      "step 1071 loss 1.00354397 fisher_loss 0.0903714299 triplet loss 0.913172543 l2_loss 11.1268225 fraction B 0.160816923 lossA 0.898388743 fraction A 0.0423680656\n",
      "step 1072 loss 1.1420821 fisher_loss 0.0907221884 triplet loss 1.05135989 l2_loss 11.1441813 fraction B 0.205286816 lossA 0.914581835 fraction A 0.0401120596\n",
      "step 1073 loss 0.940158367 fisher_loss 0.0918732584 triplet loss 0.848285139 l2_loss 11.1599941 fraction B 0.0910532102 lossA 0.927621186 fraction A 0.0384763181\n",
      "step 1074 loss 1.03233802 fisher_loss 0.0938583091 triplet loss 0.938479722 l2_loss 11.1757956 fraction B 0.132815883 lossA 0.932249725 fraction A 0.0377020389\n",
      "step 1075 loss 1.07126629 fisher_loss 0.0954496115 triplet loss 0.975816727 l2_loss 11.1894875 fraction B 0.0966127515 lossA 0.935583591 fraction A 0.0369882137\n",
      "step 1076 loss 0.844719887 fisher_loss 0.0965296 triplet loss 0.748190284 l2_loss 11.2026062 fraction B 0.0476417691 lossA 0.937413573 fraction A 0.0370160379\n",
      "step 1077 loss 0.963707507 fisher_loss 0.0964735597 triplet loss 0.867233932 l2_loss 11.2158337 fraction B 0.159144163 lossA 0.940617681 fraction A 0.0371855237\n",
      "step 1078 loss 1.00481594 fisher_loss 0.0965723544 triplet loss 0.908243597 l2_loss 11.2266502 fraction B 0.11299374 lossA 0.940358937 fraction A 0.0377095193\n",
      "step 1079 loss 0.830123961 fisher_loss 0.0967672095 triplet loss 0.733356774 l2_loss 11.2378178 fraction B 0.07293652 lossA 0.938194454 fraction A 0.0388704613\n",
      "step 1080 loss 0.832378626 fisher_loss 0.0969213 triplet loss 0.735457301 l2_loss 11.2481089 fraction B 0.0891551822 lossA 0.936311603 fraction A 0.0399355702\n",
      "step 1081 loss 1.08826506 fisher_loss 0.0965651646 triplet loss 0.991699874 l2_loss 11.2594337 fraction B 0.119929299 lossA 0.929470956 fraction A 0.0413299352\n",
      "step 1082 loss 0.921098232 fisher_loss 0.0965104252 triplet loss 0.824587822 l2_loss 11.2707367 fraction B 0.172879532 lossA 0.927088559 fraction A 0.0422681645\n",
      "step 1083 loss 0.862505138 fisher_loss 0.096746169 triplet loss 0.765759 l2_loss 11.2821217 fraction B 0.133098081 lossA 0.935211539 fraction A 0.0423171781\n",
      "step 1084 loss 1.15901232 fisher_loss 0.0964045674 triplet loss 1.06260777 l2_loss 11.297492 fraction B 0.229496092 lossA 0.942158222 fraction A 0.0419427603\n",
      "step 1085 loss 1.06269312 fisher_loss 0.0962504074 triplet loss 0.966442764 l2_loss 11.3117065 fraction B 0.122042067 lossA 0.952590585 fraction A 0.0414900333\n",
      "step 1086 loss 0.748048186 fisher_loss 0.0967563 triplet loss 0.651291907 l2_loss 11.3255339 fraction B 0.103881359 lossA 0.965082645 fraction A 0.0410358049\n",
      "step 1087 loss 0.870607793 fisher_loss 0.097748749 triplet loss 0.772859037 l2_loss 11.3398151 fraction B 0.124730796 lossA 0.993508 fraction A 0.040193297\n",
      "step 1088 loss 0.928259492 fisher_loss 0.100642465 triplet loss 0.827617049 l2_loss 11.3532734 fraction B 0.113138027 lossA 1.00798738 fraction A 0.0402010344\n",
      "step 1089 loss 0.946041167 fisher_loss 0.101772524 triplet loss 0.84426862 l2_loss 11.3683643 fraction B 0.137151271 lossA 1.018538 fraction A 0.040354792\n",
      "step 1090 loss 0.750986159 fisher_loss 0.101760432 triplet loss 0.649225712 l2_loss 11.384552 fraction B 0.0914322 lossA 1.02098536 fraction A 0.0405547768\n",
      "step 1091 loss 1.03438544 fisher_loss 0.103170224 triplet loss 0.931215167 l2_loss 11.4020309 fraction B 0.114264704 lossA 1.02314126 fraction A 0.0396112688\n",
      "step 1092 loss 0.882756 fisher_loss 0.103445336 triplet loss 0.779310644 l2_loss 11.4205456 fraction B 0.0672953576 lossA 1.0227716 fraction A 0.037808869\n",
      "step 1093 loss 1.16765785 fisher_loss 0.102836907 triplet loss 1.06482089 l2_loss 11.4394579 fraction B 0.190974 lossA 1.00534368 fraction A 0.0354958922\n",
      "step 1094 loss 0.987899423 fisher_loss 0.103498153 triplet loss 0.884401262 l2_loss 11.4608707 fraction B 0.193252861 lossA 0.963590622 fraction A 0.0346395262\n",
      "step 1095 loss 1.12854099 fisher_loss 0.10640806 triplet loss 1.02213287 l2_loss 11.4795008 fraction B 0.131651446 lossA 0.938906431 fraction A 0.0343463495\n",
      "step 1096 loss 0.979718089 fisher_loss 0.109918147 triplet loss 0.869799912 l2_loss 11.4954576 fraction B 0.0809523836 lossA 0.930590332 fraction A 0.0338371284\n",
      "step 1097 loss 1.00803232 fisher_loss 0.114620373 triplet loss 0.893411934 l2_loss 11.5109148 fraction B 0.0651404411 lossA 0.930573881 fraction A 0.033845745\n",
      "step 1098 loss 1.0596168 fisher_loss 0.117567606 triplet loss 0.942049205 l2_loss 11.5244846 fraction B 0.0719295591 lossA 0.936532199 fraction A 0.0340892449\n",
      "step 1099 loss 0.97958678 fisher_loss 0.120428927 triplet loss 0.85915786 l2_loss 11.5367289 fraction B 0.0999273881 lossA 0.952277064 fraction A 0.034040194\n",
      "step 1100 loss 0.928829789 fisher_loss 0.122627 triplet loss 0.806202769 l2_loss 11.5489922 fraction B 0.138785541 lossA 0.946960807 fraction A 0.0337933935\n",
      "step 1101 loss 1.1248107 fisher_loss 0.116922051 triplet loss 1.00788867 l2_loss 11.5597477 fraction B 0.131210536 lossA 0.935845196 fraction A 0.0337605439\n",
      "step 1102 loss 0.887141228 fisher_loss 0.111801162 triplet loss 0.77534008 l2_loss 11.569994 fraction B 0.103509352 lossA 0.926427722 fraction A 0.0342837311\n",
      "step 1103 loss 0.899204195 fisher_loss 0.10804113 triplet loss 0.791163087 l2_loss 11.5799723 fraction B 0.112178788 lossA 0.921734869 fraction A 0.0343795642\n",
      "step 1104 loss 1.03235495 fisher_loss 0.105404213 triplet loss 0.926950753 l2_loss 11.5906677 fraction B 0.155992851 lossA 0.922136664 fraction A 0.034598466\n",
      "step 1105 loss 1.05319786 fisher_loss 0.10587772 triplet loss 0.947320163 l2_loss 11.6014347 fraction B 0.153895959 lossA 0.917482674 fraction A 0.0355588757\n",
      "step 1106 loss 0.998909116 fisher_loss 0.107543528 triplet loss 0.891365588 l2_loss 11.6107244 fraction B 0.137310475 lossA 0.913307488 fraction A 0.0371583551\n",
      "step 1107 loss 0.831509292 fisher_loss 0.111461006 triplet loss 0.720048308 l2_loss 11.6198854 fraction B 0.0784045 lossA 0.918597937 fraction A 0.0385780148\n",
      "step 1108 loss 1.14030588 fisher_loss 0.115701482 triplet loss 1.02460444 l2_loss 11.6306267 fraction B 0.18737857 lossA 0.907736659 fraction A 0.0402764082\n",
      "step 1109 loss 0.968492389 fisher_loss 0.116941527 triplet loss 0.851550877 l2_loss 11.6406279 fraction B 0.158319265 lossA 0.893988788 fraction A 0.041539453\n",
      "step 1110 loss 0.999043107 fisher_loss 0.115590312 triplet loss 0.883452773 l2_loss 11.650425 fraction B 0.201202825 lossA 0.886176288 fraction A 0.0426746979\n",
      "step 1111 loss 0.988305509 fisher_loss 0.114794053 triplet loss 0.873511434 l2_loss 11.6594162 fraction B 0.103032306 lossA 0.8787269 fraction A 0.0428837\n",
      "step 1112 loss 0.860694945 fisher_loss 0.112133019 triplet loss 0.748561919 l2_loss 11.6682482 fraction B 0.19773218 lossA 0.874363 fraction A 0.0422456525\n",
      "step 1113 loss 0.969370723 fisher_loss 0.108993754 triplet loss 0.860376954 l2_loss 11.6765871 fraction B 0.143889859 lossA 0.862843454 fraction A 0.0420759507\n",
      "step 1114 loss 0.869623303 fisher_loss 0.106295303 triplet loss 0.763328 l2_loss 11.6854801 fraction B 0.0950150117 lossA 0.859440148 fraction A 0.0418577455\n",
      "step 1115 loss 0.991289854 fisher_loss 0.106960289 triplet loss 0.884329557 l2_loss 11.6949205 fraction B 0.151919305 lossA 0.865671217 fraction A 0.0419542342\n",
      "step 1116 loss 0.987975895 fisher_loss 0.109910168 triplet loss 0.878065705 l2_loss 11.7031784 fraction B 0.153197855 lossA 0.877278745 fraction A 0.0410356931\n",
      "step 1117 loss 0.92362076 fisher_loss 0.109300829 triplet loss 0.814319909 l2_loss 11.7091675 fraction B 0.141202703 lossA 0.887096703 fraction A 0.0398585089\n",
      "step 1118 loss 0.915629447 fisher_loss 0.107746519 triplet loss 0.807882905 l2_loss 11.7155008 fraction B 0.109366491 lossA 0.890926182 fraction A 0.0402225554\n",
      "step 1119 loss 0.842889249 fisher_loss 0.108264215 triplet loss 0.734625041 l2_loss 11.7208729 fraction B 0.121683307 lossA 0.881978393 fraction A 0.0422808491\n",
      "step 1120 loss 1.06304348 fisher_loss 0.10892655 triplet loss 0.95411694 l2_loss 11.7267847 fraction B 0.170063376 lossA 0.863083839 fraction A 0.0434405431\n",
      "step 1121 loss 0.938719511 fisher_loss 0.108991161 triplet loss 0.829728365 l2_loss 11.732831 fraction B 0.101702005 lossA 0.858418107 fraction A 0.0413512737\n",
      "step 1122 loss 1.04416108 fisher_loss 0.106917948 triplet loss 0.937243164 l2_loss 11.7414713 fraction B 0.123566009 lossA 0.877426326 fraction A 0.0378583595\n",
      "step 1123 loss 0.994336426 fisher_loss 0.105898075 triplet loss 0.888438344 l2_loss 11.7505789 fraction B 0.110669136 lossA 0.906941 fraction A 0.035171479\n",
      "step 1124 loss 1.22645688 fisher_loss 0.108552195 triplet loss 1.11790466 l2_loss 11.7613153 fraction B 0.173323691 lossA 0.943156421 fraction A 0.033791814\n",
      "step 1125 loss 0.859871 fisher_loss 0.113613077 triplet loss 0.746257901 l2_loss 11.7723703 fraction B 0.10477569 lossA 1.00168633 fraction A 0.0323738419\n",
      "step 1126 loss 1.11118162 fisher_loss 0.119300537 triplet loss 0.991881132 l2_loss 11.7870827 fraction B 0.144086227 lossA 1.02632678 fraction A 0.0316035226\n",
      "step 1127 loss 1.03750253 fisher_loss 0.118827656 triplet loss 0.918674886 l2_loss 11.8038197 fraction B 0.165544435 lossA 1.02343786 fraction A 0.031659428\n",
      "step 1128 loss 0.94171977 fisher_loss 0.11579825 triplet loss 0.825921535 l2_loss 11.8176098 fraction B 0.155364335 lossA 1.00339592 fraction A 0.0319362581\n",
      "step 1129 loss 0.82760936 fisher_loss 0.111925602 triplet loss 0.715683758 l2_loss 11.8325539 fraction B 0.149998128 lossA 0.975485742 fraction A 0.0324962549\n",
      "step 1130 loss 0.990775287 fisher_loss 0.108039245 triplet loss 0.882736 l2_loss 11.8481617 fraction B 0.136839256 lossA 0.934446096 fraction A 0.0338432156\n",
      "step 1131 loss 1.18725502 fisher_loss 0.10548044 triplet loss 1.08177459 l2_loss 11.8626614 fraction B 0.112002172 lossA 0.892536283 fraction A 0.0369139\n",
      "step 1132 loss 1.06671536 fisher_loss 0.105174825 triplet loss 0.96154058 l2_loss 11.87638 fraction B 0.19479166 lossA 0.864345849 fraction A 0.0408505201\n",
      "step 1133 loss 0.856639504 fisher_loss 0.108151466 triplet loss 0.748488069 l2_loss 11.8906279 fraction B 0.121500559 lossA 0.85341543 fraction A 0.0448053963\n",
      "step 1134 loss 0.871604264 fisher_loss 0.111182041 triplet loss 0.76042223 l2_loss 11.905221 fraction B 0.109998554 lossA 0.844487906 fraction A 0.0509430654\n",
      "step 1135 loss 0.949302375 fisher_loss 0.115663506 triplet loss 0.833638847 l2_loss 11.9181671 fraction B 0.118296705 lossA 0.845677078 fraction A 0.0546759628\n",
      "step 1136 loss 0.820603132 fisher_loss 0.117284134 triplet loss 0.703319 l2_loss 11.9317417 fraction B 0.10146451 lossA 0.845599473 fraction A 0.0547414\n",
      "step 1137 loss 1.11729825 fisher_loss 0.111983769 triplet loss 1.00531447 l2_loss 11.9484844 fraction B 0.168682888 lossA 0.850313127 fraction A 0.0528369732\n",
      "step 1138 loss 0.981009245 fisher_loss 0.107800417 triplet loss 0.873208821 l2_loss 11.9637365 fraction B 0.128895283 lossA 0.865671456 fraction A 0.0482862443\n",
      "step 1139 loss 1.08011281 fisher_loss 0.105733551 triplet loss 0.974379301 l2_loss 11.9792128 fraction B 0.124181837 lossA 0.891503096 fraction A 0.0438552536\n",
      "step 1140 loss 0.984074175 fisher_loss 0.107089885 triplet loss 0.876984298 l2_loss 11.9936333 fraction B 0.0837823302 lossA 0.925376892 fraction A 0.0402857587\n",
      "step 1141 loss 0.799429417 fisher_loss 0.110621765 triplet loss 0.688807666 l2_loss 12.0069542 fraction B 0.0988558456 lossA 0.948652 fraction A 0.0386878885\n",
      "step 1142 loss 0.738579 fisher_loss 0.112611987 triplet loss 0.625966966 l2_loss 12.0223837 fraction B 0.0727472529 lossA 0.948504806 fraction A 0.0381663851\n",
      "step 1143 loss 1.00296009 fisher_loss 0.111249872 triplet loss 0.891710162 l2_loss 12.0356083 fraction B 0.174445242 lossA 0.946215928 fraction A 0.037804652\n",
      "step 1144 loss 0.998546481 fisher_loss 0.109078877 triplet loss 0.889467597 l2_loss 12.0471907 fraction B 0.137748301 lossA 0.941942334 fraction A 0.0377853326\n",
      "step 1145 loss 1.00094748 fisher_loss 0.107247308 triplet loss 0.893700123 l2_loss 12.0593386 fraction B 0.158077642 lossA 0.937119 fraction A 0.0380351767\n",
      "step 1146 loss 1.00130951 fisher_loss 0.105489232 triplet loss 0.89582026 l2_loss 12.0710793 fraction B 0.111357555 lossA 0.934742212 fraction A 0.0378356315\n",
      "step 1147 loss 1.04965 fisher_loss 0.104197368 triplet loss 0.945452571 l2_loss 12.0810232 fraction B 0.188148409 lossA 0.929286778 fraction A 0.0383223407\n",
      "step 1148 loss 1.06668401 fisher_loss 0.10333962 triplet loss 0.963344395 l2_loss 12.0892935 fraction B 0.142451674 lossA 0.922812283 fraction A 0.0390329771\n",
      "step 1149 loss 0.924009681 fisher_loss 0.103646904 triplet loss 0.820362806 l2_loss 12.0961943 fraction B 0.099242039 lossA 0.919962287 fraction A 0.0397374928\n",
      "step 1150 loss 0.880917549 fisher_loss 0.104338288 triplet loss 0.776579261 l2_loss 12.1036797 fraction B 0.0914510116 lossA 0.921862662 fraction A 0.03975036\n",
      "step 1151 loss 0.820844114 fisher_loss 0.104016289 triplet loss 0.71682781 l2_loss 12.1152744 fraction B 0.101623669 lossA 0.927728057 fraction A 0.0391773507\n",
      "step 1152 loss 1.07635462 fisher_loss 0.103526324 triplet loss 0.972828269 l2_loss 12.127408 fraction B 0.169896275 lossA 0.937494159 fraction A 0.038027\n",
      "step 1153 loss 0.927585721 fisher_loss 0.103731424 triplet loss 0.823854268 l2_loss 12.1402063 fraction B 0.146387905 lossA 0.939612 fraction A 0.036969956\n",
      "step 1154 loss 0.893712878 fisher_loss 0.103602916 triplet loss 0.79011 l2_loss 12.1530304 fraction B 0.142693773 lossA 0.943119109 fraction A 0.035630621\n",
      "step 1155 loss 0.933561862 fisher_loss 0.103975296 triplet loss 0.829586565 l2_loss 12.1671495 fraction B 0.123806082 lossA 0.938360572 fraction A 0.0355304629\n",
      "step 1156 loss 0.911085367 fisher_loss 0.103772663 triplet loss 0.807312727 l2_loss 12.1786013 fraction B 0.13557218 lossA 0.915113807 fraction A 0.0375165343\n",
      "step 1157 loss 1.04524052 fisher_loss 0.102710418 triplet loss 0.942530096 l2_loss 12.187706 fraction B 0.177692026 lossA 0.890012383 fraction A 0.0404611453\n",
      "step 1158 loss 1.03251815 fisher_loss 0.101284146 triplet loss 0.931234062 l2_loss 12.1972599 fraction B 0.194089249 lossA 0.867515683 fraction A 0.0441571213\n",
      "step 1159 loss 0.830500662 fisher_loss 0.101264484 triplet loss 0.729236186 l2_loss 12.2067652 fraction B 0.0832282 lossA 0.860226929 fraction A 0.0445449576\n",
      "step 1160 loss 1.04656303 fisher_loss 0.100053184 triplet loss 0.946509898 l2_loss 12.2182217 fraction B 0.241652563 lossA 0.858123243 fraction A 0.0440929271\n",
      "step 1161 loss 1.08082151 fisher_loss 0.0989299268 triplet loss 0.981891632 l2_loss 12.2290478 fraction B 0.121449381 lossA 0.860833943 fraction A 0.0426356532\n",
      "step 1162 loss 1.06003594 fisher_loss 0.0977269188 triplet loss 0.962309 l2_loss 12.2401161 fraction B 0.0583103597 lossA 0.868310928 fraction A 0.0394899212\n",
      "step 1163 loss 1.03027618 fisher_loss 0.0972495899 triplet loss 0.933026552 l2_loss 12.2530794 fraction B 0.15232642 lossA 0.886439085 fraction A 0.0366249382\n",
      "step 1164 loss 1.01293695 fisher_loss 0.0985269696 triplet loss 0.914409935 l2_loss 12.2661247 fraction B 0.0931859389 lossA 0.903674901 fraction A 0.0352983624\n",
      "step 1165 loss 1.0787 fisher_loss 0.102514394 triplet loss 0.97618556 l2_loss 12.2760487 fraction B 0.169531137 lossA 0.92866236 fraction A 0.0343592912\n",
      "step 1166 loss 0.899745 fisher_loss 0.108809136 triplet loss 0.790935874 l2_loss 12.2854013 fraction B 0.134325653 lossA 0.93640852 fraction A 0.0337857679\n",
      "step 1167 loss 1.18094862 fisher_loss 0.109230541 triplet loss 1.0717181 l2_loss 12.2928734 fraction B 0.182093471 lossA 0.937688887 fraction A 0.0330658183\n",
      "step 1168 loss 0.787459493 fisher_loss 0.107460655 triplet loss 0.679998815 l2_loss 12.2992687 fraction B 0.0963032842 lossA 0.924942672 fraction A 0.0327909\n",
      "step 1169 loss 0.744738758 fisher_loss 0.103358887 triplet loss 0.641379893 l2_loss 12.305521 fraction B 0.118194714 lossA 0.916894794 fraction A 0.032568071\n",
      "step 1170 loss 0.796974957 fisher_loss 0.100971296 triplet loss 0.696003675 l2_loss 12.3138094 fraction B 0.101247065 lossA 0.914337158 fraction A 0.0315433964\n",
      "step 1171 loss 0.824992418 fisher_loss 0.100729533 triplet loss 0.724262893 l2_loss 12.323163 fraction B 0.10337545 lossA 0.909562469 fraction A 0.0310623683\n",
      "step 1172 loss 1.11789 fisher_loss 0.103421785 triplet loss 1.01446819 l2_loss 12.3335962 fraction B 0.224018306 lossA 0.895414114 fraction A 0.0315273032\n",
      "step 1173 loss 0.990876436 fisher_loss 0.107241958 triplet loss 0.883634508 l2_loss 12.3442955 fraction B 0.136273012 lossA 0.887949884 fraction A 0.0317569487\n",
      "step 1174 loss 1.37599802 fisher_loss 0.11092373 triplet loss 1.26507425 l2_loss 12.355937 fraction B 0.152458116 lossA 0.877566278 fraction A 0.0325336121\n",
      "step 1175 loss 1.02771497 fisher_loss 0.112703852 triplet loss 0.915011168 l2_loss 12.3659534 fraction B 0.189100608 lossA 0.875630558 fraction A 0.0327209495\n",
      "step 1176 loss 0.959143221 fisher_loss 0.11050202 triplet loss 0.848641217 l2_loss 12.3755751 fraction B 0.175724372 lossA 0.886611521 fraction A 0.0317366384\n",
      "step 1177 loss 1.10143042 fisher_loss 0.104418844 triplet loss 0.997011542 l2_loss 12.3854723 fraction B 0.119009465 lossA 0.904282808 fraction A 0.0305010155\n",
      "step 1178 loss 0.786150753 fisher_loss 0.100920334 triplet loss 0.685230434 l2_loss 12.3969831 fraction B 0.0930241123 lossA 0.912330866 fraction A 0.0300331116\n",
      "step 1179 loss 0.983754158 fisher_loss 0.0990295708 triplet loss 0.884724617 l2_loss 12.4107037 fraction B 0.131255656 lossA 0.905171335 fraction A 0.0306896\n",
      "step 1180 loss 1.09611392 fisher_loss 0.0996754691 triplet loss 0.996438503 l2_loss 12.4257793 fraction B 0.136138707 lossA 0.883416712 fraction A 0.0324586034\n",
      "step 1181 loss 0.721542954 fisher_loss 0.100081049 triplet loss 0.621461928 l2_loss 12.4385529 fraction B 0.0711633 lossA 0.863177061 fraction A 0.0344462506\n",
      "step 1182 loss 1.01422751 fisher_loss 0.100661911 triplet loss 0.913565636 l2_loss 12.4523172 fraction B 0.114667147 lossA 0.848533452 fraction A 0.03616466\n",
      "step 1183 loss 1.02505 fisher_loss 0.100484103 triplet loss 0.924565911 l2_loss 12.4668159 fraction B 0.122056715 lossA 0.84591645 fraction A 0.0365075134\n",
      "step 1184 loss 1.06089485 fisher_loss 0.0999891311 triplet loss 0.960905731 l2_loss 12.4815626 fraction B 0.218956947 lossA 0.840912879 fraction A 0.037268009\n",
      "step 1185 loss 0.87275964 fisher_loss 0.0995869488 triplet loss 0.773172677 l2_loss 12.4944239 fraction B 0.0710654259 lossA 0.825902104 fraction A 0.0398410223\n",
      "step 1186 loss 0.93021822 fisher_loss 0.0992514789 triplet loss 0.830966711 l2_loss 12.5060654 fraction B 0.101143986 lossA 0.819615 fraction A 0.0413815528\n",
      "step 1187 loss 1.00779784 fisher_loss 0.0994177237 triplet loss 0.908380091 l2_loss 12.5176668 fraction B 0.199275628 lossA 0.821106911 fraction A 0.0417504\n",
      "step 1188 loss 0.979305804 fisher_loss 0.100151248 triplet loss 0.879154563 l2_loss 12.5298386 fraction B 0.106314339 lossA 0.828534722 fraction A 0.042075254\n",
      "step 1189 loss 0.948530674 fisher_loss 0.102385439 triplet loss 0.846145213 l2_loss 12.5401878 fraction B 0.130672902 lossA 0.838910043 fraction A 0.0434717797\n",
      "step 1190 loss 0.95393157 fisher_loss 0.105135389 triplet loss 0.848796189 l2_loss 12.5500889 fraction B 0.100222558 lossA 0.862018347 fraction A 0.0427805744\n",
      "step 1191 loss 0.857828379 fisher_loss 0.109204143 triplet loss 0.748624265 l2_loss 12.5606861 fraction B 0.133257732 lossA 0.892033279 fraction A 0.0408783816\n",
      "step 1192 loss 0.837150931 fisher_loss 0.112956189 triplet loss 0.724194765 l2_loss 12.5728731 fraction B 0.115488157 lossA 0.914393604 fraction A 0.0375883542\n",
      "step 1193 loss 1.06549907 fisher_loss 0.112695701 triplet loss 0.952803373 l2_loss 12.5857658 fraction B 0.229352012 lossA 0.922270894 fraction A 0.034711238\n",
      "step 1194 loss 1.01817119 fisher_loss 0.108754285 triplet loss 0.909416854 l2_loss 12.5984125 fraction B 0.173106819 lossA 0.927311718 fraction A 0.032057751\n",
      "step 1195 loss 0.868226886 fisher_loss 0.103970319 triplet loss 0.764256597 l2_loss 12.6107349 fraction B 0.104081482 lossA 0.931079507 fraction A 0.0304867923\n",
      "step 1196 loss 0.922612607 fisher_loss 0.102526918 triplet loss 0.820085704 l2_loss 12.6242352 fraction B 0.136532798 lossA 0.927126 fraction A 0.0300332587\n",
      "step 1197 loss 0.923986077 fisher_loss 0.102819741 triplet loss 0.821166337 l2_loss 12.6390619 fraction B 0.118321858 lossA 0.911203146 fraction A 0.030786898\n",
      "step 1198 loss 0.847105324 fisher_loss 0.105811656 triplet loss 0.741293669 l2_loss 12.6534042 fraction B 0.0987367257 lossA 0.889953375 fraction A 0.0325271599\n",
      "step 1199 loss 1.06845832 fisher_loss 0.110369474 triplet loss 0.958088875 l2_loss 12.6669073 fraction B 0.118715487 lossA 0.874703407 fraction A 0.0345950201\n",
      "step 1200 loss 0.973054945 fisher_loss 0.112736307 triplet loss 0.860318661 l2_loss 12.6784744 fraction B 0.0757113844 lossA 0.866443098 fraction A 0.0358146206\n",
      "step 1201 loss 0.948038578 fisher_loss 0.110307403 triplet loss 0.837731183 l2_loss 12.6910295 fraction B 0.101875454 lossA 0.862199485 fraction A 0.0367164798\n",
      "step 1202 loss 1.11219394 fisher_loss 0.105336413 triplet loss 1.00685751 l2_loss 12.7013168 fraction B 0.155041 lossA 0.865893722 fraction A 0.0363091044\n",
      "step 1203 loss 1.01950276 fisher_loss 0.100397795 triplet loss 0.919104934 l2_loss 12.7111406 fraction B 0.0853199735 lossA 0.873111188 fraction A 0.0351333879\n",
      "step 1204 loss 0.942302942 fisher_loss 0.0964264274 triplet loss 0.845876515 l2_loss 12.7201805 fraction B 0.0935798138 lossA 0.881118715 fraction A 0.0344391391\n",
      "step 1205 loss 1.05418098 fisher_loss 0.0947752297 triplet loss 0.95940572 l2_loss 12.7279634 fraction B 0.170113489 lossA 0.897780418 fraction A 0.0331884846\n",
      "step 1206 loss 1.04061091 fisher_loss 0.0951591507 triplet loss 0.945451796 l2_loss 12.7347012 fraction B 0.18884705 lossA 0.919757068 fraction A 0.031818904\n",
      "step 1207 loss 1.08443534 fisher_loss 0.0987965 triplet loss 0.985638857 l2_loss 12.7404079 fraction B 0.134052187 lossA 0.930422664 fraction A 0.0310763363\n",
      "step 1208 loss 1.03680742 fisher_loss 0.10216891 triplet loss 0.93463856 l2_loss 12.7464762 fraction B 0.115352713 lossA 0.943559468 fraction A 0.0303403307\n",
      "step 1209 loss 1.10275698 fisher_loss 0.105907798 triplet loss 0.996849179 l2_loss 12.753459 fraction B 0.203565642 lossA 0.941294789 fraction A 0.0302319974\n",
      "step 1210 loss 0.732574105 fisher_loss 0.106955059 triplet loss 0.625619054 l2_loss 12.7609863 fraction B 0.107069321 lossA 0.927649915 fraction A 0.0308119748\n",
      "step 1211 loss 1.04564965 fisher_loss 0.104497977 triplet loss 0.941151619 l2_loss 12.7694416 fraction B 0.114306785 lossA 0.905870378 fraction A 0.03179086\n",
      "step 1212 loss 0.831429124 fisher_loss 0.101358861 triplet loss 0.730070233 l2_loss 12.7776794 fraction B 0.138983 lossA 0.891200304 fraction A 0.0330855064\n",
      "step 1213 loss 1.26930642 fisher_loss 0.100045651 triplet loss 1.16926074 l2_loss 12.7872925 fraction B 0.157970756 lossA 0.874415755 fraction A 0.0342203826\n",
      "step 1214 loss 0.987440646 fisher_loss 0.0983481333 triplet loss 0.889092505 l2_loss 12.7960682 fraction B 0.138460144 lossA 0.864707589 fraction A 0.0352449827\n",
      "step 1215 loss 1.06132627 fisher_loss 0.0965885073 triplet loss 0.964737713 l2_loss 12.8055544 fraction B 0.160158604 lossA 0.870509505 fraction A 0.0353132822\n",
      "step 1216 loss 0.804371059 fisher_loss 0.0952980891 triplet loss 0.709072948 l2_loss 12.8176498 fraction B 0.0901493058 lossA 0.878525615 fraction A 0.0357351415\n",
      "step 1217 loss 1.09746587 fisher_loss 0.0942098796 triplet loss 1.00325596 l2_loss 12.830452 fraction B 0.13946566 lossA 0.889591515 fraction A 0.0360353589\n",
      "step 1218 loss 1.11114025 fisher_loss 0.0949229822 triplet loss 1.01621723 l2_loss 12.8431339 fraction B 0.172469497 lossA 0.905218601 fraction A 0.0359785706\n",
      "step 1219 loss 0.885393739 fisher_loss 0.0964850411 triplet loss 0.78890872 l2_loss 12.8551483 fraction B 0.0581985302 lossA 0.943509579 fraction A 0.0343548171\n",
      "step 1220 loss 0.790838718 fisher_loss 0.098735638 triplet loss 0.692103088 l2_loss 12.8706741 fraction B 0.119319826 lossA 0.975111663 fraction A 0.0332751535\n",
      "step 1221 loss 1.21056414 fisher_loss 0.100237109 triplet loss 1.11032701 l2_loss 12.8870945 fraction B 0.199082896 lossA 0.990777194 fraction A 0.0330385789\n",
      "step 1222 loss 0.904969752 fisher_loss 0.101420887 triplet loss 0.803548872 l2_loss 12.9015989 fraction B 0.126471236 lossA 0.993987441 fraction A 0.0329843573\n",
      "step 1223 loss 1.10606742 fisher_loss 0.101651244 triplet loss 1.00441623 l2_loss 12.9161329 fraction B 0.109544307 lossA 0.991307795 fraction A 0.0330450684\n",
      "step 1224 loss 0.891005635 fisher_loss 0.100859202 triplet loss 0.79014641 l2_loss 12.9292755 fraction B 0.12437927 lossA 0.976234138 fraction A 0.0333211608\n",
      "step 1225 loss 0.99678129 fisher_loss 0.0986804 triplet loss 0.898100913 l2_loss 12.9414482 fraction B 0.170177758 lossA 0.944545448 fraction A 0.0341319926\n",
      "step 1226 loss 1.00334466 fisher_loss 0.0957753435 triplet loss 0.907569349 l2_loss 12.9531078 fraction B 0.145614102 lossA 0.917358041 fraction A 0.0353663675\n",
      "step 1227 loss 0.774065256 fisher_loss 0.0937507302 triplet loss 0.680314541 l2_loss 12.9630442 fraction B 0.104966097 lossA 0.897836864 fraction A 0.0373182707\n",
      "step 1228 loss 0.896149099 fisher_loss 0.0929486603 triplet loss 0.803200424 l2_loss 12.9724464 fraction B 0.126812384 lossA 0.879756808 fraction A 0.0403503925\n",
      "step 1229 loss 0.933825314 fisher_loss 0.0938312039 triplet loss 0.839994133 l2_loss 12.9800739 fraction B 0.109249815 lossA 0.86920774 fraction A 0.0438100509\n",
      "step 1230 loss 0.926164567 fisher_loss 0.0966375321 triplet loss 0.829527 l2_loss 12.9884052 fraction B 0.139671057 lossA 0.864679515 fraction A 0.0465719402\n",
      "step 1231 loss 0.96754992 fisher_loss 0.0982764289 triplet loss 0.869273484 l2_loss 12.9961643 fraction B 0.127096072 lossA 0.867775738 fraction A 0.0468166173\n",
      "step 1232 loss 0.937981844 fisher_loss 0.0980497077 triplet loss 0.839932144 l2_loss 13.0044346 fraction B 0.19356519 lossA 0.87577039 fraction A 0.0455281325\n",
      "step 1233 loss 0.998946846 fisher_loss 0.0974752903 triplet loss 0.901471555 l2_loss 13.0127134 fraction B 0.16516155 lossA 0.887439 fraction A 0.0438831896\n",
      "step 1234 loss 0.853267 fisher_loss 0.0970146731 triplet loss 0.756252348 l2_loss 13.0211248 fraction B 0.0900927633 lossA 0.902302 fraction A 0.0420176946\n",
      "step 1235 loss 1.04961658 fisher_loss 0.0970348194 triplet loss 0.952581763 l2_loss 13.0306711 fraction B 0.251730353 lossA 0.925466597 fraction A 0.0397919342\n",
      "step 1236 loss 0.928911269 fisher_loss 0.0988521352 triplet loss 0.830059111 l2_loss 13.0398989 fraction B 0.149595886 lossA 0.959247708 fraction A 0.0375799201\n",
      "step 1237 loss 1.00865579 fisher_loss 0.101241112 triplet loss 0.907414675 l2_loss 13.049984 fraction B 0.115395851 lossA 0.971546113 fraction A 0.0377296805\n",
      "step 1238 loss 1.03266776 fisher_loss 0.101717293 triplet loss 0.930950463 l2_loss 13.0597754 fraction B 0.135247663 lossA 0.974322081 fraction A 0.0384682529\n",
      "step 1239 loss 0.920176446 fisher_loss 0.102095552 triplet loss 0.818080902 l2_loss 13.0700665 fraction B 0.0720856711 lossA 0.959448814 fraction A 0.0405866355\n",
      "step 1240 loss 0.887642205 fisher_loss 0.100548938 triplet loss 0.787093282 l2_loss 13.0801306 fraction B 0.125613704 lossA 0.942639828 fraction A 0.0411568582\n",
      "step 1241 loss 0.945169151 fisher_loss 0.0984444171 triplet loss 0.846724749 l2_loss 13.0939684 fraction B 0.139279023 lossA 0.934832036 fraction A 0.0414429232\n",
      "step 1242 loss 0.900037467 fisher_loss 0.0982270166 triplet loss 0.801810443 l2_loss 13.108263 fraction B 0.0909572169 lossA 0.946999073 fraction A 0.0388399214\n",
      "step 1243 loss 0.936586618 fisher_loss 0.0986247584 triplet loss 0.837961853 l2_loss 13.12535 fraction B 0.107872255 lossA 0.9603 fraction A 0.0374400578\n",
      "step 1244 loss 0.912764 fisher_loss 0.102918275 triplet loss 0.809845746 l2_loss 13.1416407 fraction B 0.103528775 lossA 0.974477 fraction A 0.037132144\n",
      "step 1245 loss 0.844467223 fisher_loss 0.108245656 triplet loss 0.736221552 l2_loss 13.1562185 fraction B 0.0874844715 lossA 0.974101424 fraction A 0.0381509513\n",
      "step 1246 loss 1.09650266 fisher_loss 0.110997751 triplet loss 0.985504925 l2_loss 13.1692753 fraction B 0.125172168 lossA 0.976176262 fraction A 0.0378562696\n",
      "step 1247 loss 0.950778902 fisher_loss 0.109453864 triplet loss 0.841325045 l2_loss 13.1817389 fraction B 0.134061918 lossA 0.976726472 fraction A 0.0379273929\n",
      "step 1248 loss 0.897201717 fisher_loss 0.10714563 triplet loss 0.790056109 l2_loss 13.1947231 fraction B 0.118931517 lossA 0.984995306 fraction A 0.0381073616\n",
      "step 1249 loss 0.934596837 fisher_loss 0.10561569 triplet loss 0.828981161 l2_loss 13.2063589 fraction B 0.176174015 lossA 1.00531948 fraction A 0.0380604379\n",
      "step 1250 loss 1.00645804 fisher_loss 0.106009707 triplet loss 0.900448322 l2_loss 13.2172518 fraction B 0.149863169 lossA 1.02951324 fraction A 0.0382664725\n",
      "step 1251 loss 0.975875 fisher_loss 0.107495904 triplet loss 0.868379116 l2_loss 13.226203 fraction B 0.119798467 lossA 1.04168856 fraction A 0.0388935581\n",
      "step 1252 loss 0.734228432 fisher_loss 0.108975433 triplet loss 0.625253 l2_loss 13.2341108 fraction B 0.115648977 lossA 1.03451693 fraction A 0.0396383628\n",
      "step 1253 loss 0.904034257 fisher_loss 0.108361654 triplet loss 0.795672596 l2_loss 13.2420816 fraction B 0.165265501 lossA 1.00610793 fraction A 0.0402250849\n",
      "step 1254 loss 0.882521331 fisher_loss 0.105710819 triplet loss 0.776810527 l2_loss 13.2501078 fraction B 0.125468835 lossA 0.986094654 fraction A 0.0406463929\n",
      "step 1255 loss 0.766186595 fisher_loss 0.103320979 triplet loss 0.662865639 l2_loss 13.2589636 fraction B 0.102225415 lossA 0.97865814 fraction A 0.0407030322\n",
      "step 1256 loss 1.00327849 fisher_loss 0.102036953 triplet loss 0.901241481 l2_loss 13.2675085 fraction B 0.117850602 lossA 0.978185833 fraction A 0.0398173407\n",
      "step 1257 loss 0.861510694 fisher_loss 0.100856185 triplet loss 0.760654509 l2_loss 13.2761745 fraction B 0.141576618 lossA 0.983413935 fraction A 0.0388303548\n",
      "step 1258 loss 0.86671859 fisher_loss 0.0996855274 triplet loss 0.767033041 l2_loss 13.288949 fraction B 0.146713272 lossA 0.988553524 fraction A 0.0375902951\n",
      "step 1259 loss 0.801805139 fisher_loss 0.100011483 triplet loss 0.701793671 l2_loss 13.300787 fraction B 0.131931439 lossA 1.0008812 fraction A 0.0358408\n",
      "step 1260 loss 0.786609 fisher_loss 0.101896994 triplet loss 0.684712 l2_loss 13.3153381 fraction B 0.100592248 lossA 1.00483477 fraction A 0.0353209823\n",
      "step 1261 loss 0.952820063 fisher_loss 0.103738934 triplet loss 0.849081159 l2_loss 13.3302279 fraction B 0.0923444778 lossA 1.01723051 fraction A 0.0341121964\n",
      "step 1262 loss 0.724623799 fisher_loss 0.105852574 triplet loss 0.618771255 l2_loss 13.3472013 fraction B 0.0927840769 lossA 1.03013289 fraction A 0.0331074633\n",
      "step 1263 loss 0.863256574 fisher_loss 0.107844427 triplet loss 0.755412161 l2_loss 13.3669901 fraction B 0.0718774 lossA 1.03485143 fraction A 0.0326287821\n",
      "step 1264 loss 0.957516253 fisher_loss 0.10817527 triplet loss 0.849341 l2_loss 13.3840494 fraction B 0.129171193 lossA 1.03648663 fraction A 0.0326223671\n",
      "step 1265 loss 1.04666829 fisher_loss 0.106434897 triplet loss 0.94023335 l2_loss 13.398984 fraction B 0.102545589 lossA 1.04888916 fraction A 0.0322025269\n",
      "step 1266 loss 0.76634407 fisher_loss 0.10479027 triplet loss 0.6615538 l2_loss 13.4124603 fraction B 0.0817063674 lossA 1.04307246 fraction A 0.0327488855\n",
      "step 1267 loss 0.932267785 fisher_loss 0.102967091 triplet loss 0.829300702 l2_loss 13.426218 fraction B 0.0535035208 lossA 1.03831542 fraction A 0.0336601287\n",
      "step 1268 loss 1.1064533 fisher_loss 0.101489231 triplet loss 1.00496411 l2_loss 13.4382372 fraction B 0.102548189 lossA 1.03578556 fraction A 0.0344955586\n",
      "step 1269 loss 1.0206852 fisher_loss 0.101306707 triplet loss 0.919378459 l2_loss 13.4491358 fraction B 0.115446091 lossA 1.03575277 fraction A 0.035060212\n",
      "step 1270 loss 0.998890758 fisher_loss 0.102357544 triplet loss 0.896533191 l2_loss 13.4590044 fraction B 0.172203213 lossA 1.030532 fraction A 0.0359788612\n",
      "step 1271 loss 1.12891078 fisher_loss 0.10475155 triplet loss 1.02415919 l2_loss 13.4690456 fraction B 0.265153974 lossA 1.02591527 fraction A 0.0367489643\n",
      "step 1272 loss 0.97007525 fisher_loss 0.107210845 triplet loss 0.862864435 l2_loss 13.478323 fraction B 0.122038767 lossA 1.01623082 fraction A 0.0382394902\n",
      "step 1273 loss 1.03093708 fisher_loss 0.110366695 triplet loss 0.920570433 l2_loss 13.4863482 fraction B 0.116604038 lossA 1.00250626 fraction A 0.0399415828\n",
      "step 1274 loss 0.835003614 fisher_loss 0.112662286 triplet loss 0.722341299 l2_loss 13.4934978 fraction B 0.102777779 lossA 1.00419807 fraction A 0.0397941\n",
      "step 1275 loss 0.967532158 fisher_loss 0.112545222 triplet loss 0.854986966 l2_loss 13.5044069 fraction B 0.166930407 lossA 1.00237381 fraction A 0.0392083265\n",
      "step 1276 loss 1.02120852 fisher_loss 0.109460428 triplet loss 0.911748052 l2_loss 13.5156603 fraction B 0.0970951 lossA 1.00419581 fraction A 0.0377513841\n",
      "step 1277 loss 0.839749217 fisher_loss 0.105324209 triplet loss 0.734425 l2_loss 13.527894 fraction B 0.0805931911 lossA 1.00955307 fraction A 0.035943266\n",
      "step 1278 loss 1.08468091 fisher_loss 0.103092425 triplet loss 0.981588542 l2_loss 13.5418816 fraction B 0.154547751 lossA 1.02518332 fraction A 0.0340346955\n",
      "step 1279 loss 0.763748407 fisher_loss 0.103431493 triplet loss 0.660316944 l2_loss 13.5534811 fraction B 0.0957806557 lossA 1.04521763 fraction A 0.032377068\n",
      "step 1280 loss 0.864082 fisher_loss 0.104352601 triplet loss 0.759729385 l2_loss 13.5691643 fraction B 0.150108218 lossA 1.05319417 fraction A 0.0311254989\n",
      "step 1281 loss 1.10864067 fisher_loss 0.104887158 triplet loss 1.00375354 l2_loss 13.5831385 fraction B 0.168389589 lossA 1.04181528 fraction A 0.0305443853\n",
      "step 1282 loss 1.02452898 fisher_loss 0.105543025 triplet loss 0.918985963 l2_loss 13.5961 fraction B 0.094454512 lossA 1.02251303 fraction A 0.0304523669\n",
      "step 1283 loss 0.682885766 fisher_loss 0.10697981 triplet loss 0.575906 l2_loss 13.6079645 fraction B 0.076080583 lossA 1.00553823 fraction A 0.0309953522\n",
      "step 1284 loss 1.06639302 fisher_loss 0.108873725 triplet loss 0.957519293 l2_loss 13.620697 fraction B 0.156283766 lossA 0.987441897 fraction A 0.0319956839\n",
      "step 1285 loss 0.925786138 fisher_loss 0.108834833 triplet loss 0.816951334 l2_loss 13.6325054 fraction B 0.0374028832 lossA 0.97028774 fraction A 0.0332577378\n",
      "step 1286 loss 0.742657 fisher_loss 0.10772185 triplet loss 0.634935141 l2_loss 13.6462812 fraction B 0.103678927 lossA 0.960815489 fraction A 0.0342412777\n",
      "step 1287 loss 0.874892831 fisher_loss 0.106335454 triplet loss 0.76855737 l2_loss 13.6611118 fraction B 0.0788827837 lossA 0.957894802 fraction A 0.0344472788\n",
      "step 1288 loss 1.1239053 fisher_loss 0.103823408 triplet loss 1.02008188 l2_loss 13.6740055 fraction B 0.137803555 lossA 0.954431117 fraction A 0.0347796455\n",
      "step 1289 loss 0.986691535 fisher_loss 0.10232003 triplet loss 0.884371519 l2_loss 13.6862726 fraction B 0.0781542212 lossA 0.965252459 fraction A 0.0339485779\n",
      "step 1290 loss 0.78260386 fisher_loss 0.101580285 triplet loss 0.681023598 l2_loss 13.6989965 fraction B 0.0546431281 lossA 0.98771596 fraction A 0.0326558\n",
      "step 1291 loss 0.84457159 fisher_loss 0.102591619 triplet loss 0.741979957 l2_loss 13.7125778 fraction B 0.0796217844 lossA 1.01772141 fraction A 0.0311774854\n",
      "step 1292 loss 1.06305337 fisher_loss 0.105693854 triplet loss 0.957359493 l2_loss 13.7265959 fraction B 0.131368116 lossA 1.03810883 fraction A 0.0308346674\n",
      "step 1293 loss 0.886969268 fisher_loss 0.109402381 triplet loss 0.77756691 l2_loss 13.7379189 fraction B 0.118394732 lossA 1.03295 fraction A 0.031840682\n",
      "step 1294 loss 1.01555538 fisher_loss 0.10972403 triplet loss 0.905831397 l2_loss 13.7494783 fraction B 0.109706484 lossA 0.995769799 fraction A 0.0349555463\n",
      "step 1295 loss 1.04604793 fisher_loss 0.108660311 triplet loss 0.937387645 l2_loss 13.7603645 fraction B 0.0895377547 lossA 0.974815607 fraction A 0.0376294516\n",
      "step 1296 loss 0.930034816 fisher_loss 0.108872138 triplet loss 0.821162701 l2_loss 13.7692461 fraction B 0.0943546891 lossA 0.955938876 fraction A 0.0409073457\n",
      "step 1297 loss 1.06615019 fisher_loss 0.109200582 triplet loss 0.956949651 l2_loss 13.7802486 fraction B 0.170918182 lossA 0.946699739 fraction A 0.0438983664\n",
      "step 1298 loss 0.914386094 fisher_loss 0.109156668 triplet loss 0.805229425 l2_loss 13.7924061 fraction B 0.137000859 lossA 0.944592237 fraction A 0.0460586511\n",
      "step 1299 loss 1.01833439 fisher_loss 0.10968636 triplet loss 0.908648074 l2_loss 13.8034859 fraction B 0.121678174 lossA 0.951732278 fraction A 0.0452579744\n",
      "step 1300 loss 0.826302707 fisher_loss 0.110018797 triplet loss 0.716283917 l2_loss 13.8162184 fraction B 0.123791903 lossA 0.950307965 fraction A 0.0444952808\n",
      "step 1301 loss 0.968072772 fisher_loss 0.109513909 triplet loss 0.858558893 l2_loss 13.8318377 fraction B 0.125690207 lossA 0.944847643 fraction A 0.0435155146\n",
      "step 1302 loss 0.909534097 fisher_loss 0.110075653 triplet loss 0.799458444 l2_loss 13.8485842 fraction B 0.113825552 lossA 0.942585647 fraction A 0.0418828204\n",
      "step 1303 loss 0.882698953 fisher_loss 0.109337263 triplet loss 0.773361683 l2_loss 13.8666792 fraction B 0.112383142 lossA 0.93857795 fraction A 0.0413960703\n",
      "step 1304 loss 1.03469086 fisher_loss 0.110127106 triplet loss 0.924563706 l2_loss 13.8850689 fraction B 0.122050159 lossA 0.945800304 fraction A 0.0397469886\n",
      "step 1305 loss 0.827199399 fisher_loss 0.110976234 triplet loss 0.71622318 l2_loss 13.9049702 fraction B 0.094384037 lossA 0.95900619 fraction A 0.039047312\n",
      "step 1306 loss 0.943041623 fisher_loss 0.113059156 triplet loss 0.82998246 l2_loss 13.9250441 fraction B 0.103318587 lossA 0.965031564 fraction A 0.0387424789\n",
      "step 1307 loss 1.05893791 fisher_loss 0.115758762 triplet loss 0.94317919 l2_loss 13.9436245 fraction B 0.0876338333 lossA 0.961754441 fraction A 0.0391206\n",
      "step 1308 loss 1.12117207 fisher_loss 0.117379181 triplet loss 1.00379288 l2_loss 13.9585733 fraction B 0.0998179168 lossA 0.971210539 fraction A 0.0395691469\n",
      "step 1309 loss 1.02399731 fisher_loss 0.119388521 triplet loss 0.904608727 l2_loss 13.9700098 fraction B 0.123325512 lossA 0.981529355 fraction A 0.0394794345\n",
      "step 1310 loss 0.912688613 fisher_loss 0.118888438 triplet loss 0.793800175 l2_loss 13.9819012 fraction B 0.100525551 lossA 0.992420793 fraction A 0.0381293595\n",
      "step 1311 loss 1.1040051 fisher_loss 0.114520669 triplet loss 0.98948437 l2_loss 13.9938021 fraction B 0.0856116414 lossA 1.0115453 fraction A 0.0363150425\n",
      "step 1312 loss 1.16172624 fisher_loss 0.113341026 triplet loss 1.04838526 l2_loss 14.005909 fraction B 0.190075651 lossA 1.02504694 fraction A 0.0352202728\n",
      "step 1313 loss 1.39489043 fisher_loss 0.115103953 triplet loss 1.27978647 l2_loss 14.017705 fraction B 0.143181 lossA 1.02293181 fraction A 0.0347887\n",
      "step 1314 loss 1.09961104 fisher_loss 0.117308751 triplet loss 0.982302248 l2_loss 14.0263863 fraction B 0.123289905 lossA 1.00374341 fraction A 0.0350140184\n",
      "step 1315 loss 1.14100885 fisher_loss 0.11687807 triplet loss 1.02413082 l2_loss 14.0355263 fraction B 0.209973708 lossA 0.98707372 fraction A 0.0359284543\n",
      "step 1316 loss 1.018978 fisher_loss 0.11649289 triplet loss 0.902485132 l2_loss 14.0439796 fraction B 0.111991942 lossA 0.966286719 fraction A 0.0373778455\n",
      "step 1317 loss 1.1955415 fisher_loss 0.1148654 triplet loss 1.08067608 l2_loss 14.0515032 fraction B 0.119725965 lossA 0.947411299 fraction A 0.0391658023\n",
      "step 1318 loss 1.10315382 fisher_loss 0.113660417 triplet loss 0.98949337 l2_loss 14.0571775 fraction B 0.146092623 lossA 0.93393451 fraction A 0.0403547175\n",
      "step 1319 loss 0.958168149 fisher_loss 0.112361029 triplet loss 0.845807135 l2_loss 14.063693 fraction B 0.141060442 lossA 0.924777091 fraction A 0.0408870727\n",
      "step 1320 loss 0.993847728 fisher_loss 0.109518901 triplet loss 0.884328842 l2_loss 14.0719976 fraction B 0.105342127 lossA 0.916807175 fraction A 0.0414129347\n",
      "step 1321 loss 1.02082705 fisher_loss 0.10652189 triplet loss 0.91430521 l2_loss 14.0821714 fraction B 0.0743311 lossA 0.911866724 fraction A 0.0413228609\n",
      "step 1322 loss 0.919205904 fisher_loss 0.103815123 triplet loss 0.815390766 l2_loss 14.094265 fraction B 0.117436826 lossA 0.907208741 fraction A 0.0411357805\n",
      "step 1323 loss 0.904050708 fisher_loss 0.103551023 triplet loss 0.800499678 l2_loss 14.1082878 fraction B 0.0855610147 lossA 0.914303541 fraction A 0.0394704193\n",
      "step 1324 loss 0.971061945 fisher_loss 0.104528181 triplet loss 0.866533756 l2_loss 14.1229706 fraction B 0.0777365491 lossA 0.91742444 fraction A 0.0385935232\n",
      "step 1325 loss 0.818498135 fisher_loss 0.106137551 triplet loss 0.712360561 l2_loss 14.1382532 fraction B 0.111087114 lossA 0.930927932 fraction A 0.037274424\n",
      "step 1326 loss 0.863067 fisher_loss 0.108925454 triplet loss 0.75414151 l2_loss 14.1527262 fraction B 0.179226473 lossA 0.940001607 fraction A 0.03744369\n",
      "step 1327 loss 0.710392475 fisher_loss 0.111907773 triplet loss 0.598484695 l2_loss 14.1668949 fraction B 0.11285992 lossA 0.938436151 fraction A 0.0373513773\n",
      "step 1328 loss 1.12875676 fisher_loss 0.109674588 triplet loss 1.01908219 l2_loss 14.1804895 fraction B 0.147850037 lossA 0.936000228 fraction A 0.0372982547\n",
      "step 1329 loss 0.677422047 fisher_loss 0.107370161 triplet loss 0.570051908 l2_loss 14.1920977 fraction B 0.0982484147 lossA 0.923415184 fraction A 0.0387943164\n",
      "step 1330 loss 0.966849267 fisher_loss 0.104937926 triplet loss 0.861911356 l2_loss 14.2041664 fraction B 0.108833551 lossA 0.925531447 fraction A 0.0390212834\n",
      "step 1331 loss 0.99708569 fisher_loss 0.105932392 triplet loss 0.891153276 l2_loss 14.2157249 fraction B 0.124837659 lossA 0.924556494 fraction A 0.0400062911\n",
      "step 1332 loss 1.17696667 fisher_loss 0.107791498 triplet loss 1.06917512 l2_loss 14.2261143 fraction B 0.127762899 lossA 0.926545441 fraction A 0.0402100906\n",
      "step 1333 loss 0.92449218 fisher_loss 0.108067572 triplet loss 0.816424608 l2_loss 14.2354612 fraction B 0.121877246 lossA 0.938563824 fraction A 0.038881164\n",
      "step 1334 loss 1.06967938 fisher_loss 0.107329167 triplet loss 0.96235019 l2_loss 14.2458591 fraction B 0.0757651255 lossA 0.962131262 fraction A 0.0365792587\n",
      "step 1335 loss 0.920968175 fisher_loss 0.107115321 triplet loss 0.813852847 l2_loss 14.2573061 fraction B 0.156953499 lossA 0.997487783 fraction A 0.0339689963\n",
      "step 1336 loss 1.09151244 fisher_loss 0.108537108 triplet loss 0.982975364 l2_loss 14.2665205 fraction B 0.141215608 lossA 1.04103649 fraction A 0.0317197368\n",
      "step 1337 loss 0.965950429 fisher_loss 0.111026 triplet loss 0.85492444 l2_loss 14.2753382 fraction B 0.109814279 lossA 1.06051385 fraction A 0.0308739319\n",
      "step 1338 loss 1.12372339 fisher_loss 0.111922957 triplet loss 1.01180041 l2_loss 14.2847395 fraction B 0.135474861 lossA 1.04267299 fraction A 0.0313437805\n",
      "step 1339 loss 1.05105555 fisher_loss 0.108496182 triplet loss 0.942559421 l2_loss 14.2933331 fraction B 0.190242857 lossA 0.99450469 fraction A 0.0329696573\n",
      "step 1340 loss 0.970715463 fisher_loss 0.104772739 triplet loss 0.865942717 l2_loss 14.3024826 fraction B 0.139299631 lossA 0.949751616 fraction A 0.0356231779\n",
      "step 1341 loss 0.772176385 fisher_loss 0.103354104 triplet loss 0.668822289 l2_loss 14.3129387 fraction B 0.0826640353 lossA 0.914554894 fraction A 0.0390588604\n",
      "step 1342 loss 0.832865 fisher_loss 0.104219198 triplet loss 0.728645802 l2_loss 14.324688 fraction B 0.105263159 lossA 0.895999908 fraction A 0.0421625413\n",
      "step 1343 loss 1.27136302 fisher_loss 0.107237548 triplet loss 1.16412544 l2_loss 14.3373013 fraction B 0.163835168 lossA 0.893972576 fraction A 0.042795714\n",
      "step 1344 loss 1.05344975 fisher_loss 0.108722016 triplet loss 0.944727719 l2_loss 14.3512726 fraction B 0.148468152 lossA 0.898365498 fraction A 0.041531682\n",
      "step 1345 loss 0.913212299 fisher_loss 0.107664198 triplet loss 0.805548072 l2_loss 14.3640747 fraction B 0.0959721506 lossA 0.89939177 fraction A 0.0408053175\n",
      "step 1346 loss 1.06151879 fisher_loss 0.106589146 triplet loss 0.95492959 l2_loss 14.3786221 fraction B 0.149539098 lossA 0.907478809 fraction A 0.0386047773\n",
      "step 1347 loss 0.983813345 fisher_loss 0.10567347 triplet loss 0.878139853 l2_loss 14.3925562 fraction B 0.172630817 lossA 0.915332198 fraction A 0.0366628468\n",
      "step 1348 loss 0.970055103 fisher_loss 0.105943203 triplet loss 0.8641119 l2_loss 14.4069147 fraction B 0.107328989 lossA 0.926795125 fraction A 0.0342284478\n",
      "step 1349 loss 0.915371537 fisher_loss 0.105729952 triplet loss 0.8096416 l2_loss 14.4219961 fraction B 0.0774671659 lossA 0.944149494 fraction A 0.0323818326\n",
      "step 1350 loss 0.873850405 fisher_loss 0.105539896 triplet loss 0.768310487 l2_loss 14.4387236 fraction B 0.107400462 lossA 0.965444803 fraction A 0.0311631877\n",
      "step 1351 loss 0.974035144 fisher_loss 0.106477052 triplet loss 0.867558122 l2_loss 14.4552517 fraction B 0.0853198767 lossA 0.984271288 fraction A 0.0302023757\n",
      "step 1352 loss 0.87782377 fisher_loss 0.107560441 triplet loss 0.770263314 l2_loss 14.4731436 fraction B 0.140987322 lossA 0.991039336 fraction A 0.0301698949\n",
      "step 1353 loss 0.923353195 fisher_loss 0.107385226 triplet loss 0.815968 l2_loss 14.4866791 fraction B 0.129545122 lossA 0.988707066 fraction A 0.0303654801\n",
      "step 1354 loss 1.1167475 fisher_loss 0.106601864 triplet loss 1.01014566 l2_loss 14.5015659 fraction B 0.114056811 lossA 0.989572 fraction A 0.0308473893\n",
      "step 1355 loss 0.879905164 fisher_loss 0.10669557 triplet loss 0.773209572 l2_loss 14.5149765 fraction B 0.0947341919 lossA 1.00171494 fraction A 0.0306609683\n",
      "step 1356 loss 0.918978393 fisher_loss 0.107486561 triplet loss 0.811491847 l2_loss 14.5269136 fraction B 0.0574409664 lossA 1.02133238 fraction A 0.0297923591\n",
      "step 1357 loss 1.00174546 fisher_loss 0.107480913 triplet loss 0.894264579 l2_loss 14.5408688 fraction B 0.0972503647 lossA 1.0216254 fraction A 0.0297376253\n",
      "step 1358 loss 0.806635082 fisher_loss 0.10646864 triplet loss 0.700166464 l2_loss 14.5528336 fraction B 0.103222176 lossA 1.01964915 fraction A 0.0296215937\n",
      "step 1359 loss 0.949665546 fisher_loss 0.105454579 triplet loss 0.844211 l2_loss 14.5629435 fraction B 0.126804233 lossA 1.01525688 fraction A 0.0300079621\n",
      "step 1360 loss 1.00083864 fisher_loss 0.105720475 triplet loss 0.895118177 l2_loss 14.5724268 fraction B 0.0531600602 lossA 1.01818585 fraction A 0.0300645679\n",
      "step 1361 loss 0.933361351 fisher_loss 0.10731703 triplet loss 0.826044321 l2_loss 14.5834017 fraction B 0.0966415107 lossA 1.0178405 fraction A 0.0303056501\n",
      "step 1362 loss 0.985898077 fisher_loss 0.107545391 triplet loss 0.878352702 l2_loss 14.5943813 fraction B 0.132371068 lossA 1.01430047 fraction A 0.0312614031\n",
      "step 1363 loss 0.984456837 fisher_loss 0.107717142 triplet loss 0.876739681 l2_loss 14.6052885 fraction B 0.118696719 lossA 0.995717883 fraction A 0.032832142\n",
      "step 1364 loss 0.860536695 fisher_loss 0.105958857 triplet loss 0.754577816 l2_loss 14.6161413 fraction B 0.11409045 lossA 0.984804809 fraction A 0.0341845639\n",
      "step 1365 loss 0.991266549 fisher_loss 0.10506127 triplet loss 0.886205256 l2_loss 14.6249723 fraction B 0.117545061 lossA 0.97483778 fraction A 0.0359788612\n",
      "step 1366 loss 0.89019841 fisher_loss 0.105390184 triplet loss 0.784808218 l2_loss 14.6321754 fraction B 0.101653218 lossA 0.969994247 fraction A 0.0365412422\n",
      "step 1367 loss 0.932803 fisher_loss 0.104307614 triplet loss 0.828495383 l2_loss 14.644824 fraction B 0.158615723 lossA 0.973608434 fraction A 0.0362501554\n",
      "step 1368 loss 0.963687897 fisher_loss 0.103892162 triplet loss 0.859795749 l2_loss 14.6560421 fraction B 0.14229399 lossA 0.976278 fraction A 0.0359021313\n",
      "step 1369 loss 0.766106188 fisher_loss 0.104066476 triplet loss 0.662039697 l2_loss 14.6674919 fraction B 0.0575319827 lossA 0.991391301 fraction A 0.0348418243\n",
      "step 1370 loss 1.00593483 fisher_loss 0.1046464 triplet loss 0.90128839 l2_loss 14.6804514 fraction B 0.103252299 lossA 1.01200926 fraction A 0.0337609835\n",
      "step 1371 loss 0.803832531 fisher_loss 0.105609015 triplet loss 0.698223531 l2_loss 14.6927776 fraction B 0.0684226602 lossA 1.02738881 fraction A 0.0337950066\n",
      "step 1372 loss 0.983491659 fisher_loss 0.107442833 triplet loss 0.876048803 l2_loss 14.7041607 fraction B 0.162974969 lossA 1.04845667 fraction A 0.0332740881\n",
      "step 1373 loss 0.97528404 fisher_loss 0.108610198 triplet loss 0.866673827 l2_loss 14.7148151 fraction B 0.0888186544 lossA 1.05390143 fraction A 0.0336769186\n",
      "step 1374 loss 0.812364876 fisher_loss 0.108761266 triplet loss 0.703603625 l2_loss 14.7255287 fraction B 0.0754303336 lossA 1.04397094 fraction A 0.0342156887\n",
      "step 1375 loss 0.996171 fisher_loss 0.107369095 triplet loss 0.888801873 l2_loss 14.7374296 fraction B 0.10114228 lossA 1.03778732 fraction A 0.0337909348\n",
      "step 1376 loss 1.0784986 fisher_loss 0.106077328 triplet loss 0.972421229 l2_loss 14.7490101 fraction B 0.151735827 lossA 1.02852988 fraction A 0.0330551863\n",
      "step 1377 loss 0.726971805 fisher_loss 0.104517825 triplet loss 0.622454 l2_loss 14.7608662 fraction B 0.061751619 lossA 1.01384485 fraction A 0.032970611\n",
      "step 1378 loss 1.08553267 fisher_loss 0.104306638 triplet loss 0.981226087 l2_loss 14.7740059 fraction B 0.135225013 lossA 0.999788105 fraction A 0.0337725319\n",
      "step 1379 loss 1.1071763 fisher_loss 0.104453206 triplet loss 1.0027231 l2_loss 14.7848396 fraction B 0.090560995 lossA 0.989149153 fraction A 0.0343592912\n",
      "step 1380 loss 0.942269087 fisher_loss 0.105194479 triplet loss 0.837074637 l2_loss 14.7954969 fraction B 0.139604568 lossA 0.980890393 fraction A 0.0347058475\n",
      "step 1381 loss 0.94835639 fisher_loss 0.106192276 triplet loss 0.842164099 l2_loss 14.8061361 fraction B 0.117994204 lossA 0.994401038 fraction A 0.0336365178\n",
      "step 1382 loss 1.00672007 fisher_loss 0.105767608 triplet loss 0.900952518 l2_loss 14.8189011 fraction B 0.164574713 lossA 1.0001384 fraction A 0.0334677696\n",
      "step 1383 loss 0.965862691 fisher_loss 0.105029583 triplet loss 0.860833108 l2_loss 14.8303576 fraction B 0.0963765457 lossA 1.00504553 fraction A 0.0334117897\n",
      "step 1384 loss 0.960760772 fisher_loss 0.104552343 triplet loss 0.856208444 l2_loss 14.841033 fraction B 0.136197805 lossA 1.01355147 fraction A 0.0333949588\n",
      "step 1385 loss 1.03311694 fisher_loss 0.104280308 triplet loss 0.928836644 l2_loss 14.8512726 fraction B 0.132532954 lossA 1.01585639 fraction A 0.0337096937\n",
      "step 1386 loss 0.996305585 fisher_loss 0.104256526 triplet loss 0.892049074 l2_loss 14.8607225 fraction B 0.0855681 lossA 1.04189014 fraction A 0.0328975059\n",
      "step 1387 loss 1.00544822 fisher_loss 0.105397083 triplet loss 0.900051177 l2_loss 14.8708601 fraction B 0.151579633 lossA 1.0623306 fraction A 0.0319423787\n",
      "step 1388 loss 0.787409663 fisher_loss 0.105235621 triplet loss 0.682174 l2_loss 14.8844452 fraction B 0.0808767825 lossA 1.06156027 fraction A 0.0313913263\n",
      "step 1389 loss 1.03459716 fisher_loss 0.103640966 triplet loss 0.930956185 l2_loss 14.8977222 fraction B 0.116555147 lossA 1.05073404 fraction A 0.0312023778\n",
      "step 1390 loss 1.28296888 fisher_loss 0.10332375 triplet loss 1.17964518 l2_loss 14.9111042 fraction B 0.138744116 lossA 1.03859782 fraction A 0.0310654491\n",
      "step 1391 loss 0.963977873 fisher_loss 0.104470737 triplet loss 0.859507143 l2_loss 14.9234381 fraction B 0.136415124 lossA 0.987329245 fraction A 0.0327069797\n",
      "step 1392 loss 0.914937794 fisher_loss 0.105775774 triplet loss 0.809162 l2_loss 14.9343853 fraction B 0.136863872 lossA 0.950639486 fraction A 0.0346107855\n",
      "step 1393 loss 0.926833272 fisher_loss 0.106249325 triplet loss 0.82058394 l2_loss 14.9432812 fraction B 0.0969852954 lossA 0.91974771 fraction A 0.0379617438\n",
      "step 1394 loss 1.0086242 fisher_loss 0.108589277 triplet loss 0.900034904 l2_loss 14.9539461 fraction B 0.0939142779 lossA 0.907706678 fraction A 0.0408953577\n",
      "step 1395 loss 0.885707498 fisher_loss 0.110168122 triplet loss 0.775539398 l2_loss 14.9635019 fraction B 0.129955307 lossA 0.910105824 fraction A 0.041849643\n",
      "step 1396 loss 1.06941068 fisher_loss 0.111193232 triplet loss 0.958217502 l2_loss 14.9722414 fraction B 0.132393256 lossA 0.919477522 fraction A 0.0402812846\n",
      "step 1397 loss 0.894792914 fisher_loss 0.110998258 triplet loss 0.783794641 l2_loss 14.981782 fraction B 0.086340256 lossA 0.934099317 fraction A 0.0370314717\n",
      "step 1398 loss 0.957629144 fisher_loss 0.111395493 triplet loss 0.846233666 l2_loss 14.9908676 fraction B 0.0563743562 lossA 0.964562356 fraction A 0.0338168181\n",
      "step 1399 loss 0.827947199 fisher_loss 0.115824856 triplet loss 0.712122321 l2_loss 15.0007067 fraction B 0.137984917 lossA 1.01661587 fraction A 0.0318896957\n",
      "step 1400 loss 0.995543778 fisher_loss 0.12046881 triplet loss 0.875075 l2_loss 15.0110054 fraction B 0.18570143 lossA 1.06384385 fraction A 0.0318489671\n",
      "step 1401 loss 0.985784233 fisher_loss 0.124922514 triplet loss 0.860861719 l2_loss 15.0201702 fraction B 0.144088313 lossA 1.1027478 fraction A 0.0322684795\n",
      "step 1402 loss 0.860558212 fisher_loss 0.125757024 triplet loss 0.734801173 l2_loss 15.0293522 fraction B 0.2289913 lossA 1.12363374 fraction A 0.0311321355\n",
      "step 1403 loss 0.778431237 fisher_loss 0.120931923 triplet loss 0.657499313 l2_loss 15.034996 fraction B 0.140783533 lossA 1.10648012 fraction A 0.031802956\n",
      "step 1404 loss 1.01195693 fisher_loss 0.120771237 triplet loss 0.891185701 l2_loss 15.0407286 fraction B 0.195764914 lossA 1.06022418 fraction A 0.0337056257\n",
      "step 1405 loss 0.845125 fisher_loss 0.124198198 triplet loss 0.720926821 l2_loss 15.0459099 fraction B 0.0856195241 lossA 1.03117681 fraction A 0.03563172\n",
      "step 1406 loss 0.943702698 fisher_loss 0.126478672 triplet loss 0.817224 l2_loss 15.0537319 fraction B 0.160369545 lossA 1.01151967 fraction A 0.0362704657\n",
      "step 1407 loss 1.10077369 fisher_loss 0.12574622 triplet loss 0.975027502 l2_loss 15.061882 fraction B 0.168623701 lossA 0.990520954 fraction A 0.0351975448\n",
      "step 1408 loss 1.03222334 fisher_loss 0.120051287 triplet loss 0.912172 l2_loss 15.0720234 fraction B 0.159809038 lossA 0.977347672 fraction A 0.033410836\n",
      "step 1409 loss 1.23588562 fisher_loss 0.114930257 triplet loss 1.12095535 l2_loss 15.0826387 fraction B 0.190415308 lossA 0.974213362 fraction A 0.0319148116\n",
      "step 1410 loss 0.786366165 fisher_loss 0.113552526 triplet loss 0.672813654 l2_loss 15.0934496 fraction B 0.0860215053 lossA 0.987483144 fraction A 0.0299120937\n",
      "step 1411 loss 0.976161897 fisher_loss 0.114837401 triplet loss 0.861324489 l2_loss 15.1063595 fraction B 0.160726547 lossA 1.00643218 fraction A 0.0282663461\n",
      "step 1412 loss 0.755197763 fisher_loss 0.116390005 triplet loss 0.638807774 l2_loss 15.1203432 fraction B 0.119043298 lossA 1.00580227 fraction A 0.0278965831\n",
      "step 1413 loss 0.897144437 fisher_loss 0.116118751 triplet loss 0.781025708 l2_loss 15.1354752 fraction B 0.0778207928 lossA 0.996260524 fraction A 0.0281730443\n",
      "step 1414 loss 1.09276867 fisher_loss 0.113862731 triplet loss 0.978906 l2_loss 15.1505852 fraction B 0.117481507 lossA 0.993207037 fraction A 0.0280960202\n",
      "step 1415 loss 0.741306841 fisher_loss 0.111792699 triplet loss 0.629514158 l2_loss 15.1681099 fraction B 0.0925394818 lossA 0.99236244 fraction A 0.0281613134\n",
      "step 1416 loss 1.01429009 fisher_loss 0.108749487 triplet loss 0.905540586 l2_loss 15.1857948 fraction B 0.140385643 lossA 1.00251913 fraction A 0.0281585269\n",
      "step 1417 loss 0.824067116 fisher_loss 0.10907343 triplet loss 0.714993656 l2_loss 15.2024 fraction B 0.0787055939 lossA 1.01317918 fraction A 0.0283501539\n",
      "step 1418 loss 1.28245604 fisher_loss 0.110788256 triplet loss 1.17166781 l2_loss 15.2209015 fraction B 0.0606308579 lossA 1.02101779 fraction A 0.0286320038\n",
      "step 1419 loss 1.12652397 fisher_loss 0.112078287 triplet loss 1.01444566 l2_loss 15.2376347 fraction B 0.202139542 lossA 1.02874696 fraction A 0.0288225301\n",
      "step 1420 loss 0.923542202 fisher_loss 0.112675749 triplet loss 0.810866475 l2_loss 15.2528076 fraction B 0.105934344 lossA 1.03909707 fraction A 0.029713355\n",
      "step 1421 loss 0.847041786 fisher_loss 0.111856058 triplet loss 0.735185742 l2_loss 15.2677841 fraction B 0.0932607353 lossA 1.04152107 fraction A 0.0300214179\n",
      "step 1422 loss 1.04897785 fisher_loss 0.1112426 triplet loss 0.9377352 l2_loss 15.283514 fraction B 0.148379728 lossA 1.04091787 fraction A 0.0301351026\n",
      "step 1423 loss 0.966556907 fisher_loss 0.11081636 triplet loss 0.855740547 l2_loss 15.2980995 fraction B 0.136558399 lossA 1.03324747 fraction A 0.0303744264\n",
      "step 1424 loss 0.945477128 fisher_loss 0.11023403 triplet loss 0.835243106 l2_loss 15.3120775 fraction B 0.162713513 lossA 1.02240634 fraction A 0.030870853\n",
      "step 1425 loss 0.91977644 fisher_loss 0.109584935 triplet loss 0.810191512 l2_loss 15.3233757 fraction B 0.096328117 lossA 1.01548338 fraction A 0.0314612053\n",
      "step 1426 loss 1.05837715 fisher_loss 0.109297112 triplet loss 0.94908 l2_loss 15.3336296 fraction B 0.118164837 lossA 1.02500653 fraction A 0.0308845267\n",
      "step 1427 loss 0.835149527 fisher_loss 0.109894872 triplet loss 0.725254655 l2_loss 15.3442945 fraction B 0.103868298 lossA 1.0347333 fraction A 0.0302368738\n",
      "step 1428 loss 0.892481208 fisher_loss 0.111244261 triplet loss 0.781236947 l2_loss 15.3545532 fraction B 0.0835298449 lossA 1.04177 fraction A 0.0300691128\n",
      "step 1429 loss 1.17723954 fisher_loss 0.112938769 triplet loss 1.06430078 l2_loss 15.3662167 fraction B 0.1713925 lossA 1.03539932 fraction A 0.0305633396\n",
      "step 1430 loss 0.866213381 fisher_loss 0.112938516 triplet loss 0.753274858 l2_loss 15.3764009 fraction B 0.0855434611 lossA 1.03038561 fraction A 0.0310630649\n",
      "step 1431 loss 0.920149207 fisher_loss 0.113028571 triplet loss 0.807120621 l2_loss 15.385375 fraction B 0.119921036 lossA 1.02182829 fraction A 0.0315100364\n",
      "step 1432 loss 0.890479326 fisher_loss 0.111816496 triplet loss 0.77866286 l2_loss 15.3942099 fraction B 0.134056345 lossA 0.994566679 fraction A 0.0334376693\n",
      "step 1433 loss 1.09670007 fisher_loss 0.109461516 triplet loss 0.987238586 l2_loss 15.4049273 fraction B 0.0914503559 lossA 0.974779904 fraction A 0.0353044122\n",
      "step 1434 loss 0.87629509 fisher_loss 0.108018436 triplet loss 0.768276632 l2_loss 15.4157486 fraction B 0.105975807 lossA 0.967270374 fraction A 0.0363245\n",
      "step 1435 loss 0.789598405 fisher_loss 0.10724137 triplet loss 0.682357 l2_loss 15.4258537 fraction B 0.0691563189 lossA 0.970438 fraction A 0.0361170396\n",
      "step 1436 loss 0.936516762 fisher_loss 0.106506504 triplet loss 0.830010235 l2_loss 15.4385748 fraction B 0.0923992395 lossA 0.97772491 fraction A 0.0351300128\n",
      "step 1437 loss 1.05285621 fisher_loss 0.105798528 triplet loss 0.947057724 l2_loss 15.452445 fraction B 0.123488709 lossA 1.00891495 fraction A 0.0327608734\n",
      "step 1438 loss 0.800251365 fisher_loss 0.10498523 triplet loss 0.695266128 l2_loss 15.4671984 fraction B 0.10173402 lossA 1.04003358 fraction A 0.0309797712\n",
      "step 1439 loss 0.907649875 fisher_loss 0.105534352 triplet loss 0.8021155 l2_loss 15.4830599 fraction B 0.0973285213 lossA 1.08168876 fraction A 0.0300956927\n",
      "step 1440 loss 1.14442575 fisher_loss 0.107596077 triplet loss 1.03682971 l2_loss 15.4995537 fraction B 0.0893139392 lossA 1.10017335 fraction A 0.0305852257\n",
      "step 1441 loss 0.944196105 fisher_loss 0.108997375 triplet loss 0.83519876 l2_loss 15.5139656 fraction B 0.115260221 lossA 1.09550607 fraction A 0.0306641571\n",
      "step 1442 loss 1.02308881 fisher_loss 0.107258089 triplet loss 0.915830672 l2_loss 15.5274849 fraction B 0.121405177 lossA 1.08485651 fraction A 0.0309402514\n",
      "step 1443 loss 0.955993891 fisher_loss 0.105997808 triplet loss 0.84999609 l2_loss 15.5402203 fraction B 0.107471056 lossA 1.08436489 fraction A 0.03133839\n",
      "step 1444 loss 0.705998898 fisher_loss 0.105832309 triplet loss 0.600166619 l2_loss 15.5523815 fraction B 0.115653113 lossA 1.07469392 fraction A 0.0316519886\n",
      "step 1445 loss 0.843807936 fisher_loss 0.104603991 triplet loss 0.73920393 l2_loss 15.5622606 fraction B 0.0798396394 lossA 1.06119347 fraction A 0.0326151811\n",
      "step 1446 loss 0.915531278 fisher_loss 0.103188321 triplet loss 0.812342942 l2_loss 15.5721598 fraction B 0.0946635306 lossA 1.04706216 fraction A 0.0333700664\n",
      "step 1447 loss 0.99152106 fisher_loss 0.102331236 triplet loss 0.889189839 l2_loss 15.582345 fraction B 0.0969365761 lossA 1.0380311 fraction A 0.0333609767\n",
      "step 1448 loss 1.29620266 fisher_loss 0.103022486 triplet loss 1.1931802 l2_loss 15.5909452 fraction B 0.142993614 lossA 1.02900457 fraction A 0.0334385857\n",
      "step 1449 loss 1.02224922 fisher_loss 0.104651481 triplet loss 0.917597711 l2_loss 15.5994282 fraction B 0.0827261508 lossA 1.03117502 fraction A 0.0329754837\n",
      "step 1450 loss 1.09344542 fisher_loss 0.105869569 triplet loss 0.987575829 l2_loss 15.611762 fraction B 0.127670348 lossA 1.02629352 fraction A 0.0327940136\n",
      "step 1451 loss 0.814850092 fisher_loss 0.10661082 triplet loss 0.708239257 l2_loss 15.624012 fraction B 0.112667434 lossA 1.0279758 fraction A 0.0329108164\n",
      "step 1452 loss 0.825021744 fisher_loss 0.105685443 triplet loss 0.719336271 l2_loss 15.6355543 fraction B 0.138421685 lossA 1.01094437 fraction A 0.0340137258\n",
      "step 1453 loss 0.999002874 fisher_loss 0.103949681 triplet loss 0.895053208 l2_loss 15.6477671 fraction B 0.0936734676 lossA 0.983884811 fraction A 0.0361369811\n",
      "step 1454 loss 0.948301613 fisher_loss 0.103402555 triplet loss 0.844899058 l2_loss 15.6614456 fraction B 0.102286 lossA 0.967660666 fraction A 0.0372943319\n",
      "step 1455 loss 1.13864398 fisher_loss 0.104630962 triplet loss 1.03401303 l2_loss 15.6772499 fraction B 0.106304169 lossA 0.962619543 fraction A 0.0372898243\n",
      "step 1456 loss 1.03256655 fisher_loss 0.105875388 triplet loss 0.926691175 l2_loss 15.6913328 fraction B 0.0952650383 lossA 0.961407125 fraction A 0.0366219692\n",
      "step 1457 loss 1.1647017 fisher_loss 0.106566526 triplet loss 1.05813515 l2_loss 15.7044649 fraction B 0.097551018 lossA 0.965119779 fraction A 0.036168877\n",
      "step 1458 loss 0.895232856 fisher_loss 0.104938947 triplet loss 0.790293932 l2_loss 15.7166328 fraction B 0.0781447142 lossA 0.978671908 fraction A 0.0349238701\n",
      "step 1459 loss 0.883469582 fisher_loss 0.104057625 triplet loss 0.779412 l2_loss 15.7297239 fraction B 0.122711547 lossA 0.997320294 fraction A 0.0334262326\n",
      "step 1460 loss 0.992078185 fisher_loss 0.104350224 triplet loss 0.887728 l2_loss 15.741971 fraction B 0.0653972328 lossA 1.0287056 fraction A 0.0314751714\n",
      "step 1461 loss 1.10746956 fisher_loss 0.106889501 triplet loss 1.00058007 l2_loss 15.7530127 fraction B 0.137696341 lossA 1.04595 fraction A 0.0311153438\n",
      "step 1462 loss 0.949760199 fisher_loss 0.10980539 triplet loss 0.839954793 l2_loss 15.7627134 fraction B 0.138073504 lossA 1.05089831 fraction A 0.0314897634\n",
      "step 1463 loss 1.05422592 fisher_loss 0.111664578 triplet loss 0.942561388 l2_loss 15.7742596 fraction B 0.158576176 lossA 1.03821075 fraction A 0.0323767401\n",
      "step 1464 loss 0.816685855 fisher_loss 0.109062865 triplet loss 0.707623 l2_loss 15.7842436 fraction B 0.141355306 lossA 1.01345837 fraction A 0.0339689255\n",
      "step 1465 loss 0.752306223 fisher_loss 0.102440052 triplet loss 0.649866164 l2_loss 15.792181 fraction B 0.0928391516 lossA 0.990207136 fraction A 0.0372997224\n",
      "step 1466 loss 0.891222835 fisher_loss 0.101928599 triplet loss 0.789294243 l2_loss 15.7990971 fraction B 0.0688088313 lossA 0.980264187 fraction A 0.0408329964\n",
      "step 1467 loss 1.14327645 fisher_loss 0.106860697 triplet loss 1.03641582 l2_loss 15.8039055 fraction B 0.187702551 lossA 0.985763431 fraction A 0.0432666615\n",
      "step 1468 loss 1.12736869 fisher_loss 0.113275006 triplet loss 1.01409364 l2_loss 15.8104429 fraction B 0.124711484 lossA 0.996752501 fraction A 0.0440019704\n",
      "step 1469 loss 1.11250746 fisher_loss 0.116107464 triplet loss 0.9964 l2_loss 15.8166952 fraction B 0.10954801 lossA 1.01823604 fraction A 0.041802384\n",
      "step 1470 loss 1.07436371 fisher_loss 0.114450075 triplet loss 0.959913611 l2_loss 15.8236122 fraction B 0.110679194 lossA 1.03433168 fraction A 0.038847\n",
      "step 1471 loss 1.01722932 fisher_loss 0.110640302 triplet loss 0.906589 l2_loss 15.8307152 fraction B 0.0847908184 lossA 1.04420185 fraction A 0.0358469561\n",
      "step 1472 loss 0.880879402 fisher_loss 0.107473604 triplet loss 0.77340579 l2_loss 15.8407307 fraction B 0.0896343514 lossA 1.01997054 fraction A 0.0341730528\n",
      "step 1473 loss 1.06216586 fisher_loss 0.103709385 triplet loss 0.958456457 l2_loss 15.8515778 fraction B 0.113860495 lossA 0.995660484 fraction A 0.0340216421\n",
      "step 1474 loss 0.86606741 fisher_loss 0.103399783 triplet loss 0.762667596 l2_loss 15.8636723 fraction B 0.0740203187 lossA 0.982996345 fraction A 0.0348381922\n",
      "step 1475 loss 0.988832 fisher_loss 0.104702771 triplet loss 0.884129226 l2_loss 15.8791008 fraction B 0.10204234 lossA 0.981247 fraction A 0.0357717276\n",
      "step 1476 loss 0.801717639 fisher_loss 0.10842026 triplet loss 0.693297386 l2_loss 15.8960924 fraction B 0.0772185102 lossA 0.988071859 fraction A 0.0361459628\n",
      "step 1477 loss 0.951313853 fisher_loss 0.11343319 triplet loss 0.837880671 l2_loss 15.9151249 fraction B 0.055125542 lossA 1.00443876 fraction A 0.0348869525\n",
      "step 1478 loss 0.896818101 fisher_loss 0.115130052 triplet loss 0.781688035 l2_loss 15.9344301 fraction B 0.108266011 lossA 1.01768363 fraction A 0.03405343\n",
      "step 1479 loss 1.05035174 fisher_loss 0.114710525 triplet loss 0.93564117 l2_loss 15.95401 fraction B 0.0725853071 lossA 1.02060747 fraction A 0.0337220877\n",
      "step 1480 loss 0.96554774 fisher_loss 0.112343609 triplet loss 0.853204131 l2_loss 15.9720125 fraction B 0.0767290667 lossA 1.01944268 fraction A 0.0341738611\n",
      "step 1481 loss 0.880075693 fisher_loss 0.110866584 triplet loss 0.769209087 l2_loss 15.9892406 fraction B 0.10490527 lossA 1.03573596 fraction A 0.0339916535\n",
      "step 1482 loss 1.12489831 fisher_loss 0.111190639 triplet loss 1.01370764 l2_loss 16.005867 fraction B 0.165141419 lossA 1.0589329 fraction A 0.0344894379\n",
      "step 1483 loss 0.927848101 fisher_loss 0.112467162 triplet loss 0.815380931 l2_loss 16.0207214 fraction B 0.0804249421 lossA 1.08372867 fraction A 0.0353011116\n",
      "step 1484 loss 1.15650201 fisher_loss 0.115211368 triplet loss 1.04129064 l2_loss 16.0359783 fraction B 0.112841807 lossA 1.09329009 fraction A 0.0366294123\n",
      "step 1485 loss 0.821316421 fisher_loss 0.117380917 triplet loss 0.703935504 l2_loss 16.049139 fraction B 0.173930272 lossA 1.10644579 fraction A 0.0373392776\n",
      "step 1486 loss 0.854282379 fisher_loss 0.118159682 triplet loss 0.736122727 l2_loss 16.0621471 fraction B 0.0810073242 lossA 1.10771263 fraction A 0.0386465341\n",
      "step 1487 loss 1.14991844 fisher_loss 0.118139878 triplet loss 1.03177857 l2_loss 16.0751266 fraction B 0.11140383 lossA 1.08655965 fraction A 0.0397874266\n",
      "step 1488 loss 1.02639961 fisher_loss 0.115804739 triplet loss 0.910594821 l2_loss 16.0888901 fraction B 0.11566747 lossA 1.07635128 fraction A 0.0404111\n",
      "step 1489 loss 1.04174197 fisher_loss 0.114679299 triplet loss 0.92706269 l2_loss 16.1032391 fraction B 0.123423226 lossA 1.05873883 fraction A 0.0403637365\n",
      "step 1490 loss 0.867128134 fisher_loss 0.112645052 triplet loss 0.754483104 l2_loss 16.1177254 fraction B 0.132153675 lossA 1.03971016 fraction A 0.0395671278\n",
      "step 1491 loss 0.890879 fisher_loss 0.111118853 triplet loss 0.779760122 l2_loss 16.1331291 fraction B 0.117057405 lossA 1.00937819 fraction A 0.0398415737\n",
      "step 1492 loss 0.621261 fisher_loss 0.110795125 triplet loss 0.51046586 l2_loss 16.1495647 fraction B 0.0818390772 lossA 0.980029106 fraction A 0.0409526564\n",
      "step 1493 loss 0.762001514 fisher_loss 0.110514484 triplet loss 0.651487052 l2_loss 16.170248 fraction B 0.09839423 lossA 0.967382789 fraction A 0.0411795527\n",
      "step 1494 loss 0.907841 fisher_loss 0.111336127 triplet loss 0.796504915 l2_loss 16.1910172 fraction B 0.113780662 lossA 0.963024497 fraction A 0.0407197885\n",
      "step 1495 loss 0.996111393 fisher_loss 0.112937845 triplet loss 0.883173525 l2_loss 16.2108345 fraction B 0.160786361 lossA 0.964506149 fraction A 0.0395250432\n",
      "step 1496 loss 0.915947855 fisher_loss 0.112508252 triplet loss 0.803439617 l2_loss 16.2291527 fraction B 0.0895238072 lossA 0.967633784 fraction A 0.0385527946\n",
      "step 1497 loss 0.661564231 fisher_loss 0.11042387 triplet loss 0.551140368 l2_loss 16.2456646 fraction B 0.0664796 lossA 0.990194857 fraction A 0.0364003554\n",
      "step 1498 loss 0.855994463 fisher_loss 0.107024297 triplet loss 0.748970151 l2_loss 16.2646046 fraction B 0.0945338532 lossA 1.02358711 fraction A 0.0349945538\n",
      "step 1499 loss 1.09126723 fisher_loss 0.105412945 triplet loss 0.985854268 l2_loss 16.2831306 fraction B 0.116067126 lossA 1.05025721 fraction A 0.0346104912\n",
      "step 1500 loss 0.982496738 fisher_loss 0.106525451 triplet loss 0.875971317 l2_loss 16.3004894 fraction B 0.10636989 lossA 1.07223129 fraction A 0.0352270566\n",
      "step 1501 loss 1.06405342 fisher_loss 0.108463891 triplet loss 0.955589533 l2_loss 16.3167953 fraction B 0.130794108 lossA 1.06715822 fraction A 0.0364093371\n",
      "step 1502 loss 0.880177855 fisher_loss 0.110239722 triplet loss 0.769938111 l2_loss 16.3301163 fraction B 0.13524501 lossA 1.07260144 fraction A 0.0374123082\n",
      "step 1503 loss 1.07960153 fisher_loss 0.112368435 triplet loss 0.967233062 l2_loss 16.3430882 fraction B 0.148576066 lossA 1.06720161 fraction A 0.0386809222\n",
      "step 1504 loss 1.06500387 fisher_loss 0.112674661 triplet loss 0.952329218 l2_loss 16.3539124 fraction B 0.136219338 lossA 1.05765581 fraction A 0.0395558365\n",
      "step 1505 loss 1.0828979 fisher_loss 0.111899376 triplet loss 0.970998526 l2_loss 16.3632259 fraction B 0.152028978 lossA 1.04558039 fraction A 0.040183913\n",
      "step 1506 loss 0.952112198 fisher_loss 0.11063192 triplet loss 0.841480255 l2_loss 16.3721447 fraction B 0.133477405 lossA 1.04533851 fraction A 0.0395533815\n",
      "step 1507 loss 0.986317396 fisher_loss 0.109073147 triplet loss 0.877244234 l2_loss 16.381588 fraction B 0.0966724679 lossA 1.05348325 fraction A 0.0376345441\n",
      "step 1508 loss 1.04296052 fisher_loss 0.107870534 triplet loss 0.93509 l2_loss 16.3906422 fraction B 0.0832017213 lossA 1.05630088 fraction A 0.0362065285\n",
      "step 1509 loss 0.895155787 fisher_loss 0.107706286 triplet loss 0.787449479 l2_loss 16.3992 fraction B 0.114296511 lossA 1.06448233 fraction A 0.0337576121\n",
      "step 1510 loss 0.947480619 fisher_loss 0.111235164 triplet loss 0.836245477 l2_loss 16.4081936 fraction B 0.112021662 lossA 1.06831634 fraction A 0.0319634229\n",
      "step 1511 loss 0.841073513 fisher_loss 0.117307462 triplet loss 0.723766 l2_loss 16.4187584 fraction B 0.0621267296 lossA 1.06024623 fraction A 0.0311867241\n",
      "step 1512 loss 1.05867946 fisher_loss 0.122484885 triplet loss 0.936194599 l2_loss 16.4315186 fraction B 0.0858080909 lossA 1.06016481 fraction A 0.0303395614\n",
      "step 1513 loss 0.974049747 fisher_loss 0.12364345 triplet loss 0.850406289 l2_loss 16.4445934 fraction B 0.139095977 lossA 1.04996192 fraction A 0.0302464794\n",
      "step 1514 loss 1.27613616 fisher_loss 0.122140847 triplet loss 1.15399528 l2_loss 16.4561501 fraction B 0.148292065 lossA 1.02428961 fraction A 0.0310583729\n",
      "step 1515 loss 0.828570724 fisher_loss 0.117876016 triplet loss 0.71069473 l2_loss 16.4655304 fraction B 0.120079368 lossA 0.989784539 fraction A 0.0328166336\n",
      "step 1516 loss 0.938352466 fisher_loss 0.114865027 triplet loss 0.823487461 l2_loss 16.4760056 fraction B 0.0979309082 lossA 0.955109 fraction A 0.0353842601\n",
      "step 1517 loss 0.960072041 fisher_loss 0.116528578 triplet loss 0.84354347 l2_loss 16.486721 fraction B 0.122873686 lossA 0.934708834 fraction A 0.0374185033\n",
      "step 1518 loss 1.01887691 fisher_loss 0.118260942 triplet loss 0.900616 l2_loss 16.4977341 fraction B 0.10938061 lossA 0.933210254 fraction A 0.0373015553\n",
      "step 1519 loss 1.00309408 fisher_loss 0.117608212 triplet loss 0.885485888 l2_loss 16.5091171 fraction B 0.162275016 lossA 0.946015835 fraction A 0.0359952487\n",
      "step 1520 loss 1.02513957 fisher_loss 0.115820974 triplet loss 0.909318626 l2_loss 16.5191898 fraction B 0.114123374 lossA 0.967215836 fraction A 0.0340870097\n",
      "step 1521 loss 1.03891051 fisher_loss 0.113771223 triplet loss 0.925139248 l2_loss 16.5316868 fraction B 0.130467653 lossA 0.986046314 fraction A 0.0317471586\n",
      "step 1522 loss 0.956804335 fisher_loss 0.111820817 triplet loss 0.844983518 l2_loss 16.5432377 fraction B 0.0853676274 lossA 1.00511742 fraction A 0.0295363553\n",
      "step 1523 loss 0.8441118 fisher_loss 0.110263295 triplet loss 0.733848512 l2_loss 16.5533867 fraction B 0.079819493 lossA 1.02325201 fraction A 0.0277405549\n",
      "step 1524 loss 0.896424 fisher_loss 0.111114018 triplet loss 0.78531 l2_loss 16.5651035 fraction B 0.0564043559 lossA 1.03847742 fraction A 0.0266869552\n",
      "step 1525 loss 0.91223073 fisher_loss 0.115431435 triplet loss 0.796799302 l2_loss 16.5757332 fraction B 0.115641229 lossA 1.03093064 fraction A 0.0270597972\n",
      "step 1526 loss 0.9184466 fisher_loss 0.117912725 triplet loss 0.800533891 l2_loss 16.5856762 fraction B 0.195614547 lossA 1.00800908 fraction A 0.0284427963\n",
      "step 1527 loss 0.919296324 fisher_loss 0.114588238 triplet loss 0.804708064 l2_loss 16.595932 fraction B 0.101310119 lossA 0.992966652 fraction A 0.0299259163\n",
      "step 1528 loss 0.94386375 fisher_loss 0.111419342 triplet loss 0.832444429 l2_loss 16.6066341 fraction B 0.112766802 lossA 0.970018387 fraction A 0.0331259072\n",
      "step 1529 loss 0.77712512 fisher_loss 0.108660847 triplet loss 0.668464243 l2_loss 16.6170902 fraction B 0.0915997103 lossA 0.952223957 fraction A 0.0355644822\n",
      "step 1530 loss 0.947891653 fisher_loss 0.105455108 triplet loss 0.842436552 l2_loss 16.6279812 fraction B 0.111944646 lossA 0.943926036 fraction A 0.0372644514\n",
      "step 1531 loss 0.954028487 fisher_loss 0.104664542 triplet loss 0.849363923 l2_loss 16.6405029 fraction B 0.137601301 lossA 0.941817284 fraction A 0.0385397039\n",
      "step 1532 loss 1.02504647 fisher_loss 0.105121449 triplet loss 0.919925 l2_loss 16.6533222 fraction B 0.06479913 lossA 0.939980805 fraction A 0.0392165035\n",
      "step 1533 loss 0.97835803 fisher_loss 0.104976892 triplet loss 0.873381138 l2_loss 16.6675663 fraction B 0.122506097 lossA 0.944706082 fraction A 0.0380619019\n",
      "step 1534 loss 0.849672377 fisher_loss 0.104521699 triplet loss 0.745150685 l2_loss 16.6833897 fraction B 0.0834818333 lossA 0.969762623 fraction A 0.035149958\n",
      "step 1535 loss 0.904990494 fisher_loss 0.104787603 triplet loss 0.800202906 l2_loss 16.6999722 fraction B 0.0971495584 lossA 1.0018549 fraction A 0.0322438776\n",
      "step 1536 loss 1.03132939 fisher_loss 0.106669374 triplet loss 0.92466 l2_loss 16.7162838 fraction B 0.0894120708 lossA 1.03373086 fraction A 0.0306421611\n",
      "step 1537 loss 0.761780798 fisher_loss 0.109464921 triplet loss 0.652315855 l2_loss 16.7319546 fraction B 0.0922030658 lossA 1.0506444 fraction A 0.0306474399\n",
      "step 1538 loss 0.815591097 fisher_loss 0.110563457 triplet loss 0.70502764 l2_loss 16.7499657 fraction B 0.0851153433 lossA 1.06584859 fraction A 0.0314033516\n",
      "step 1539 loss 0.802221179 fisher_loss 0.11097683 triplet loss 0.691244364 l2_loss 16.7683887 fraction B 0.0883092657 lossA 1.08754015 fraction A 0.0328921564\n",
      "step 1540 loss 0.791884 fisher_loss 0.111558795 triplet loss 0.68032521 l2_loss 16.788168 fraction B 0.0774170309 lossA 1.08727932 fraction A 0.032867115\n",
      "step 1541 loss 0.710307479 fisher_loss 0.109496854 triplet loss 0.600810647 l2_loss 16.8060417 fraction B 0.0686578155 lossA 1.0779531 fraction A 0.0322870277\n",
      "step 1542 loss 0.843014 fisher_loss 0.106860086 triplet loss 0.736153901 l2_loss 16.822216 fraction B 0.086486876 lossA 1.06456506 fraction A 0.0321118273\n",
      "step 1543 loss 0.849287748 fisher_loss 0.105356507 triplet loss 0.743931234 l2_loss 16.8383045 fraction B 0.0657997951 lossA 1.04880023 fraction A 0.0324823596\n",
      "step 1544 loss 1.03253937 fisher_loss 0.104914822 triplet loss 0.927624583 l2_loss 16.8532181 fraction B 0.075686492 lossA 1.03142393 fraction A 0.0334330872\n",
      "step 1545 loss 0.716725349 fisher_loss 0.104656622 triplet loss 0.612068713 l2_loss 16.8676853 fraction B 0.0671443939 lossA 1.01835012 fraction A 0.0331228636\n",
      "step 1546 loss 0.974668086 fisher_loss 0.103829972 triplet loss 0.870838106 l2_loss 16.8847198 fraction B 0.0697032586 lossA 1.01218534 fraction A 0.0326557644\n",
      "step 1547 loss 1.10206306 fisher_loss 0.103608362 triplet loss 0.99845475 l2_loss 16.9012012 fraction B 0.199603677 lossA 1.01499867 fraction A 0.0318396203\n",
      "step 1548 loss 0.788484573 fisher_loss 0.103987165 triplet loss 0.684497416 l2_loss 16.9171524 fraction B 0.0561738499 lossA 1.04377306 fraction A 0.0296981409\n",
      "step 1549 loss 0.981407046 fisher_loss 0.104913302 triplet loss 0.876493752 l2_loss 16.9333839 fraction B 0.148597047 lossA 1.06799936 fraction A 0.0284999497\n",
      "step 1550 loss 0.911866367 fisher_loss 0.106215589 triplet loss 0.805650771 l2_loss 16.948019 fraction B 0.145057723 lossA 1.09442854 fraction A 0.0278253891\n",
      "step 1551 loss 0.876345515 fisher_loss 0.106437944 triplet loss 0.769907594 l2_loss 16.9621563 fraction B 0.0919718593 lossA 1.11338747 fraction A 0.0280373991\n",
      "step 1552 loss 1.17985451 fisher_loss 0.106113754 triplet loss 1.07374072 l2_loss 16.9767838 fraction B 0.109771989 lossA 1.11812806 fraction A 0.0283039231\n",
      "step 1553 loss 1.14369273 fisher_loss 0.105193526 triplet loss 1.03849924 l2_loss 16.9903641 fraction B 0.153030634 lossA 1.10248363 fraction A 0.0295295\n",
      "step 1554 loss 1.09929109 fisher_loss 0.104474813 triplet loss 0.994816244 l2_loss 17.0020084 fraction B 0.162392393 lossA 1.06957245 fraction A 0.0318296477\n",
      "step 1555 loss 0.844050825 fisher_loss 0.105534114 triplet loss 0.738516688 l2_loss 17.011961 fraction B 0.0798215717 lossA 1.04308641 fraction A 0.0349863395\n",
      "step 1556 loss 1.09122574 fisher_loss 0.107587889 triplet loss 0.98363781 l2_loss 17.0234032 fraction B 0.109482445 lossA 1.02391183 fraction A 0.0392895341\n",
      "step 1557 loss 1.02461517 fisher_loss 0.110499397 triplet loss 0.914115787 l2_loss 17.0326653 fraction B 0.129889324 lossA 1.0183816 fraction A 0.04143475\n",
      "step 1558 loss 0.944559455 fisher_loss 0.110792585 triplet loss 0.833766878 l2_loss 17.043623 fraction B 0.0764378458 lossA 1.02100909 fraction A 0.0405431166\n",
      "step 1559 loss 1.23819113 fisher_loss 0.107997812 triplet loss 1.13019335 l2_loss 17.056654 fraction B 0.159847289 lossA 1.02900743 fraction A 0.0397233404\n",
      "step 1560 loss 0.902349651 fisher_loss 0.106453851 triplet loss 0.795895815 l2_loss 17.0686207 fraction B 0.101434015 lossA 1.03601933 fraction A 0.0384935141\n",
      "step 1561 loss 0.937695265 fisher_loss 0.105883926 triplet loss 0.831811368 l2_loss 17.0810261 fraction B 0.0732409358 lossA 1.03900254 fraction A 0.0369307287\n",
      "step 1562 loss 0.919786215 fisher_loss 0.107425667 triplet loss 0.812360525 l2_loss 17.0936356 fraction B 0.080497928 lossA 1.0322268 fraction A 0.0355795138\n",
      "step 1563 loss 1.15902185 fisher_loss 0.109065078 triplet loss 1.0499568 l2_loss 17.1064472 fraction B 0.18782869 lossA 1.02174759 fraction A 0.0351792872\n",
      "step 1564 loss 0.718634546 fisher_loss 0.110981524 triplet loss 0.607653 l2_loss 17.1177025 fraction B 0.0813798308 lossA 1.01983285 fraction A 0.0343351327\n",
      "step 1565 loss 0.925027072 fisher_loss 0.112731092 triplet loss 0.812296 l2_loss 17.1288834 fraction B 0.0844058245 lossA 1.01820266 fraction A 0.0334211\n",
      "step 1566 loss 1.06800604 fisher_loss 0.112710059 triplet loss 0.95529592 l2_loss 17.1422558 fraction B 0.0863811299 lossA 1.01711106 fraction A 0.0323760435\n",
      "step 1567 loss 1.0874666 fisher_loss 0.112326 triplet loss 0.975140631 l2_loss 17.1546078 fraction B 0.0810656324 lossA 1.01486778 fraction A 0.0311779249\n",
      "step 1568 loss 0.907791197 fisher_loss 0.113040768 triplet loss 0.794750452 l2_loss 17.1668224 fraction B 0.0775292814 lossA 1.01809096 fraction A 0.0301161855\n",
      "step 1569 loss 0.789986 fisher_loss 0.113092996 triplet loss 0.676893 l2_loss 17.1784611 fraction B 0.0632962808 lossA 1.02511609 fraction A 0.0293811336\n",
      "step 1570 loss 1.01487529 fisher_loss 0.11304298 triplet loss 0.901832283 l2_loss 17.1901531 fraction B 0.200756207 lossA 1.02973771 fraction A 0.0292950906\n",
      "step 1571 loss 0.952229202 fisher_loss 0.112147212 triplet loss 0.840082 l2_loss 17.2013302 fraction B 0.115544714 lossA 1.04484355 fraction A 0.0285470225\n",
      "step 1572 loss 0.996730208 fisher_loss 0.11183317 triplet loss 0.884897053 l2_loss 17.2129269 fraction B 0.136722252 lossA 1.04052985 fraction A 0.0283057932\n",
      "step 1573 loss 1.05266368 fisher_loss 0.110758461 triplet loss 0.9419052 l2_loss 17.225832 fraction B 0.121212125 lossA 1.03135431 fraction A 0.0286843181\n",
      "step 1574 loss 1.02899063 fisher_loss 0.109482855 triplet loss 0.919507742 l2_loss 17.2371769 fraction B 0.108042464 lossA 1.00727379 fraction A 0.0298904274\n",
      "step 1575 loss 1.07566428 fisher_loss 0.10810715 triplet loss 0.967557192 l2_loss 17.2482 fraction B 0.181100518 lossA 0.969309568 fraction A 0.0326829664\n",
      "step 1576 loss 1.0468415 fisher_loss 0.107440867 triplet loss 0.939400673 l2_loss 17.2580433 fraction B 0.168398529 lossA 0.944411337 fraction A 0.0356502347\n",
      "step 1577 loss 0.848728776 fisher_loss 0.1082616 triplet loss 0.740467191 l2_loss 17.2670498 fraction B 0.0783051476 lossA 0.93548435 fraction A 0.0373012237\n",
      "step 1578 loss 1.00187874 fisher_loss 0.109118901 triplet loss 0.8927598 l2_loss 17.2771721 fraction B 0.0750564933 lossA 0.933270037 fraction A 0.037369892\n",
      "step 1579 loss 0.94693619 fisher_loss 0.109074585 triplet loss 0.837861598 l2_loss 17.287344 fraction B 0.0515712351 lossA 0.947723091 fraction A 0.0348299071\n",
      "step 1580 loss 0.914665639 fisher_loss 0.10704457 triplet loss 0.807621062 l2_loss 17.3009586 fraction B 0.115955308 lossA 0.98630476 fraction A 0.0314772241\n",
      "step 1581 loss 0.873690844 fisher_loss 0.107214577 triplet loss 0.766476274 l2_loss 17.3141975 fraction B 0.0972121656 lossA 1.04260099 fraction A 0.0291073862\n",
      "step 1582 loss 0.780530155 fisher_loss 0.110858202 triplet loss 0.669671953 l2_loss 17.3274155 fraction B 0.0752471611 lossA 1.09514165 fraction A 0.0279125683\n",
      "step 1583 loss 0.89988786 fisher_loss 0.116508767 triplet loss 0.783379078 l2_loss 17.34025 fraction B 0.140200645 lossA 1.09635651 fraction A 0.0278207697\n",
      "step 1584 loss 0.996402383 fisher_loss 0.116987899 triplet loss 0.879414499 l2_loss 17.3478775 fraction B 0.0530856885 lossA 1.09045541 fraction A 0.0281564\n",
      "step 1585 loss 0.743566751 fisher_loss 0.115215547 triplet loss 0.628351212 l2_loss 17.3555374 fraction B 0.0706117228 lossA 1.05823612 fraction A 0.0300468225\n",
      "step 1586 loss 0.975673139 fisher_loss 0.112933755 triplet loss 0.862739384 l2_loss 17.3625698 fraction B 0.12260101 lossA 1.04104257 fraction A 0.0318365023\n",
      "step 1587 loss 1.05392551 fisher_loss 0.112172224 triplet loss 0.941753268 l2_loss 17.3688126 fraction B 0.0823422447 lossA 1.03729057 fraction A 0.0334015228\n",
      "step 1588 loss 0.805845737 fisher_loss 0.112143271 triplet loss 0.693702459 l2_loss 17.375248 fraction B 0.0564271249 lossA 1.01754057 fraction A 0.0363852866\n",
      "step 1589 loss 1.06709445 fisher_loss 0.111805834 triplet loss 0.955288649 l2_loss 17.382473 fraction B 0.122673161 lossA 1.00025702 fraction A 0.0397894047\n",
      "step 1590 loss 0.930829167 fisher_loss 0.111809425 triplet loss 0.819019735 l2_loss 17.3892269 fraction B 0.133201152 lossA 0.994889438 fraction A 0.0411728434\n",
      "step 1591 loss 0.829449773 fisher_loss 0.111027792 triplet loss 0.718422 l2_loss 17.3987236 fraction B 0.0642941818 lossA 1.00454354 fraction A 0.0402265489\n",
      "step 1592 loss 1.10590863 fisher_loss 0.110212125 triplet loss 0.995696545 l2_loss 17.4075661 fraction B 0.113499261 lossA 1.025437 fraction A 0.0375849083\n",
      "step 1593 loss 1.01884294 fisher_loss 0.110084638 triplet loss 0.908758342 l2_loss 17.4164066 fraction B 0.112372242 lossA 1.05801868 fraction A 0.0338712595\n",
      "step 1594 loss 0.904937863 fisher_loss 0.112304 triplet loss 0.792633832 l2_loss 17.4248905 fraction B 0.0790625 lossA 1.08274758 fraction A 0.0320950337\n",
      "step 1595 loss 0.9931373 fisher_loss 0.113623418 triplet loss 0.87951386 l2_loss 17.4339638 fraction B 0.122631013 lossA 1.10449779 fraction A 0.03105467\n",
      "step 1596 loss 0.859592378 fisher_loss 0.113596335 triplet loss 0.745996058 l2_loss 17.4426212 fraction B 0.140493646 lossA 1.11901677 fraction A 0.0303264372\n",
      "step 1597 loss 0.792200089 fisher_loss 0.109632708 triplet loss 0.682567358 l2_loss 17.4521542 fraction B 0.0974170789 lossA 1.10685551 fraction A 0.0302868057\n",
      "step 1598 loss 0.861930907 fisher_loss 0.106819712 triplet loss 0.755111217 l2_loss 17.4611206 fraction B 0.0697292387 lossA 1.10260749 fraction A 0.029823998\n",
      "step 1599 loss 1.12850618 fisher_loss 0.10649731 triplet loss 1.0220089 l2_loss 17.4737511 fraction B 0.104171157 lossA 1.09763801 fraction A 0.0295445677\n",
      "step 1600 loss 0.717624784 fisher_loss 0.107238367 triplet loss 0.610386431 l2_loss 17.4840202 fraction B 0.0504782349 lossA 1.10400772 fraction A 0.0284977872\n",
      "step 1601 loss 0.802388251 fisher_loss 0.108812772 triplet loss 0.693575501 l2_loss 17.4940033 fraction B 0.0740898773 lossA 1.08867252 fraction A 0.0280862674\n",
      "step 1602 loss 0.902856886 fisher_loss 0.109805942 triplet loss 0.793050945 l2_loss 17.5053482 fraction B 0.106372617 lossA 1.08093441 fraction A 0.0277500506\n",
      "step 1603 loss 0.732745707 fisher_loss 0.109354191 triplet loss 0.623391509 l2_loss 17.517252 fraction B 0.0687135532 lossA 1.07373428 fraction A 0.0277904496\n",
      "step 1604 loss 0.969679892 fisher_loss 0.108010657 triplet loss 0.861669242 l2_loss 17.5292549 fraction B 0.106394075 lossA 1.06973588 fraction A 0.0278332345\n",
      "step 1605 loss 0.747183 fisher_loss 0.107525729 triplet loss 0.639657319 l2_loss 17.5423126 fraction B 0.0656029657 lossA 1.07022691 fraction A 0.0279603\n",
      "step 1606 loss 0.913048 fisher_loss 0.107564241 triplet loss 0.805483818 l2_loss 17.5565357 fraction B 0.111034729 lossA 1.06515908 fraction A 0.0286630541\n",
      "step 1607 loss 0.814718604 fisher_loss 0.108431138 triplet loss 0.706287444 l2_loss 17.5706482 fraction B 0.075686492 lossA 1.0626061 fraction A 0.0288667791\n",
      "step 1608 loss 0.7223171 fisher_loss 0.107074581 triplet loss 0.615242541 l2_loss 17.5829945 fraction B 0.0493583046 lossA 1.06758 fraction A 0.0289714467\n",
      "step 1609 loss 0.770626903 fisher_loss 0.105173454 triplet loss 0.665453434 l2_loss 17.5959091 fraction B 0.0686632469 lossA 1.082026 fraction A 0.0288511626\n",
      "step 1610 loss 1.16890967 fisher_loss 0.104504578 triplet loss 1.06440508 l2_loss 17.6098957 fraction B 0.126507103 lossA 1.09299099 fraction A 0.0289069973\n",
      "step 1611 loss 1.07228541 fisher_loss 0.104962647 triplet loss 0.967322767 l2_loss 17.6214314 fraction B 0.129016563 lossA 1.09702551 fraction A 0.0291466862\n",
      "step 1612 loss 0.87790519 fisher_loss 0.105843075 triplet loss 0.772062123 l2_loss 17.6314945 fraction B 0.0758082718 lossA 1.11540902 fraction A 0.0290033426\n",
      "step 1613 loss 0.838445961 fisher_loss 0.108433507 triplet loss 0.730012476 l2_loss 17.643528 fraction B 0.0878168 lossA 1.11010969 fraction A 0.0300830454\n",
      "step 1614 loss 0.960871279 fisher_loss 0.110685542 triplet loss 0.850185752 l2_loss 17.655817 fraction B 0.0803154409 lossA 1.09743476 fraction A 0.0313220024\n",
      "step 1615 loss 0.900728583 fisher_loss 0.112208992 triplet loss 0.788519561 l2_loss 17.6664 fraction B 0.0865956247 lossA 1.08498013 fraction A 0.0325103328\n",
      "step 1616 loss 0.975840867 fisher_loss 0.113033533 triplet loss 0.862807333 l2_loss 17.6754971 fraction B 0.138358772 lossA 1.08084714 fraction A 0.033020433\n",
      "step 1617 loss 0.965279937 fisher_loss 0.113546975 triplet loss 0.851732969 l2_loss 17.6847839 fraction B 0.0937859192 lossA 1.0840019 fraction A 0.032608144\n",
      "step 1618 loss 0.951706767 fisher_loss 0.112203509 triplet loss 0.839503288 l2_loss 17.694376 fraction B 0.120732501 lossA 1.09505713 fraction A 0.0319115855\n",
      "step 1619 loss 0.844790578 fisher_loss 0.110749878 triplet loss 0.734040678 l2_loss 17.7048302 fraction B 0.087736547 lossA 1.11581695 fraction A 0.0312506966\n",
      "step 1620 loss 0.859565 fisher_loss 0.110572934 triplet loss 0.748992085 l2_loss 17.7167568 fraction B 0.0646268576 lossA 1.11908734 fraction A 0.0318993777\n",
      "step 1621 loss 1.09358561 fisher_loss 0.111084059 triplet loss 0.982501507 l2_loss 17.729763 fraction B 0.0793149099 lossA 1.10816979 fraction A 0.032443352\n",
      "step 1622 loss 1.07029808 fisher_loss 0.111322753 triplet loss 0.958975375 l2_loss 17.7433 fraction B 0.0897199735 lossA 1.09383285 fraction A 0.0332272351\n",
      "step 1623 loss 1.01848078 fisher_loss 0.112069853 triplet loss 0.906410873 l2_loss 17.757206 fraction B 0.0659144 lossA 1.08723259 fraction A 0.032993596\n",
      "step 1624 loss 0.982952952 fisher_loss 0.113946304 triplet loss 0.869006634 l2_loss 17.771452 fraction B 0.107350722 lossA 1.08325946 fraction A 0.0313524306\n",
      "step 1625 loss 1.01929629 fisher_loss 0.114883155 triplet loss 0.904413164 l2_loss 17.7875767 fraction B 0.0702040792 lossA 1.09050047 fraction A 0.028785063\n",
      "step 1626 loss 1.02307 fisher_loss 0.115269378 triplet loss 0.907800555 l2_loss 17.807066 fraction B 0.0552561134 lossA 1.10739195 fraction A 0.0265095886\n",
      "step 1627 loss 0.950454712 fisher_loss 0.11761333 triplet loss 0.832841396 l2_loss 17.8268604 fraction B 0.0998130292 lossA 1.13171935 fraction A 0.0252680648\n",
      "step 1628 loss 1.12341785 fisher_loss 0.12113186 triplet loss 1.00228596 l2_loss 17.8461418 fraction B 0.150060207 lossA 1.13633025 fraction A 0.0256108828\n",
      "step 1629 loss 0.954876482 fisher_loss 0.12267179 triplet loss 0.8322047 l2_loss 17.8637428 fraction B 0.084395729 lossA 1.13455963 fraction A 0.0265106149\n",
      "step 1630 loss 1.00993121 fisher_loss 0.12249501 triplet loss 0.887436152 l2_loss 17.8805 fraction B 0.116166241 lossA 1.11208427 fraction A 0.0271371156\n",
      "step 1631 loss 0.933517039 fisher_loss 0.118314095 triplet loss 0.815202951 l2_loss 17.8936291 fraction B 0.0932655632 lossA 1.08251691 fraction A 0.027814243\n",
      "step 1632 loss 0.857767463 fisher_loss 0.11377456 triplet loss 0.743992925 l2_loss 17.9042244 fraction B 0.0776424557 lossA 1.06043029 fraction A 0.0290455017\n",
      "step 1633 loss 1.02894342 fisher_loss 0.111487441 triplet loss 0.917456 l2_loss 17.9133301 fraction B 0.108300537 lossA 1.05341578 fraction A 0.0296759605\n",
      "step 1634 loss 1.0083648 fisher_loss 0.110796236 triplet loss 0.897568583 l2_loss 17.923172 fraction B 0.0832428485 lossA 1.03915775 fraction A 0.0311586037\n",
      "step 1635 loss 0.852518916 fisher_loss 0.110923059 triplet loss 0.741595864 l2_loss 17.9334755 fraction B 0.0940121934 lossA 1.04294038 fraction A 0.032747712\n",
      "step 1636 loss 0.860372484 fisher_loss 0.112394869 triplet loss 0.747977614 l2_loss 17.9465714 fraction B 0.121880062 lossA 1.06346488 fraction A 0.0337752067\n",
      "step 1637 loss 1.05062962 fisher_loss 0.114883296 triplet loss 0.935746372 l2_loss 17.958168 fraction B 0.0896344781 lossA 1.079916 fraction A 0.0336860865\n",
      "step 1638 loss 0.79588908 fisher_loss 0.115184724 triplet loss 0.680704355 l2_loss 17.9716854 fraction B 0.109575041 lossA 1.1091392 fraction A 0.0326312743\n",
      "step 1639 loss 0.958096147 fisher_loss 0.115692139 triplet loss 0.842404 l2_loss 17.9854546 fraction B 0.0930016041 lossA 1.12936151 fraction A 0.0310031623\n",
      "step 1640 loss 0.619339705 fisher_loss 0.115275554 triplet loss 0.504064143 l2_loss 18.0007381 fraction B 0.0504349358 lossA 1.14250791 fraction A 0.0291658603\n",
      "step 1641 loss 0.822081208 fisher_loss 0.113974914 triplet loss 0.708106279 l2_loss 18.0191326 fraction B 0.107149303 lossA 1.13400698 fraction A 0.0279721785\n",
      "step 1642 loss 0.902036488 fisher_loss 0.112288222 triplet loss 0.789748251 l2_loss 18.0377312 fraction B 0.08207158 lossA 1.13183463 fraction A 0.0273750443\n",
      "step 1643 loss 0.804890871 fisher_loss 0.111266449 triplet loss 0.693624437 l2_loss 18.055624 fraction B 0.131987467 lossA 1.1057303 fraction A 0.0280390121\n",
      "step 1644 loss 0.962211192 fisher_loss 0.108325191 triplet loss 0.853886 l2_loss 18.0728321 fraction B 0.103514202 lossA 1.08454406 fraction A 0.0294566918\n",
      "step 1645 loss 1.22060931 fisher_loss 0.108059138 triplet loss 1.11255014 l2_loss 18.0898628 fraction B 0.0807667747 lossA 1.05491722 fraction A 0.0320578963\n",
      "step 1646 loss 1.05880737 fisher_loss 0.109678507 triplet loss 0.949128866 l2_loss 18.1044693 fraction B 0.0613390468 lossA 1.04514372 fraction A 0.0328473933\n",
      "step 1647 loss 1.09244084 fisher_loss 0.111507244 triplet loss 0.980933547 l2_loss 18.1214046 fraction B 0.139364615 lossA 1.05346382 fraction A 0.0315886736\n",
      "step 1648 loss 0.922753513 fisher_loss 0.110672601 triplet loss 0.81208092 l2_loss 18.1372013 fraction B 0.126481712 lossA 1.0798831 fraction A 0.0293469653\n",
      "step 1649 loss 1.13250041 fisher_loss 0.108558685 triplet loss 1.02394176 l2_loss 18.1525135 fraction B 0.0838070214 lossA 1.10118234 fraction A 0.0277970862\n",
      "step 1650 loss 1.10929728 fisher_loss 0.107287854 triplet loss 1.00200939 l2_loss 18.1653023 fraction B 0.0647005141 lossA 1.1273967 fraction A 0.0270779449\n",
      "step 1651 loss 1.02284849 fisher_loss 0.107886426 triplet loss 0.914962053 l2_loss 18.1777229 fraction B 0.0688499585 lossA 1.13514924 fraction A 0.027584929\n",
      "step 1652 loss 1.10493231 fisher_loss 0.109577112 triplet loss 0.995355248 l2_loss 18.1910744 fraction B 0.14854981 lossA 1.13298059 fraction A 0.0291780308\n",
      "step 1653 loss 0.888218582 fisher_loss 0.112082146 triplet loss 0.776136458 l2_loss 18.2037964 fraction B 0.146927297 lossA 1.11278284 fraction A 0.0299328435\n",
      "step 1654 loss 0.701552749 fisher_loss 0.112323493 triplet loss 0.589229226 l2_loss 18.2142906 fraction B 0.0904922411 lossA 1.08820319 fraction A 0.0300229564\n",
      "step 1655 loss 0.896271825 fisher_loss 0.109916866 triplet loss 0.786354959 l2_loss 18.2240334 fraction B 0.105683289 lossA 1.06957757 fraction A 0.0310366694\n",
      "step 1656 loss 0.923622131 fisher_loss 0.109308541 triplet loss 0.814313591 l2_loss 18.2343674 fraction B 0.104420647 lossA 1.05467975 fraction A 0.0329133831\n",
      "step 1658 loss 0.863222063 fisher_loss 0.108852193 triplet loss 0.754369855 l2_loss 18.2562351 fraction B 0.0735801384 lossA 1.05208969 fraction A 0.0358818956\n",
      "step 1659 loss 1.00070488 fisher_loss 0.108176284 triplet loss 0.892528653 l2_loss 18.2659912 fraction B 0.102700256 lossA 1.0603621 fraction A 0.0363197364\n",
      "step 1660 loss 0.830744088 fisher_loss 0.107135281 triplet loss 0.723608792 l2_loss 18.2761631 fraction B 0.0855697393 lossA 1.07854986 fraction A 0.0356936418\n",
      "step 1661 loss 0.674123406 fisher_loss 0.106054664 triplet loss 0.568068743 l2_loss 18.2879581 fraction B 0.0659756288 lossA 1.09890008 fraction A 0.0352640115\n",
      "step 1662 loss 0.853444278 fisher_loss 0.105967678 triplet loss 0.747476578 l2_loss 18.3001041 fraction B 0.0634482503 lossA 1.11528409 fraction A 0.0347333439\n",
      "step 1663 loss 0.969766319 fisher_loss 0.106647015 triplet loss 0.863119304 l2_loss 18.3142605 fraction B 0.099154748 lossA 1.12606359 fraction A 0.0344547555\n",
      "step 1664 loss 1.08739567 fisher_loss 0.108180076 triplet loss 0.979215622 l2_loss 18.328764 fraction B 0.120203421 lossA 1.12635756 fraction A 0.035225261\n",
      "step 1673 loss 0.943347752 fisher_loss 0.109705344 triplet loss 0.833642423 l2_loss 18.452013 fraction B 0.0731296241 lossA 1.10002375 fraction A 0.0380590782\n",
      "step 1674 loss 0.817825675 fisher_loss 0.110043302 triplet loss 0.707782388 l2_loss 18.4642315 fraction B 0.0739814565 lossA 1.11010623 fraction A 0.0380410068\n",
      "step 1675 loss 0.691488087 fisher_loss 0.110920206 triplet loss 0.580567896 l2_loss 18.4770679 fraction B 0.0706003457 lossA 1.12379169 fraction A 0.0378533751\n",
      "step 1676 loss 0.821045339 fisher_loss 0.11166741 triplet loss 0.709377944 l2_loss 18.489502 fraction B 0.106996253 lossA 1.13610923 fraction A 0.0376824625\n",
      "step 1677 loss 1.11311722 fisher_loss 0.11270991 triplet loss 1.00040734 l2_loss 18.5005779 fraction B 0.174458817 lossA 1.14435542 fraction A 0.0372954309\n",
      "step 1678 loss 1.00530541 fisher_loss 0.113902576 triplet loss 0.891402841 l2_loss 18.5087185 fraction B 0.17788583 lossA 1.14487112 fraction A 0.0364538804\n",
      "step 1679 loss 0.599938631 fisher_loss 0.114219263 triplet loss 0.485719383 l2_loss 18.5170631 fraction B 0.108737402 lossA 1.13952386 fraction A 0.0365008414\n",
      "step 1680 loss 0.927637339 fisher_loss 0.113375619 triplet loss 0.814261734 l2_loss 18.5249596 fraction B 0.10704013 lossA 1.12420177 fraction A 0.0373733714\n",
      "step 1681 loss 0.945507288 fisher_loss 0.114034764 triplet loss 0.831472516 l2_loss 18.532486 fraction B 0.149960473 lossA 1.10034597 fraction A 0.0393780321\n",
      "step 1682 loss 0.894310415 fisher_loss 0.115077123 triplet loss 0.779233277 l2_loss 18.5416946 fraction B 0.0914890543 lossA 1.08548617 fraction A 0.0404691361\n",
      "step 1683 loss 1.13067234 fisher_loss 0.115141161 triplet loss 1.01553118 l2_loss 18.5523663 fraction B 0.108626656 lossA 1.08085418 fraction A 0.040855065\n",
      "step 1684 loss 0.951520205 fisher_loss 0.114292324 triplet loss 0.837227881 l2_loss 18.5629692 fraction B 0.0673317611 lossA 1.08008826 fraction A 0.0397761352\n",
      "step 1694 loss 1.0760746 fisher_loss 0.120092645 triplet loss 0.95598191 l2_loss 18.6991634 fraction B 0.0916261673 lossA 1.16102993 fraction A 0.0290287845\n",
      "step 1695 loss 1.02525842 fisher_loss 0.117708631 triplet loss 0.907549739 l2_loss 18.7095356 fraction B 0.108232535 lossA 1.13508356 fraction A 0.0294689\n",
      "step 1696 loss 0.908326805 fisher_loss 0.115526102 triplet loss 0.792800725 l2_loss 18.7190933 fraction B 0.0622764863 lossA 1.11414504 fraction A 0.0301011186\n",
      "step 1697 loss 0.93909508 fisher_loss 0.113891825 triplet loss 0.82520324 l2_loss 18.7302723 fraction B 0.0801583305 lossA 1.1013869 fraction A 0.0307155196\n",
      "step 1698 loss 0.869887 fisher_loss 0.113925293 triplet loss 0.755961716 l2_loss 18.7420845 fraction B 0.100764021 lossA 1.10726082 fraction A 0.030687768\n",
      "step 1699 loss 0.795096278 fisher_loss 0.115692042 triplet loss 0.679404259 l2_loss 18.7531776 fraction B 0.0580750816 lossA 1.11459923 fraction A 0.0310400426\n",
      "step 1700 loss 1.05522633 fisher_loss 0.118820764 triplet loss 0.93640554 l2_loss 18.7650394 fraction B 0.0607931651 lossA 1.11921644 fraction A 0.031593\n",
      "step 1701 loss 0.967858255 fisher_loss 0.122392431 triplet loss 0.845465839 l2_loss 18.7757397 fraction B 0.113820553 lossA 1.08997917 fraction A 0.0333098\n",
      "step 1702 loss 0.91128546 fisher_loss 0.121830083 triplet loss 0.789455354 l2_loss 18.7855854 fraction B 0.0838741586 lossA 1.0523448 fraction A 0.0361934751\n",
      "step 1703 loss 1.06743789 fisher_loss 0.120046005 triplet loss 0.947391868 l2_loss 18.7959671 fraction B 0.148146808 lossA 1.02202201 fraction A 0.0390819572\n",
      "step 1704 loss 1.15579557 fisher_loss 0.118172631 triplet loss 1.03762293 l2_loss 18.8086796 fraction B 0.0738459304 lossA 1.0047847 fraction A 0.0403555594\n",
      "step 1705 loss 0.795290232 fisher_loss 0.117234387 triplet loss 0.678055823 l2_loss 18.8204784 fraction B 0.0682153404 lossA 1.00055528 fraction A 0.039662227\n",
      "step 1706 loss 0.920222 fisher_loss 0.116127968 triplet loss 0.804094 l2_loss 18.8344135 fraction B 0.0893892 lossA 0.999407828 fraction A 0.0390786231\n",
      "step 1707 loss 0.919868886 fisher_loss 0.115404353 triplet loss 0.804464519 l2_loss 18.8469086 fraction B 0.0638251454 lossA 1.01326418 fraction A 0.0356095396\n",
      "step 1708 loss 0.964389443 fisher_loss 0.114054784 triplet loss 0.850334644 l2_loss 18.859148 fraction B 0.0879689753 lossA 1.04942763 fraction A 0.0310361572\n",
      "step 1709 loss 0.904458284 fisher_loss 0.11402563 triplet loss 0.790432632 l2_loss 18.8757458 fraction B 0.0623663701 lossA 1.07511222 fraction A 0.0288556349\n",
      "step 1710 loss 0.680286407 fisher_loss 0.115843706 triplet loss 0.564442694 l2_loss 18.893362 fraction B 0.140158713 lossA 1.0828892 fraction A 0.0283952467\n",
      "step 1711 loss 1.14387631 fisher_loss 0.115520053 triplet loss 1.02835631 l2_loss 18.9106121 fraction B 0.136725098 lossA 1.07213068 fraction A 0.0287093576\n",
      "step 1712 loss 0.896878064 fisher_loss 0.115011342 triplet loss 0.781866729 l2_loss 18.9237938 fraction B 0.0941468 lossA 1.04956949 fraction A 0.0301226377\n",
      "step 1713 loss 0.761329174 fisher_loss 0.115099415 triplet loss 0.646229744 l2_loss 18.9362411 fraction B 0.0793602 lossA 1.03891551 fraction A 0.0310666952\n",
      "step 1714 loss 0.930083632 fisher_loss 0.114643186 triplet loss 0.815440476 l2_loss 18.949234 fraction B 0.130261928 lossA 1.05097723 fraction A 0.0303713102\n",
      "step 1715 loss 1.02838409 fisher_loss 0.113447167 triplet loss 0.9149369 l2_loss 18.962635 fraction B 0.0868696719 lossA 1.0633359 fraction A 0.0298117157\n",
      "step 1716 loss 0.891954064 fisher_loss 0.112360455 triplet loss 0.779593587 l2_loss 18.9751968 fraction B 0.095820576 lossA 1.08852112 fraction A 0.0284457654\n",
      "step 1717 loss 1.01455319 fisher_loss 0.111740671 triplet loss 0.902812481 l2_loss 18.9878311 fraction B 0.129937291 lossA 1.10468125 fraction A 0.0280380957\n",
      "step 1718 loss 1.04084933 fisher_loss 0.112646662 triplet loss 0.928202629 l2_loss 19.0001221 fraction B 0.103514202 lossA 1.11015415 fraction A 0.027759729\n",
      "step 1719 loss 0.865756691 fisher_loss 0.112943187 triplet loss 0.752813518 l2_loss 19.0100307 fraction B 0.11015445 lossA 1.09872115 fraction A 0.0276959389\n",
      "step 1720 loss 1.19673669 fisher_loss 0.111808904 triplet loss 1.0849278 l2_loss 19.0193748 fraction B 0.197023273 lossA 1.08152425 fraction A 0.0286234617\n",
      "step 1721 loss 1.10664594 fisher_loss 0.111728035 triplet loss 0.994917929 l2_loss 19.0267677 fraction B 0.0910807401 lossA 1.04604089 fraction A 0.0312513188\n",
      "step 1722 loss 1.02387691 fisher_loss 0.111846715 triplet loss 0.91203022 l2_loss 19.033083 fraction B 0.0687481835 lossA 1.02096379 fraction A 0.0336026065\n",
      "step 1723 loss 1.03564 fisher_loss 0.112672806 triplet loss 0.922967196 l2_loss 19.0401554 fraction B 0.0948710591 lossA 1.0064441 fraction A 0.0353685692\n",
      "step 1724 loss 0.999802113 fisher_loss 0.113061011 triplet loss 0.886741102 l2_loss 19.0493126 fraction B 0.117656618 lossA 1.00626385 fraction A 0.0355404355\n",
      "step 1725 loss 1.05042887 fisher_loss 0.113195896 triplet loss 0.937233 l2_loss 19.059309 fraction B 0.104469776 lossA 1.01557028 fraction A 0.0346189588\n",
      "step 1726 loss 0.765375674 fisher_loss 0.112570636 triplet loss 0.65280503 l2_loss 19.0708866 fraction B 0.0479718894 lossA 1.03579545 fraction A 0.0322429612\n",
      "step 1727 loss 1.1446979 fisher_loss 0.111214124 triplet loss 1.03348374 l2_loss 19.0842228 fraction B 0.0625735298 lossA 1.05819213 fraction A 0.0308780018\n",
      "step 1728 loss 0.54441762 fisher_loss 0.110896543 triplet loss 0.433521092 l2_loss 19.0990925 fraction B 0.0457495637 lossA 1.07086766 fraction A 0.0302830301\n",
      "step 1729 loss 0.956129968 fisher_loss 0.111574635 triplet loss 0.844555318 l2_loss 19.115694 fraction B 0.0957220197 lossA 1.0827235 fraction A 0.0300086234\n",
      "step 1730 loss 0.739342272 fisher_loss 0.112584613 triplet loss 0.626757681 l2_loss 19.1322937 fraction B 0.0688488781 lossA 1.08364165 fraction A 0.0304144602\n",
      "step 1731 loss 0.897631168 fisher_loss 0.113117382 triplet loss 0.784513772 l2_loss 19.1499062 fraction B 0.0877164528 lossA 1.08084989 fraction A 0.0307051446\n",
      "step 1732 loss 0.97513932 fisher_loss 0.113044545 triplet loss 0.86209476 l2_loss 19.1671085 fraction B 0.0727792382 lossA 1.06848061 fraction A 0.030749578\n",
      "step 1733 loss 0.738140404 fisher_loss 0.112540297 triplet loss 0.6256001 l2_loss 19.1842575 fraction B 0.039252229 lossA 1.06311679 fraction A 0.0308829863\n",
      "step 1734 loss 1.06016433 fisher_loss 0.1128361 triplet loss 0.947328269 l2_loss 19.2009182 fraction B 0.092997618 lossA 1.05211 fraction A 0.0316389725\n",
      "step 1735 loss 0.906785846 fisher_loss 0.114062093 triplet loss 0.792723775 l2_loss 19.217411 fraction B 0.0633341819 lossA 1.054245 fraction A 0.0318145044\n",
      "step 1736 loss 0.713642716 fisher_loss 0.115893714 triplet loss 0.597749 l2_loss 19.2318325 fraction B 0.0855037421 lossA 1.05455315 fraction A 0.0315261297\n",
      "step 1737 loss 0.865156 fisher_loss 0.114508867 triplet loss 0.750647128 l2_loss 19.2423115 fraction B 0.0890460759 lossA 1.05886567 fraction A 0.0317068323\n",
      "step 1738 loss 1.02741933 fisher_loss 0.114174008 triplet loss 0.91324532 l2_loss 19.2535419 fraction B 0.0999495313 lossA 1.0624162 fraction A 0.0323544107\n",
      "step 1739 loss 0.799398 fisher_loss 0.115452565 triplet loss 0.683945417 l2_loss 19.2641602 fraction B 0.0728378743 lossA 1.06183791 fraction A 0.0325265713\n",
      "step 1740 loss 0.849171162 fisher_loss 0.115943953 triplet loss 0.733227193 l2_loss 19.2761345 fraction B 0.0503834337 lossA 1.07498837 fraction A 0.0321070254\n",
      "step 1741 loss 0.996459901 fisher_loss 0.11710351 triplet loss 0.879356384 l2_loss 19.2876148 fraction B 0.141902596 lossA 1.08781552 fraction A 0.0312281139\n",
      "step 1742 loss 0.866730511 fisher_loss 0.117535219 triplet loss 0.749195278 l2_loss 19.2980728 fraction B 0.0815656558 lossA 1.09909678 fraction A 0.0307576805\n",
      "step 1743 loss 0.969613254 fisher_loss 0.118181355 triplet loss 0.851431906 l2_loss 19.3091125 fraction B 0.127624765 lossA 1.12186408 fraction A 0.0294647943\n",
      "step 1744 loss 0.895718515 fisher_loss 0.11928314 triplet loss 0.776435375 l2_loss 19.3195305 fraction B 0.0794324949 lossA 1.13038 fraction A 0.0288730115\n",
      "step 1745 loss 1.04168797 fisher_loss 0.120596893 triplet loss 0.92109108 l2_loss 19.3280926 fraction B 0.10951864 lossA 1.13804185 fraction A 0.0284548569\n",
      "step 1746 loss 0.870674729 fisher_loss 0.120289654 triplet loss 0.750385046 l2_loss 19.3371334 fraction B 0.104699075 lossA 1.13328946 fraction A 0.02870965\n",
      "step 1747 loss 0.852506459 fisher_loss 0.118644662 triplet loss 0.733861804 l2_loss 19.345747 fraction B 0.082054995 lossA 1.12426054 fraction A 0.0292912032\n",
      "step 1748 loss 0.833693206 fisher_loss 0.117136918 triplet loss 0.716556311 l2_loss 19.3549976 fraction B 0.0637340844 lossA 1.10823917 fraction A 0.0297617484\n",
      "step 1749 loss 0.801713645 fisher_loss 0.115825787 triplet loss 0.685887873 l2_loss 19.3682346 fraction B 0.0646274686 lossA 1.08447587 fraction A 0.0309093464\n",
      "step 1750 loss 1.1788646 fisher_loss 0.11703489 triplet loss 1.06182969 l2_loss 19.3836327 fraction B 0.159801245 lossA 1.0636549 fraction A 0.0316718593\n",
      "step 1751 loss 0.859423339 fisher_loss 0.119104922 triplet loss 0.740318418 l2_loss 19.3986206 fraction B 0.0641575083 lossA 1.05142856 fraction A 0.0312093068\n",
      "step 1752 loss 0.966681182 fisher_loss 0.121011414 triplet loss 0.845669746 l2_loss 19.415823 fraction B 0.103761703 lossA 1.05364954 fraction A 0.0300375484\n",
      "step 1753 loss 0.994743168 fisher_loss 0.121776827 triplet loss 0.872966349 l2_loss 19.4323349 fraction B 0.0397268198 lossA 1.05541325 fraction A 0.0294019561\n",
      "step 1754 loss 0.754017591 fisher_loss 0.121955007 triplet loss 0.632062554 l2_loss 19.4501247 fraction B 0.0410095789 lossA 1.06010532 fraction A 0.0285838302\n",
      "step 1755 loss 1.06550527 fisher_loss 0.122757688 triplet loss 0.942747533 l2_loss 19.4678307 fraction B 0.0805353224 lossA 1.08267438 fraction A 0.027566012\n",
      "step 1756 loss 1.13490808 fisher_loss 0.122237779 triplet loss 1.01267028 l2_loss 19.4832611 fraction B 0.129036888 lossA 1.09428728 fraction A 0.0272929966\n",
      "step 1757 loss 1.08360434 fisher_loss 0.122350171 triplet loss 0.961254179 l2_loss 19.4974499 fraction B 0.103121057 lossA 1.10898495 fraction A 0.0274292659\n",
      "step 1758 loss 0.955348611 fisher_loss 0.123051941 triplet loss 0.832296669 l2_loss 19.5103111 fraction B 0.0782061443 lossA 1.12534487 fraction A 0.0278221983\n",
      "step 1759 loss 0.750239134 fisher_loss 0.125078171 triplet loss 0.625160933 l2_loss 19.5222645 fraction B 0.065322 lossA 1.13264728 fraction A 0.0284695216\n",
      "step 1760 loss 1.05791175 fisher_loss 0.126994476 triplet loss 0.930917263 l2_loss 19.5338173 fraction B 0.0932265148 lossA 1.12303936 fraction A 0.0294778813\n",
      "step 1761 loss 0.780597806 fisher_loss 0.12531881 triplet loss 0.655279 l2_loss 19.5433235 fraction B 0.0773395449 lossA 1.12298179 fraction A 0.0310114101\n",
      "step 1762 loss 0.922986388 fisher_loss 0.124644168 triplet loss 0.798342228 l2_loss 19.5526028 fraction B 0.0936933681 lossA 1.10549831 fraction A 0.0328182094\n",
      "step 1763 loss 0.953185797 fisher_loss 0.122707918 triplet loss 0.830477893 l2_loss 19.5640659 fraction B 0.124280058 lossA 1.0933603 fraction A 0.0344826169\n",
      "step 1764 loss 0.742677152 fisher_loss 0.121818781 triplet loss 0.620858371 l2_loss 19.5744781 fraction B 0.0703275874 lossA 1.07719147 fraction A 0.0357014872\n",
      "step 1765 loss 0.847149491 fisher_loss 0.120132923 triplet loss 0.727016568 l2_loss 19.5865364 fraction B 0.0660110265 lossA 1.07008994 fraction A 0.0359912924\n",
      "step 1766 loss 1.17777574 fisher_loss 0.118816867 triplet loss 1.05895889 l2_loss 19.6015053 fraction B 0.154073015 lossA 1.0643636 fraction A 0.0358567461\n",
      "step 1767 loss 1.08094227 fisher_loss 0.117992565 triplet loss 0.962949753 l2_loss 19.6164951 fraction B 0.0829415917 lossA 1.0602082 fraction A 0.0350309201\n",
      "step 1768 loss 0.822549403 fisher_loss 0.118438646 triplet loss 0.704110742 l2_loss 19.6310921 fraction B 0.0687730312 lossA 1.06292105 fraction A 0.0338070653\n",
      "step 1769 loss 1.06550014 fisher_loss 0.119216479 triplet loss 0.946283698 l2_loss 19.6472588 fraction B 0.112116188 lossA 1.07997584 fraction A 0.0316617377\n",
      "step 1770 loss 0.935932279 fisher_loss 0.119470172 triplet loss 0.8164621 l2_loss 19.6639462 fraction B 0.0860700309 lossA 1.11032069 fraction A 0.0296641197\n",
      "step 1771 loss 0.867117 fisher_loss 0.119552389 triplet loss 0.747564614 l2_loss 19.6800156 fraction B 0.0711974725 lossA 1.1407578 fraction A 0.0293075908\n",
      "step 1772 loss 1.09529102 fisher_loss 0.120456792 triplet loss 0.974834263 l2_loss 19.6952972 fraction B 0.0891532078 lossA 1.15567458 fraction A 0.0292660184\n",
      "step 1773 loss 0.869688451 fisher_loss 0.120357566 triplet loss 0.749330878 l2_loss 19.7080212 fraction B 0.061351154 lossA 1.16195393 fraction A 0.0292574018\n",
      "step 1774 loss 0.970860362 fisher_loss 0.119981885 triplet loss 0.850878477 l2_loss 19.7205181 fraction B 0.0660152 lossA 1.16375911 fraction A 0.028869126\n",
      "step 1775 loss 0.925187528 fisher_loss 0.120402031 triplet loss 0.80478549 l2_loss 19.7333488 fraction B 0.0358316042 lossA 1.15229952 fraction A 0.0287553668\n",
      "step 1776 loss 0.953979969 fisher_loss 0.120325774 triplet loss 0.833654225 l2_loss 19.7445717 fraction B 0.0913984329 lossA 1.14815605 fraction A 0.0288239233\n",
      "step 1777 loss 1.01248229 fisher_loss 0.119394682 triplet loss 0.893087566 l2_loss 19.7563686 fraction B 0.0707378685 lossA 1.12228251 fraction A 0.0295058172\n",
      "step 1778 loss 1.16751468 fisher_loss 0.117756478 triplet loss 1.0497582 l2_loss 19.7671528 fraction B 0.11852105 lossA 1.10912585 fraction A 0.0303199105\n",
      "step 1779 loss 1.1036526 fisher_loss 0.116491094 triplet loss 0.987161517 l2_loss 19.7770958 fraction B 0.0603189 lossA 1.10117888 fraction A 0.0309917238\n",
      "step 1780 loss 1.01457024 fisher_loss 0.115453966 triplet loss 0.899116218 l2_loss 19.7871323 fraction B 0.0874941424 lossA 1.0962503 fraction A 0.0311454423\n",
      "step 1781 loss 0.900543928 fisher_loss 0.114889763 triplet loss 0.785654187 l2_loss 19.7986374 fraction B 0.143003777 lossA 1.09500849 fraction A 0.0312371682\n",
      "step 1782 loss 0.991882503 fisher_loss 0.116019532 triplet loss 0.875862956 l2_loss 19.8105354 fraction B 0.133237302 lossA 1.10514975 fraction A 0.0309487209\n",
      "step 1783 loss 0.731421947 fisher_loss 0.11836946 triplet loss 0.613052487 l2_loss 19.8226242 fraction B 0.0813881829 lossA 1.10704565 fraction A 0.0307019912\n",
      "step 1784 loss 0.663610518 fisher_loss 0.12001922 triplet loss 0.543591321 l2_loss 19.8344841 fraction B 0.0720779225 lossA 1.09412956 fraction A 0.0308480486\n",
      "step 1785 loss 1.04265332 fisher_loss 0.118299156 triplet loss 0.924354196 l2_loss 19.845829 fraction B 0.108194642 lossA 1.08178759 fraction A 0.0315796919\n",
      "step 1786 loss 1.02328682 fisher_loss 0.11753881 triplet loss 0.90574795 l2_loss 19.8588161 fraction B 0.110772505 lossA 1.05850625 fraction A 0.0333430134\n",
      "step 1787 loss 0.710191548 fisher_loss 0.116219 triplet loss 0.593972564 l2_loss 19.8700771 fraction B 0.0593043342 lossA 1.05259025 fraction A 0.0338630863\n",
      "step 1788 loss 0.910170078 fisher_loss 0.116615146 triplet loss 0.793554962 l2_loss 19.8816776 fraction B 0.114310272 lossA 1.05038583 fraction A 0.0338042788\n",
      "step 1789 loss 0.768218637 fisher_loss 0.115451902 triplet loss 0.652766764 l2_loss 19.8948898 fraction B 0.0648785755 lossA 1.04754233 fraction A 0.0339241251\n",
      "step 1790 loss 1.03425479 fisher_loss 0.114534378 triplet loss 0.919720411 l2_loss 19.9086494 fraction B 0.0784777626 lossA 1.05332923 fraction A 0.0341480859\n",
      "step 1791 loss 0.885306478 fisher_loss 0.113826163 triplet loss 0.771480322 l2_loss 19.9217644 fraction B 0.0748576224 lossA 1.06691301 fraction A 0.0336211585\n",
      "step 1792 loss 0.867514729 fisher_loss 0.113312982 triplet loss 0.75420177 l2_loss 19.9350357 fraction B 0.0751838237 lossA 1.07526839 fraction A 0.0338994153\n",
      "step 1793 loss 0.982320666 fisher_loss 0.113478869 triplet loss 0.868841767 l2_loss 19.9501362 fraction B 0.1249955 lossA 1.09398437 fraction A 0.0337371901\n",
      "step 1794 loss 0.906621039 fisher_loss 0.11451 triplet loss 0.792111039 l2_loss 19.9646072 fraction B 0.0697108433 lossA 1.12190223 fraction A 0.0328822918\n",
      "step 1795 loss 0.987636209 fisher_loss 0.11587996 triplet loss 0.871756256 l2_loss 19.9782028 fraction B 0.0530292094 lossA 1.1542486 fraction A 0.0322912075\n",
      "step 1796 loss 0.685756803 fisher_loss 0.117983982 triplet loss 0.567772806 l2_loss 19.990509 fraction B 0.0613602959 lossA 1.16395247 fraction A 0.0324292742\n",
      "step 1797 loss 0.872636318 fisher_loss 0.118368469 triplet loss 0.754267871 l2_loss 20.003727 fraction B 0.0982367769 lossA 1.16743577 fraction A 0.0321603641\n",
      "step 1798 loss 0.702060819 fisher_loss 0.117258087 triplet loss 0.584802747 l2_loss 20.0154781 fraction B 0.0585555322 lossA 1.13783073 fraction A 0.0328112431\n",
      "step 1799 loss 1.0887419 fisher_loss 0.114657484 triplet loss 0.974084437 l2_loss 20.0283298 fraction B 0.0943191871 lossA 1.10675406 fraction A 0.0344947912\n",
      "step 1800 loss 1.05292237 fisher_loss 0.115051441 triplet loss 0.937871 l2_loss 20.040802 fraction B 0.0948902518 lossA 1.08893585 fraction A 0.0358208902\n",
      "step 1801 loss 0.850869119 fisher_loss 0.116116561 triplet loss 0.734752536 l2_loss 20.0521584 fraction B 0.0348595604 lossA 1.09134901 fraction A 0.0336669497\n",
      "step 1802 loss 0.939082444 fisher_loss 0.114329338 triplet loss 0.824753106 l2_loss 20.0683746 fraction B 0.12954545 lossA 1.1115917 fraction A 0.0309031513\n",
      "step 1803 loss 0.82952708 fisher_loss 0.113435514 triplet loss 0.716091573 l2_loss 20.0836506 fraction B 0.0729691163 lossA 1.12576079 fraction A 0.0290659219\n",
      "step 1804 loss 0.708422184 fisher_loss 0.114995509 triplet loss 0.593426704 l2_loss 20.0980606 fraction B 0.0520996749 lossA 1.1292305 fraction A 0.0284170955\n",
      "step 1805 loss 0.687538385 fisher_loss 0.118238844 triplet loss 0.569299519 l2_loss 20.114687 fraction B 0.0490654223 lossA 1.14517152 fraction A 0.0276192799\n",
      "step 1806 loss 0.829759538 fisher_loss 0.120791487 triplet loss 0.708968043 l2_loss 20.1304398 fraction B 0.107801467 lossA 1.14920759 fraction A 0.0276728421\n",
      "step 1807 loss 1.05155051 fisher_loss 0.121978149 triplet loss 0.929572403 l2_loss 20.1453457 fraction B 0.11846514 lossA 1.13236308 fraction A 0.0281183086\n",
      "step 1808 loss 1.09362614 fisher_loss 0.121481165 triplet loss 0.972145 l2_loss 20.1581078 fraction B 0.107076079 lossA 1.1144352 fraction A 0.0290519912\n",
      "step 1809 loss 0.967293203 fisher_loss 0.120905712 triplet loss 0.846387506 l2_loss 20.1690311 fraction B 0.0554507859 lossA 1.11164427 fraction A 0.0292461477\n",
      "step 1810 loss 1.05334544 fisher_loss 0.121593975 triplet loss 0.93175149 l2_loss 20.1825409 fraction B 0.0833876207 lossA 1.10919058 fraction A 0.0294236597\n",
      "step 1811 loss 0.867383122 fisher_loss 0.121955603 triplet loss 0.745427549 l2_loss 20.1965847 fraction B 0.0924985558 lossA 1.12213433 fraction A 0.0292072501\n",
      "step 1812 loss 0.779938757 fisher_loss 0.122705869 triplet loss 0.657232881 l2_loss 20.2106247 fraction B 0.0371197052 lossA 1.13026166 fraction A 0.0299045052\n",
      "step 1813 loss 0.909043849 fisher_loss 0.125017643 triplet loss 0.784026206 l2_loss 20.2235889 fraction B 0.103878267 lossA 1.13247204 fraction A 0.0318872035\n",
      "step 1814 loss 0.936875403 fisher_loss 0.127667859 triplet loss 0.809207559 l2_loss 20.2356529 fraction B 0.0605782717 lossA 1.1460309 fraction A 0.0334016681\n",
      "step 1815 loss 0.990066588 fisher_loss 0.129877448 triplet loss 0.86018914 l2_loss 20.2476864 fraction B 0.117030486 lossA 1.15061247 fraction A 0.0344174\n",
      "step 1816 loss 0.986964345 fisher_loss 0.128930748 triplet loss 0.858033597 l2_loss 20.2606678 fraction B 0.0865202621 lossA 1.15414476 fraction A 0.035839919\n",
      "step 1817 loss 0.853080511 fisher_loss 0.127939746 triplet loss 0.72514075 l2_loss 20.2721443 fraction B 0.103493556 lossA 1.16123927 fraction A 0.0372573026\n",
      "step 1818 loss 1.03301418 fisher_loss 0.127914041 triplet loss 0.905100107 l2_loss 20.283514 fraction B 0.0912052095 lossA 1.14025795 fraction A 0.0381339416\n",
      "step 1819 loss 1.0459168 fisher_loss 0.125586107 triplet loss 0.920330644 l2_loss 20.2945137 fraction B 0.0740293041 lossA 1.12846231 fraction A 0.0375832208\n",
      "step 1820 loss 1.01034522 fisher_loss 0.123604096 triplet loss 0.886741161 l2_loss 20.3052731 fraction B 0.0630921 lossA 1.12941575 fraction A 0.0368544\n",
      "step 1821 loss 0.932935178 fisher_loss 0.123450533 triplet loss 0.809484661 l2_loss 20.3181477 fraction B 0.0585926212 lossA 1.12752736 fraction A 0.0357097723\n",
      "step 1822 loss 1.03689468 fisher_loss 0.128143057 triplet loss 0.908751667 l2_loss 20.331665 fraction B 0.175028801 lossA 1.1400609 fraction A 0.0363798589\n",
      "step 1823 loss 0.980484843 fisher_loss 0.136080921 triplet loss 0.844403923 l2_loss 20.3459988 fraction B 0.146173283 lossA 1.14708638 fraction A 0.036333669\n",
      "step 1824 loss 0.968168616 fisher_loss 0.135482043 triplet loss 0.832686543 l2_loss 20.3580284 fraction B 0.184347361 lossA 1.14221609 fraction A 0.0344249494\n",
      "step 1825 loss 1.1627301 fisher_loss 0.130038977 triplet loss 1.03269112 l2_loss 20.3688507 fraction B 0.169577271 lossA 1.13889301 fraction A 0.0326079577\n",
      "step 1826 loss 0.884024382 fisher_loss 0.12514022 triplet loss 0.758884132 l2_loss 20.3767567 fraction B 0.0701368 lossA 1.12656963 fraction A 0.0335342735\n",
      "step 1827 loss 1.02049637 fisher_loss 0.126983464 triplet loss 0.893512845 l2_loss 20.3840752 fraction B 0.0862485543 lossA 1.11565161 fraction A 0.0345080234\n",
      "step 1828 loss 0.995247602 fisher_loss 0.131151527 triplet loss 0.864096045 l2_loss 20.392 fraction B 0.0622202158 lossA 1.11525214 fraction A 0.0334464684\n",
      "step 1829 loss 1.04838049 fisher_loss 0.132825926 triplet loss 0.915554583 l2_loss 20.4003773 fraction B 0.122310467 lossA 1.11037672 fraction A 0.0327628888\n",
      "step 1830 loss 1.09095764 fisher_loss 0.131900832 triplet loss 0.959056795 l2_loss 20.4098244 fraction B 0.0871393383 lossA 1.11480582 fraction A 0.0316424184\n",
      "step 1831 loss 1.31633604 fisher_loss 0.12764962 triplet loss 1.18868637 l2_loss 20.4172554 fraction B 0.114340663 lossA 1.12135208 fraction A 0.0311244354\n",
      "step 1832 loss 1.21963525 fisher_loss 0.12270233 triplet loss 1.09693289 l2_loss 20.4262562 fraction B 0.0560600497 lossA 1.1257515 fraction A 0.0310908556\n",
      "step 1833 loss 0.942450345 fisher_loss 0.119856425 triplet loss 0.822593927 l2_loss 20.4348087 fraction B 0.0827627182 lossA 1.14163923 fraction A 0.0301787294\n",
      "step 1834 loss 0.907424927 fisher_loss 0.118670851 triplet loss 0.788754046 l2_loss 20.4427662 fraction B 0.0442214981 lossA 1.14530659 fraction A 0.0299061928\n",
      "step 1835 loss 0.901724815 fisher_loss 0.120086104 triplet loss 0.781638682 l2_loss 20.4540749 fraction B 0.125288814 lossA 1.12575376 fraction A 0.0315607376\n",
      "step 1836 loss 0.997207582 fisher_loss 0.120106772 triplet loss 0.877100825 l2_loss 20.4653988 fraction B 0.052574873 lossA 1.10833943 fraction A 0.0334052257\n",
      "step 1837 loss 0.81009078 fisher_loss 0.121021427 triplet loss 0.689069331 l2_loss 20.4773617 fraction B 0.0483451933 lossA 1.09774399 fraction A 0.0343794189\n",
      "step 1838 loss 0.879772902 fisher_loss 0.122732513 triplet loss 0.757040381 l2_loss 20.4923801 fraction B 0.0606594905 lossA 1.09128606 fraction A 0.0345946178\n",
      "step 1839 loss 1.16497958 fisher_loss 0.123365551 triplet loss 1.04161406 l2_loss 20.5067616 fraction B 0.135083556 lossA 1.08767116 fraction A 0.0346470065\n",
      "step 1840 loss 0.982505202 fisher_loss 0.12435022 triplet loss 0.858155 l2_loss 20.5194302 fraction B 0.113802463 lossA 1.08826804 fraction A 0.0347396843\n",
      "step 1841 loss 0.818230689 fisher_loss 0.123095714 triplet loss 0.695135 l2_loss 20.5315323 fraction B 0.0695029348 lossA 1.09445429 fraction A 0.0344354\n",
      "step 1842 loss 1.11091959 fisher_loss 0.122011721 triplet loss 0.988907874 l2_loss 20.5423107 fraction B 0.0751656368 lossA 1.10238433 fraction A 0.0344352163\n",
      "step 1843 loss 0.834700823 fisher_loss 0.120530255 triplet loss 0.714170575 l2_loss 20.5519695 fraction B 0.0386026 lossA 1.11206234 fraction A 0.0339923128\n",
      "step 1844 loss 0.87384367 fisher_loss 0.120006613 triplet loss 0.753837049 l2_loss 20.5642986 fraction B 0.0781448558 lossA 1.12005067 fraction A 0.0334781073\n",
      "step 1845 loss 1.02501595 fisher_loss 0.118956737 triplet loss 0.906059206 l2_loss 20.5765266 fraction B 0.144612506 lossA 1.12117386 fraction A 0.0334624909\n",
      "step 1846 loss 1.2079972 fisher_loss 0.118266106 triplet loss 1.0897311 l2_loss 20.588192 fraction B 0.119871773 lossA 1.12932384 fraction A 0.0335961208\n",
      "step 1847 loss 1.06449723 fisher_loss 0.119097248 triplet loss 0.94539994 l2_loss 20.5986614 fraction B 0.136576742 lossA 1.13189936 fraction A 0.0344947912\n",
      "step 1848 loss 0.797628462 fisher_loss 0.12004894 triplet loss 0.677579522 l2_loss 20.6090813 fraction B 0.0761758313 lossA 1.14270425 fraction A 0.0354215428\n",
      "step 1849 loss 0.998321116 fisher_loss 0.122172654 triplet loss 0.876148462 l2_loss 20.6188679 fraction B 0.0929641 lossA 1.16590083 fraction A 0.0350907855\n",
      "step 1850 loss 0.832773924 fisher_loss 0.124002993 triplet loss 0.708770931 l2_loss 20.6307564 fraction B 0.125502512 lossA 1.1792984 fraction A 0.0347796455\n",
      "step 1851 loss 0.975875 fisher_loss 0.124169327 triplet loss 0.85170567 l2_loss 20.6450939 fraction B 0.089682512 lossA 1.1793611 fraction A 0.0352456048\n",
      "step 1852 loss 1.0770272 fisher_loss 0.123129822 triplet loss 0.953897417 l2_loss 20.6589184 fraction B 0.0877974555 lossA 1.16374767 fraction A 0.0361021534\n",
      "step 1853 loss 1.03151572 fisher_loss 0.121865444 triplet loss 0.909650266 l2_loss 20.669611 fraction B 0.133305773 lossA 1.14202011 fraction A 0.0361913852\n",
      "step 1854 loss 0.966170549 fisher_loss 0.121034704 triplet loss 0.845135868 l2_loss 20.6803684 fraction B 0.0840912312 lossA 1.12694192 fraction A 0.0349439234\n",
      "step 1855 loss 0.99235642 fisher_loss 0.120707951 triplet loss 0.87164849 l2_loss 20.6936226 fraction B 0.0509348325 lossA 1.11184824 fraction A 0.0342853814\n",
      "step 1856 loss 0.839047432 fisher_loss 0.119952336 triplet loss 0.719095111 l2_loss 20.7083 fraction B 0.0603268668 lossA 1.11046469 fraction A 0.0321715102\n",
      "step 1857 loss 1.04857957 fisher_loss 0.119553268 triplet loss 0.929026306 l2_loss 20.7255707 fraction B 0.101288699 lossA 1.10719955 fraction A 0.0311452225\n",
      "step 1858 loss 0.984720409 fisher_loss 0.119852424 triplet loss 0.864868 l2_loss 20.7415752 fraction B 0.0850732177 lossA 1.10692918 fraction A 0.0303722266\n",
      "step 1859 loss 1.08313262 fisher_loss 0.11872568 triplet loss 0.964406908 l2_loss 20.7578659 fraction B 0.0969572812 lossA 1.10056806 fraction A 0.0300196949\n",
      "step 1860 loss 1.0933398 fisher_loss 0.118365772 triplet loss 0.974974036 l2_loss 20.7741585 fraction B 0.184922382 lossA 1.09461987 fraction A 0.0301209893\n",
      "step 1861 loss 0.954773 fisher_loss 0.11760883 triplet loss 0.837164164 l2_loss 20.7890816 fraction B 0.105756991 lossA 1.09438336 fraction A 0.0304748043\n",
      "step 1862 loss 0.964625597 fisher_loss 0.115987644 triplet loss 0.848637938 l2_loss 20.8025684 fraction B 0.113044575 lossA 1.08329403 fraction A 0.0306414273\n",
      "step 1863 loss 0.879989743 fisher_loss 0.114485078 triplet loss 0.765504658 l2_loss 20.8147964 fraction B 0.153045416 lossA 1.07122338 fraction A 0.0311845243\n",
      "step 1864 loss 0.913707614 fisher_loss 0.113344453 triplet loss 0.800363183 l2_loss 20.8258018 fraction B 0.0922424644 lossA 1.0598278 fraction A 0.0319503\n",
      "step 1865 loss 0.865996957 fisher_loss 0.113249071 triplet loss 0.752747893 l2_loss 20.8366566 fraction B 0.113901004 lossA 1.05490887 fraction A 0.0325288437\n",
      "step 1866 loss 1.01381612 fisher_loss 0.112745427 triplet loss 0.901070714 l2_loss 20.8488617 fraction B 0.164758503 lossA 1.05016768 fraction A 0.0331203714\n",
      "step 1867 loss 0.833573341 fisher_loss 0.11241205 triplet loss 0.721161306 l2_loss 20.8621368 fraction B 0.0897343829 lossA 1.0406394 fraction A 0.0347650535\n",
      "step 1868 loss 0.773228049 fisher_loss 0.112785771 triplet loss 0.660442293 l2_loss 20.8755856 fraction B 0.0626178 lossA 1.04245353 fraction A 0.0360300764\n",
      "step 1869 loss 0.954150319 fisher_loss 0.11260882 triplet loss 0.841541529 l2_loss 20.8912067 fraction B 0.102795817 lossA 1.04834449 fraction A 0.0366499797\n",
      "step 1870 loss 0.97193706 fisher_loss 0.112629272 triplet loss 0.859307766 l2_loss 20.9061852 fraction B 0.0781576112 lossA 1.05514169 fraction A 0.0371420421\n",
      "step 1871 loss 0.974831045 fisher_loss 0.112691917 triplet loss 0.862139106 l2_loss 20.9200268 fraction B 0.104988292 lossA 1.07098055 fraction A 0.0357616469\n",
      "step 1872 loss 0.766066611 fisher_loss 0.112175234 triplet loss 0.653891385 l2_loss 20.9348545 fraction B 0.0593954846 lossA 1.0916971 fraction A 0.0338061862\n",
      "step 1873 loss 0.78693068 fisher_loss 0.11347191 triplet loss 0.673458755 l2_loss 20.9508972 fraction B 0.0929374844 lossA 1.10315394 fraction A 0.0327801183\n",
      "step 1874 loss 0.834589183 fisher_loss 0.114345953 triplet loss 0.720243216 l2_loss 20.9675026 fraction B 0.108894102 lossA 1.11016083 fraction A 0.0319437347\n",
      "step 1875 loss 0.905319571 fisher_loss 0.114298671 triplet loss 0.79102093 l2_loss 20.9842224 fraction B 0.0843965188 lossA 1.12101519 fraction A 0.0314656049\n",
      "step 1876 loss 0.743784726 fisher_loss 0.114830717 triplet loss 0.628954 l2_loss 21.0004845 fraction B 0.0645870566 lossA 1.12174487 fraction A 0.0317774415\n",
      "step 1877 loss 0.99424839 fisher_loss 0.115378372 triplet loss 0.87887 l2_loss 21.0175591 fraction B 0.129526213 lossA 1.11896694 fraction A 0.0311814807\n",
      "step 1878 loss 0.976957083 fisher_loss 0.116401613 triplet loss 0.86055547 l2_loss 21.0350285 fraction B 0.0913278162 lossA 1.1197505 fraction A 0.0308747757\n",
      "step 1879 loss 0.992622077 fisher_loss 0.117931344 triplet loss 0.874690711 l2_loss 21.0518055 fraction B 0.0796435401 lossA 1.10077429 fraction A 0.0316736177\n",
      "step 1880 loss 0.958290458 fisher_loss 0.117830902 triplet loss 0.840459585 l2_loss 21.0670414 fraction B 0.14867492 lossA 1.08476841 fraction A 0.032296963\n",
      "step 1881 loss 0.857750356 fisher_loss 0.11693009 triplet loss 0.740820289 l2_loss 21.0815182 fraction B 0.0521978028 lossA 1.08469236 fraction A 0.0319460072\n",
      "step 1882 loss 0.900514066 fisher_loss 0.116080284 triplet loss 0.784433782 l2_loss 21.0959053 fraction B 0.060422793 lossA 1.08317447 fraction A 0.0317601375\n",
      "step 1883 loss 0.781478763 fisher_loss 0.116138846 triplet loss 0.665339887 l2_loss 21.1100483 fraction B 0.0590840094 lossA 1.08958578 fraction A 0.031446062\n",
      "step 1884 loss 0.810742736 fisher_loss 0.117304228 triplet loss 0.69343853 l2_loss 21.125206 fraction B 0.0624192394 lossA 1.10272121 fraction A 0.031094484\n",
      "step 1885 loss 0.821094871 fisher_loss 0.120619662 triplet loss 0.700475216 l2_loss 21.1389408 fraction B 0.0911833 lossA 1.10681283 fraction A 0.0308039822\n",
      "step 1886 loss 0.777683735 fisher_loss 0.118298709 triplet loss 0.659385 l2_loss 21.1542435 fraction B 0.0729133 lossA 1.12056065 fraction A 0.0302308612\n",
      "step 1887 loss 0.800003827 fisher_loss 0.115328409 triplet loss 0.684675395 l2_loss 21.1675358 fraction B 0.0981950238 lossA 1.12081623 fraction A 0.0303622186\n",
      "step 1888 loss 0.718584418 fisher_loss 0.115761071 triplet loss 0.602823377 l2_loss 21.1788483 fraction B 0.0369511284 lossA 1.12822425 fraction A 0.0305660535\n",
      "step 1889 loss 1.13213825 fisher_loss 0.118340597 triplet loss 1.01379764 l2_loss 21.1891708 fraction B 0.0585962422 lossA 1.12248516 fraction A 0.0314011164\n",
      "step 1890 loss 0.892667532 fisher_loss 0.120645046 triplet loss 0.772022486 l2_loss 21.1977177 fraction B 0.0585744157 lossA 1.12955284 fraction A 0.0308959279\n",
      "step 1891 loss 1.18828857 fisher_loss 0.120386682 triplet loss 1.06790185 l2_loss 21.2074718 fraction B 0.126700431 lossA 1.13165617 fraction A 0.0303360783\n",
      "step 1892 loss 0.900309682 fisher_loss 0.11755304 triplet loss 0.782756627 l2_loss 21.2169056 fraction B 0.12180803 lossA 1.14637268 fraction A 0.0296324082\n",
      "step 1893 loss 1.1003958 fisher_loss 0.11693126 triplet loss 0.983464539 l2_loss 21.2272129 fraction B 0.116660662 lossA 1.16433346 fraction A 0.029104637\n",
      "step 1894 loss 0.925003171 fisher_loss 0.118075714 triplet loss 0.806927443 l2_loss 21.2383728 fraction B 0.0754983202 lossA 1.15343118 fraction A 0.0290257055\n",
      "step 1895 loss 0.801003039 fisher_loss 0.119060159 triplet loss 0.68194288 l2_loss 21.2501297 fraction B 0.125403106 lossA 1.13405323 fraction A 0.0296941083\n",
      "step 1896 loss 0.78943491 fisher_loss 0.118223071 triplet loss 0.671211839 l2_loss 21.2634277 fraction B 0.0565787554 lossA 1.11193192 fraction A 0.0316422358\n",
      "step 1897 loss 0.875146687 fisher_loss 0.118506357 triplet loss 0.756640315 l2_loss 21.276659 fraction B 0.0667916909 lossA 1.10092938 fraction A 0.0328651741\n",
      "step 1898 loss 0.924972653 fisher_loss 0.118729353 triplet loss 0.8062433 l2_loss 21.2900772 fraction B 0.0413996205 lossA 1.10119379 fraction A 0.0337743275\n",
      "step 1899 loss 0.779533 fisher_loss 0.118291102 triplet loss 0.661241949 l2_loss 21.3035221 fraction B 0.0414583646 lossA 1.10831094 fraction A 0.0338560827\n",
      "step 1900 loss 0.952592611 fisher_loss 0.117187865 triplet loss 0.835404754 l2_loss 21.3186264 fraction B 0.0637545809 lossA 1.13014448 fraction A 0.0328510962\n",
      "step 1901 loss 1.07751989 fisher_loss 0.116073333 triplet loss 0.961446524 l2_loss 21.3340569 fraction B 0.137814969 lossA 1.17149115 fraction A 0.0318945\n",
      "step 1902 loss 0.867306232 fisher_loss 0.117381059 triplet loss 0.749925196 l2_loss 21.3499527 fraction B 0.0862213 lossA 1.21248329 fraction A 0.0321953408\n",
      "step 1903 loss 0.88824755 fisher_loss 0.12036512 triplet loss 0.767882407 l2_loss 21.3650417 fraction B 0.0806864575 lossA 1.24227023 fraction A 0.032534197\n",
      "step 1904 loss 0.681548715 fisher_loss 0.123204187 triplet loss 0.558344543 l2_loss 21.3794727 fraction B 0.0264559388 lossA 1.23831868 fraction A 0.0319747888\n",
      "Saved checkpoint for step .tf2/EWC/CWRU-noise/embedding/fisher/ckpt-1\n"
     ]
    }
   ],
   "source": [
    "conv_net.unfreeze()\n",
    "\n",
    "train_emb_EWC = Train_Embeddings_EWC(embedding, fisher_matrix_TL , learning_rate, int(num_batches*training_iters),\n",
    "                                     batch_size, display_step, \"batch_all\", margin, squared,lamb, filepath, restore=False)\n",
    "\n",
    "idx = np.random.choice(X_train.shape[0], 500)\n",
    "train_emb_EWC.fit(X_train_noise, y_train_noise, X_train[idx,:], y_train[idx], save = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FXPO22vB_KYX"
   },
   "source": [
    "#Classifier EWC\n",
    "\n",
    "Now try to train the classifier using EWC (without training the embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 731,
     "status": "ok",
     "timestamp": 1585915089383,
     "user": {
      "displayName": "Laia Domingo",
      "photoUrl": "",
      "userId": "05713674999451466092"
     },
     "user_tz": -120
    },
    "id": "E125s4ANcd59",
    "outputId": "83b4c747-c15e-445e-c7a6-5389cfbfc718"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420000"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_iters = 20000\n",
    "learning_rate = 0.0001\n",
    "filepath =\"Weights/EWC/CWRU-noise/fisher/classifier/\"\n",
    "int(num_batches*training_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4733,
     "status": "ok",
     "timestamp": 1585915097453,
     "user": {
      "displayName": "Laia Domingo",
      "photoUrl": "",
      "userId": "05713674999451466092"
     },
     "user_tz": -120
    },
    "id": "72hIrbH8AymN",
    "outputId": "56c0a44c-b8d3-42f1-892d-541dc80439ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 16 loss 0.161784232 fisher_loss 0.0513590239 l2_loss 0.0119169448 accuracy B 0.924612 accuracy A 0.96008867\n",
      "step 32 loss 0.350608528 fisher_loss 0.0551934727 l2_loss 0.0290297065 accuracy B 0.926829278 accuracy A 0.954175889\n",
      "step 48 loss 0.330241919 fisher_loss 0.0572124608 l2_loss 0.0472856909 accuracy B 0.931263864 accuracy A 0.952697694\n",
      "step 64 loss 0.38424629 fisher_loss 0.0544444434 l2_loss 0.0648033321 accuracy B 0.932002962 accuracy A 0.951958597\n",
      "step 80 loss 0.130845815 fisher_loss 0.062874347 l2_loss 0.0887026116 accuracy B 0.936437547 accuracy A 0.947524\n",
      "step 96 loss 0.274997801 fisher_loss 0.0491293445 l2_loss 0.104643837 accuracy B 0.931263864 accuracy A 0.953436792\n",
      "step 112 loss 0.196266413 fisher_loss 0.0528281368 l2_loss 0.127509475 accuracy B 0.933481157 accuracy A 0.949741304\n",
      "step 128 loss 0.395174861 fisher_loss 0.0617439859 l2_loss 0.157425985 accuracy B 0.940133035 accuracy A 0.936437547\n",
      "step 144 loss 0.120064408 fisher_loss 0.0636834577 l2_loss 0.197223768 accuracy B 0.939393938 accuracy A 0.937176645\n",
      "step 160 loss 0.18398279 fisher_loss 0.0617036186 l2_loss 0.229915693 accuracy B 0.94161123 accuracy A 0.934959352\n",
      "Saved checkpoint for step .tf2/EWC/CWRU-noise/classifier/fisher/ckpt-1\n"
     ]
    }
   ],
   "source": [
    "conv_net.freeze()\n",
    "train_clas_EWC = Train_Classifier_EWC(conv_net,fisher_matrix_CL, learning_rate, int(num_batches*training_iters),\n",
    "                                     batch_size, display_step,5e3, filepath, restore=False)\n",
    "\n",
    "train_clas_EWC.fit(X_train_noise, y_train_noise, X_train, y_train, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4oBCDC9plF5G"
   },
   "source": [
    "### Accuracy after EWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 575,
     "status": "ok",
     "timestamp": 1585915104314,
     "user": {
      "displayName": "Laia Domingo",
      "photoUrl": "",
      "userId": "05713674999451466092"
     },
     "user_tz": -120
    },
    "id": "WZBt-Ge9BDBn",
    "outputId": "edf9a169-01c5-43c0-9c6c-b11e15630420"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored from Weights/EWC/CWRU-noise/fisher/classifier/ckpt-1\n",
      "WARNING:tensorflow:Layer classification_6 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.fc1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.fc1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.fc2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.fc2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.fc3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.fc3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.out.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.out.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.fc1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.fc1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.fc2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.fc2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.fc3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.fc3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.out.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.out.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Test Accuracy: 0.951965\n"
     ]
    }
   ],
   "source": [
    "# Comment this line to use the model you just trained, and not the loaded weights\n",
    "embedding, conv_net = load_model(\"Weights/EWC/CWRU-noise/fisher/classifier/\")\n",
    "\n",
    "# Test model on test set.\n",
    "pred= conv_net(X_test)\n",
    "y_pred = np.argmax(pred.numpy(), axis=1)\n",
    "print(\"Test Accuracy: %f\" % accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 372,
     "status": "ok",
     "timestamp": 1585915105388,
     "user": {
      "displayName": "Laia Domingo",
      "photoUrl": "",
      "userId": "05713674999451466092"
     },
     "user_tz": -120
    },
    "id": "9n03hTwvB3gA",
    "outputId": "55ca4175-e87b-403c-ac7e-541dcd854f8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.951965\n"
     ]
    }
   ],
   "source": [
    "# Test model on test set.\n",
    "pred= conv_net(X_test_noise)\n",
    "print(\"Test Accuracy: %f\" % accuracy_score(y_pred, y_test_noise))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lehAk4BLz0JI"
   },
   "source": [
    "Finally, we visualize the embeddings for both datasets.\n",
    "\n",
    "### Task A (CWRU without noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sPs6EW62zitw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer embedding_6 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emb = np.nan_to_num(embedding(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1697,
     "status": "ok",
     "timestamp": 1585915110244,
     "user": {
      "displayName": "Laia Domingo",
      "photoUrl": "",
      "userId": "05713674999451466092"
     },
     "user_tz": -120
    },
    "id": "3T9TKf7lzqMm",
    "outputId": "80942fb2-afe3-4d3e-dae6-2becd7953fbb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = emb\n",
    "\n",
    "embed = umap.UMAP(n_neighbors=10,\n",
    "                      min_dist=0.2,\n",
    "                      metric='correlation').fit_transform(features)\n",
    "\n",
    "color = pd.DataFrame(y_test, columns=['color'])\n",
    "color.replace({0:'red', 1:'blue', 2:'green', 3:'orange'},inplace=True)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "plt.scatter(embed[:,0], embed[:,1], \n",
    "            c=color.values.flatten(),\n",
    "            cmap=\"Spectral\", \n",
    "            s=1.0)\n",
    "plt.setp(ax, xticks=[], yticks=[])\n",
    "plt.title(\"Extracted features CNN+Triplet Learning by UMAP\", fontsize=18)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-rIHyAEEz863"
   },
   "source": [
    "### Task B (CWRU with noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QbvqPphBz_UB"
   },
   "outputs": [],
   "source": [
    "emb_noise = np.nan_to_num(embedding(X_test_noise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1961,
     "status": "ok",
     "timestamp": 1585915112573,
     "user": {
      "displayName": "Laia Domingo",
      "photoUrl": "",
      "userId": "05713674999451466092"
     },
     "user_tz": -120
    },
    "id": "hhQH7jKFz_Rd",
    "outputId": "84f652e1-a411-4150-fe97-07b854b7d91f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = emb_noise\n",
    "\n",
    "embed = umap.UMAP(n_neighbors=10,\n",
    "                      min_dist=0.2,\n",
    "                      metric='correlation').fit_transform(features)\n",
    "\n",
    "color = pd.DataFrame(y_test_noise,columns=['color'])\n",
    "color.replace({0:'red', 1:'blue', 2:'green', 3:'orange'},inplace=True)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "plt.scatter(embed[:,0], embed[:,1], \n",
    "            c=color.values.flatten(),\n",
    "            cmap=\"Spectral\", \n",
    "            s=1.0)\n",
    "plt.setp(ax, xticks=[], yticks=[])\n",
    "plt.title(\"Extracted features CNN+Triplet Learning by UMAP\", fontsize=18)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lN7edbiU0UV-"
   },
   "source": [
    "Here we add the code needed to import this final model"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOCM95uzBeNnpx8xKK5E2O1",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Còpia de EWC-new_behaviour.ipynb",
   "provenance": [
    {
     "file_id": "1u9rd9fGDwUplRNvj1NUUc-WtAO7AsuWd",
     "timestamp": 1583829453344
    },
    {
     "file_id": "1GreEeWVtPRGldRR3V1521-LG1XIZfD5T",
     "timestamp": 1583483313327
    },
    {
     "file_id": "1fuu4M1efq7vfdDLG09En1niJUZ59I-oB",
     "timestamp": 1582024464889
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
